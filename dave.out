/home/azureuser/torch-mlir/build/bin/torch-mlir-opt: /home/azureuser/miniconda/lib/libtinfo.so.6: no version information available (required by /home/azureuser/torch-mlir/build/bin/torch-mlir-opt)
./scratch/dave.mlir:3:10: error: failed to legalize operation 'torch.operator'
    %0 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.embed_tokens.weight> : tensor<32000x4096xf32>} : () -> !torch.vtensor<[32000,4096],f32>
         ^
./scratch/dave.mlir:3:10: note: diagnostic emitted with trace:
 #0 0x000055cf2a88a54d llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) /home/azureuser/torch-mlir/externals/llvm-project/llvm/lib/Support/Unix/Signals.inc:723:11
 #1 0x000055cf2a66267e emitDiag(mlir::Location, mlir::DiagnosticSeverity, llvm::Twine const&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/IR/Diagnostics.cpp:319:5
 #2 0x000055cf2a6625a5 mlir::emitError(mlir::Location, llvm::Twine const&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/IR/Diagnostics.cpp:330:10
 #3 0x000055cf2a707da8 mlir::Operation::emitError(llvm::Twine const&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/IR/Operation.cpp:269:29
 #4 0x000055cf29171ead (anonymous namespace)::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Transforms/Utils/DialectConversion.cpp:2382:14
 #5 0x000055cf2916aebe (anonymous namespace)::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>, llvm::function_ref<void (mlir::Diagnostic&)>) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Transforms/Utils/DialectConversion.cpp:2431:16
 #6 0x000055cf2916b187 mlir::applyFullConversion(llvm::ArrayRef<mlir::Operation*>, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Transforms/Utils/DialectConversion.cpp:3418:22
 #7 0x000055cf2916b1e6 mlir::applyFullConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Transforms/Utils/DialectConversion.cpp:3423:10
 #8 0x000055cf278dc350 (anonymous namespace)::FinalizingBackendTypeConversionPass::runOnOperation() /home/azureuser/torch-mlir/lib/Dialect/TorchConversion/Transforms/BackendTypeConversionPasses.cpp:152:16
 #9 0x000055cf292a9fab mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_1::operator()() const /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:0:17
#10 0x000055cf292a9f45 void llvm::function_ref<void ()>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_1>(long) /home/azureuser/torch-mlir/externals/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:45:5
#11 0x000055cf26c66929 llvm::function_ref<void ()>::operator()() const /home/azureuser/torch-mlir/externals/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:68:5
#12 0x000055cf292acce5 void mlir::MLIRContext::executeAction<mlir::PassExecutionAction, mlir::Pass&>(llvm::function_ref<void ()>, llvm::ArrayRef<mlir::IRUnit>, mlir::Pass&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/include/mlir/IR/MLIRContext.h:276:3
#13 0x000055cf292a5703 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:525:17
#14 0x000055cf292a5c84 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:585:16
#15 0x000055cf292a6ade mlir::detail::OpToOpPassAdaptor::runOnOperationImpl(bool) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:726:20
#16 0x000055cf292a638d mlir::detail::OpToOpPassAdaptor::runOnOperation(bool) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:709:1
#17 0x000055cf292a9f96 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_1::operator()() const /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:517:11
#18 0x000055cf292a9f45 void llvm::function_ref<void ()>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_1>(long) /home/azureuser/torch-mlir/externals/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:45:5
#19 0x000055cf26c66929 llvm::function_ref<void ()>::operator()() const /home/azureuser/torch-mlir/externals/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:68:5
#20 0x000055cf292acce5 void mlir::MLIRContext::executeAction<mlir::PassExecutionAction, mlir::Pass&>(llvm::function_ref<void ()>, llvm::ArrayRef<mlir::IRUnit>, mlir::Pass&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/include/mlir/IR/MLIRContext.h:276:3
#21 0x000055cf292a5703 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:525:17
#22 0x000055cf292a5c84 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:585:16
#23 0x000055cf292a76c8 mlir::PassManager::runPasses(mlir::Operation*, mlir::AnalysisManager) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:896:10
#24 0x000055cf292a75f2 mlir::PassManager::run(mlir::Operation*) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Pass/Pass.cpp:876:60
#25 0x000055cf26beac32 performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Tools/mlir-opt/MlirOptMain.cpp:394:17
#26 0x000055cf26bea868 processBuffer(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::MlirOptMainConfig const&, mlir::DialectRegistry&, llvm::ThreadPool*) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Tools/mlir-opt/MlirOptMain.cpp:459:12
#27 0x000055cf26bea64c mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_0::operator()(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) const /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Tools/mlir-opt/MlirOptMain.cpp:530:12
#28 0x000055cf26bea5e6 mlir::LogicalResult llvm::function_ref<mlir::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_0>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) /home/azureuser/torch-mlir/externals/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:45:12
#29 0x000055cf2a776c02 llvm::function_ref<mlir::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::operator()(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) const /home/azureuser/torch-mlir/externals/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:68:12
#30 0x000055cf2a77621d mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<mlir::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, bool, bool) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Support/ToolUtilities.cpp:28:12
#31 0x000055cf26be751b mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Tools/mlir-opt/MlirOptMain.cpp:533:10
#32 0x000055cf26be77b5 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Tools/mlir-opt/MlirOptMain.cpp:568:14
#33 0x000055cf26be7988 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) /home/azureuser/torch-mlir/externals/llvm-project/mlir/lib/Tools/mlir-opt/MlirOptMain.cpp:584:10
#34 0x000055cf26be2ea5 main /home/azureuser/torch-mlir/tools/torch-mlir-opt/torch-mlir-opt.cpp:43:33
#35 0x00007f1d4c023a90 (/lib/x86_64-linux-gnu/libc.so.6+0x23a90)
#36 0x00007f1d4c023b49 __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x23b49)
#37 0x000055cf26be2d35 _start (/home/azureuser/torch-mlir/build/bin/torch-mlir-opt+0x213d35)

./scratch/dave.mlir:3:10: note: see current operation: %3 = "torch.operator"() <{name = "onnx.Constant"}> {torch.onnx.value = dense_resource<_model.embed_tokens.weight> : tensor<32000x4096xf32>} : () -> !torch.vtensor<[32000,4096],f32> loc("./scratch/dave.mlir":3:10)
// -----// IR Dump After FinalizingBackendTypeConversion Failed (torch-finalizing-backend-type-conversion) ('func.func' operation: @main_graph) //----- //
#loc3 = loc("./scratch/dave.mlir":2:25)
module {
  ml_program.global private mutable @global_seed(dense<0> : tensor<i64>) : tensor<i64> loc(#loc1)
  func.func @main_graph(%arg0: tensor<1x8xi64> loc("./scratch/dave.mlir":2:25)) -> (tensor<1x8x32000xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>) attributes {torch.onnx_meta.ir_version = 8 : si64, torch.onnx_meta.opset_version = 17 : si64, torch.onnx_meta.producer_name = "pytorch", torch.onnx_meta.producer_version = "2.3.0"} {
    %cst = arith.constant dense<1> : tensor<4xi64> loc(#loc1)
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<1x8xi64> -> !torch.vtensor<[1,8],si64> loc(#loc3)
    %1 = torch_c.from_builtin_tensor %cst : tensor<4xi64> -> !torch.vtensor<[4],si64> loc(#loc1)
    %2 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.embed_tokens.weight> : tensor<32000x4096xf32>} : () -> !torch.vtensor<[32000,4096],f32> loc(#loc4)
    %3 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.0.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc5)
    %4 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.0.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc6)
    %5 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.1.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc7)
    %6 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.1.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc8)
    %7 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.2.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc9)
    %8 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.2.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc10)
    %9 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.3.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc11)
    %10 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.3.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc12)
    %11 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.4.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc13)
    %12 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.4.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc14)
    %13 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.5.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc15)
    %14 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.5.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc16)
    %15 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.6.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc17)
    %16 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.6.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc18)
    %17 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.7.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc19)
    %18 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.7.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc20)
    %19 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.8.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc21)
    %20 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.8.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc22)
    %21 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.9.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc23)
    %22 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.9.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc24)
    %23 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.10.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc25)
    %24 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.10.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc26)
    %25 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.11.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc27)
    %26 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.11.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc28)
    %27 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.12.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc29)
    %28 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.12.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc30)
    %29 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.13.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc31)
    %30 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.13.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc32)
    %31 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.14.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc33)
    %32 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.14.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc34)
    %33 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.15.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc35)
    %34 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.15.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc36)
    %35 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.16.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc37)
    %36 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.16.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc38)
    %37 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.17.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc39)
    %38 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.17.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc40)
    %39 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.18.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc41)
    %40 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.18.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc42)
    %41 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.19.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc43)
    %42 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.19.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc44)
    %43 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.20.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc45)
    %44 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.20.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc46)
    %45 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.21.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc47)
    %46 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.21.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc48)
    %47 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.22.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc49)
    %48 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.22.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc50)
    %49 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.23.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc51)
    %50 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.23.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc52)
    %51 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.24.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc53)
    %52 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.24.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc54)
    %53 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.25.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc55)
    %54 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.25.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc56)
    %55 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.26.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc57)
    %56 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.26.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc58)
    %57 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.27.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc59)
    %58 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.27.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc60)
    %59 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.28.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc61)
    %60 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.28.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc62)
    %61 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.29.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc63)
    %62 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.29.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc64)
    %63 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.30.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc65)
    %64 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.30.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc66)
    %65 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.31.input_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc67)
    %66 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.layers.31.post_attention_layernorm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc68)
    %67 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_model.norm.weight> : tensor<4096xf32>} : () -> !torch.vtensor<[4096],f32> loc(#loc69)
    %68 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5237> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc70)
    %69 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5238> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc71)
    %70 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5239> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc72)
    %71 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5275> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc73)
    %72 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5276> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc74)
    %73 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5277> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc75)
    %74 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5278> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc76)
    %75 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5279> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc77)
    %76 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5280> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc78)
    %77 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5281> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc79)
    %78 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5317> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc80)
    %79 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5318> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc81)
    %80 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5319> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc82)
    %81 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5320> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc83)
    %82 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5321> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc84)
    %83 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5322> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc85)
    %84 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5323> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc86)
    %85 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5359> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc87)
    %86 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5360> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc88)
    %87 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5361> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc89)
    %88 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5362> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc90)
    %89 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5363> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc91)
    %90 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5364> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc92)
    %91 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5365> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc93)
    %92 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5401> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc94)
    %93 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5402> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc95)
    %94 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5403> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc96)
    %95 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5404> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc97)
    %96 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5405> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc98)
    %97 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5406> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc99)
    %98 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5407> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc100)
    %99 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5443> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc101)
    %100 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5444> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc102)
    %101 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5445> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc103)
    %102 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5446> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc104)
    %103 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5447> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc105)
    %104 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5448> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc106)
    %105 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5449> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc107)
    %106 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5485> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc108)
    %107 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5486> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc109)
    %108 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5487> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc110)
    %109 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5488> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc111)
    %110 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5489> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc112)
    %111 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5490> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc113)
    %112 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5491> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc114)
    %113 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5527> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc115)
    %114 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5528> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc116)
    %115 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5529> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc117)
    %116 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5530> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc118)
    %117 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5531> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc119)
    %118 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5532> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc120)
    %119 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5533> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc121)
    %120 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5569> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc122)
    %121 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5570> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc123)
    %122 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5571> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc124)
    %123 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5572> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc125)
    %124 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5573> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc126)
    %125 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5574> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc127)
    %126 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5575> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc128)
    %127 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5611> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc129)
    %128 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5612> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc130)
    %129 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5613> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc131)
    %130 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5614> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc132)
    %131 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5615> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc133)
    %132 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5616> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc134)
    %133 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5617> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc135)
    %134 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5653> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc136)
    %135 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5654> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc137)
    %136 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5655> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc138)
    %137 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5656> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc139)
    %138 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5657> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc140)
    %139 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5658> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc141)
    %140 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5659> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc142)
    %141 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5695> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc143)
    %142 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5696> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc144)
    %143 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5697> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc145)
    %144 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5698> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc146)
    %145 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5699> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc147)
    %146 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5700> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc148)
    %147 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5701> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc149)
    %148 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5737> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc150)
    %149 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5738> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc151)
    %150 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5739> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc152)
    %151 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5740> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc153)
    %152 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5741> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc154)
    %153 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5742> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc155)
    %154 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5743> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc156)
    %155 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5779> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc157)
    %156 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5780> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc158)
    %157 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5781> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc159)
    %158 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5782> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc160)
    %159 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5783> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc161)
    %160 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5784> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc162)
    %161 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5785> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc163)
    %162 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5821> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc164)
    %163 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5822> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc165)
    %164 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5823> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc166)
    %165 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5824> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc167)
    %166 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5825> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc168)
    %167 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5826> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc169)
    %168 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5827> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc170)
    %169 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5863> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc171)
    %170 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5864> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc172)
    %171 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5865> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc173)
    %172 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5866> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc174)
    %173 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5867> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc175)
    %174 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5868> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc176)
    %175 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5869> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc177)
    %176 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5905> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc178)
    %177 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5906> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc179)
    %178 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5907> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc180)
    %179 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5908> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc181)
    %180 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5909> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc182)
    %181 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5910> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc183)
    %182 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5911> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc184)
    %183 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5947> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc185)
    %184 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5948> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc186)
    %185 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5949> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc187)
    %186 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5950> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc188)
    %187 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5951> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc189)
    %188 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5952> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc190)
    %189 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5953> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc191)
    %190 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5989> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc192)
    %191 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5990> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc193)
    %192 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5991> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc194)
    %193 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5992> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc195)
    %194 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5993> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc196)
    %195 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5994> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc197)
    %196 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_5995> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc198)
    %197 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6031> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc199)
    %198 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6032> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc200)
    %199 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6033> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc201)
    %200 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6034> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc202)
    %201 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6035> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc203)
    %202 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6036> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc204)
    %203 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6037> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc205)
    %204 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6073> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc206)
    %205 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6074> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc207)
    %206 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6075> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc208)
    %207 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6076> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc209)
    %208 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6077> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc210)
    %209 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6078> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc211)
    %210 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6079> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc212)
    %211 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6115> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc213)
    %212 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6116> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc214)
    %213 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6117> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc215)
    %214 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6118> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc216)
    %215 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6119> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc217)
    %216 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6120> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc218)
    %217 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6121> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc219)
    %218 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6157> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc220)
    %219 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6158> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc221)
    %220 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6159> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc222)
    %221 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6160> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc223)
    %222 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6161> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc224)
    %223 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6162> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc225)
    %224 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6163> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc226)
    %225 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6199> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc227)
    %226 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6200> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc228)
    %227 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6201> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc229)
    %228 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6202> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc230)
    %229 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6203> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc231)
    %230 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6204> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc232)
    %231 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6205> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc233)
    %232 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6241> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc234)
    %233 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6242> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc235)
    %234 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6243> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc236)
    %235 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6244> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc237)
    %236 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6245> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc238)
    %237 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6246> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc239)
    %238 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6247> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc240)
    %239 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6283> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc241)
    %240 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6284> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc242)
    %241 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6285> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc243)
    %242 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6286> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc244)
    %243 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6287> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc245)
    %244 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6288> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc246)
    %245 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6289> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc247)
    %246 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6325> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc248)
    %247 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6326> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc249)
    %248 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6327> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc250)
    %249 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6328> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc251)
    %250 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6329> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc252)
    %251 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6330> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc253)
    %252 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6331> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc254)
    %253 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6367> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc255)
    %254 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6368> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc256)
    %255 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6369> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc257)
    %256 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6370> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc258)
    %257 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6371> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc259)
    %258 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6372> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc260)
    %259 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6373> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc261)
    %260 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6409> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc262)
    %261 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6410> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc263)
    %262 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6411> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc264)
    %263 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6412> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc265)
    %264 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6413> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc266)
    %265 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6414> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc267)
    %266 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6415> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc268)
    %267 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6451> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc269)
    %268 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6452> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc270)
    %269 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6453> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc271)
    %270 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6454> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc272)
    %271 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6455> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc273)
    %272 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6456> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc274)
    %273 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6457> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc275)
    %274 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6493> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc276)
    %275 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6494> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc277)
    %276 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6495> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc278)
    %277 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6496> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc279)
    %278 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6497> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc280)
    %279 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6498> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc281)
    %280 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6499> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc282)
    %281 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6535> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc283)
    %282 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6536> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc284)
    %283 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6537> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc285)
    %284 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6538> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc286)
    %285 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6539> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc287)
    %286 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6540> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc288)
    %287 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6541> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc289)
    %288 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6577> : tensor<4096x4096xf32>} : () -> !torch.vtensor<[4096,4096],f32> loc(#loc290)
    %289 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6578> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc291)
    %290 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6579> : tensor<4096x11008xf32>} : () -> !torch.vtensor<[4096,11008],f32> loc(#loc292)
    %291 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6580> : tensor<11008x4096xf32>} : () -> !torch.vtensor<[11008,4096],f32> loc(#loc293)
    %292 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<_onnx__MatMul_6581> : tensor<4096x32000xf32>} : () -> !torch.vtensor<[4096,32000],f32> loc(#loc294)
    %293 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_Constant_attr__value> : tensor<1x8xsi64>} : () -> !torch.vtensor<[1,8],si64> loc(#loc295)
    %294 = torch.operator "onnx.Gather"(%2, %0) : (!torch.vtensor<[32000,4096],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc296)
    %295 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_Constant_1_attr__value> : tensor<1x1x8x8xf32>} : () -> !torch.vtensor<[1,1,8,8],f32> loc(#loc297)
    %296 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc298)
    %297 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc299)
    %298 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_Constant_4_attr__value> : tensor<si64>} : () -> !torch.vtensor<[],si64> loc(#loc300)
    %299 = torch.operator "onnx.Mul"(%1, %298) : (!torch.vtensor<[4],si64>, !torch.vtensor<[],si64>) -> !torch.vtensor<[4],si64> loc(#loc301)
    %300 = torch.operator "onnx.Equal"(%296, %299) : (!torch.vtensor<[4],si64>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[4],i1> loc(#loc302)
    %301 = torch.operator "onnx.Where"(%300, %1, %296) : (!torch.vtensor<[4],i1>, !torch.vtensor<[4],si64>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[4],si64> loc(#loc303)
    %302 = torch.operator "onnx.Expand"(%295, %301) : (!torch.vtensor<[1,1,8,8],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[?,?,8,8],f32> loc(#loc304)
    %303 = torch.operator "onnx.Cast"(%294) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc305)
    %304 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc306)
    %305 = torch.operator "onnx.Pow"(%303, %304) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc307)
    %306 = torch.operator "onnx.ReduceMean"(%305) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc308)
    %307 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc309)
    %308 = torch.operator "onnx.Add"(%306, %307) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc310)
    %309 = torch.operator "onnx.Sqrt"(%308) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc311)
    %310 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc312)
    %311 = torch.operator "onnx.Div"(%310, %309) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc313)
    %312 = torch.operator "onnx.Mul"(%303, %311) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc314)
    %313 = torch.operator "onnx.Cast"(%312) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc315)
    %314 = torch.operator "onnx.Mul"(%3, %313) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc316)
    %315 = torch.operator "onnx.MatMul"(%314, %68) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc317)
    %316 = torch.operator "onnx.MatMul"(%314, %69) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc318)
    %317 = torch.operator "onnx.MatMul"(%314, %70) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc319)
    %318 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc320)
    %319 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc321)
    %320 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc322)
    %321 = torch.operator "onnx.Reshape"(%315, %318) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc323)
    %322 = torch.operator "onnx.Transpose"(%321) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc324)
    %323 = torch.operator "onnx.Reshape"(%316, %319) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc325)
    %324 = torch.operator "onnx.Transpose"(%323) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc326)
    %325 = torch.operator "onnx.Reshape"(%317, %320) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc327)
    %326 = torch.operator "onnx.Transpose"(%325) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc328)
    %327 = torch_c.to_builtin_tensor %326 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %328 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc330)
    %329 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc331)
    %330 = torch.operator "onnx.Gather"(%328, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc332)
    %331 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc333)
    %332 = torch.operator "onnx.Unsqueeze"(%330, %331) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc334)
    %333 = torch.operator "onnx.Gather"(%329, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc335)
    %334 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc336)
    %335 = torch.operator "onnx.Unsqueeze"(%333, %334) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc337)
    %336 = torch.operator "onnx.Mul"(%322, %332) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc338)
    %337 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc339)
    %338 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc340)
    %339 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc341)
    %340 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc342)
    %341 = torch.operator "onnx.Slice"(%322, %338, %339, %337, %340) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc343)
    %342 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc344)
    %343 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc345)
    %344 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc346)
    %345 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc347)
    %346 = torch.operator "onnx.Slice"(%322, %343, %344, %342, %345) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc348)
    %347 = torch.operator "onnx.Neg"(%346) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc349)
    %348 = torch.operator "onnx.Concat"(%347, %341) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc350)
    %349 = torch.operator "onnx.Mul"(%348, %335) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc351)
    %350 = torch.operator "onnx.Add"(%336, %349) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc352)
    %351 = torch.operator "onnx.Mul"(%324, %332) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc353)
    %352 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc354)
    %353 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc355)
    %354 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc356)
    %355 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc357)
    %356 = torch.operator "onnx.Slice"(%324, %353, %354, %352, %355) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc358)
    %357 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc359)
    %358 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc360)
    %359 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc361)
    %360 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc362)
    %361 = torch.operator "onnx.Slice"(%324, %358, %359, %357, %360) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc363)
    %362 = torch.operator "onnx.Neg"(%361) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc364)
    %363 = torch.operator "onnx.Concat"(%362, %356) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc365)
    %364 = torch.operator "onnx.Mul"(%363, %335) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc366)
    %365 = torch.operator "onnx.Add"(%351, %364) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc367)
    %366 = torch_c.to_builtin_tensor %365 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %367 = torch.operator "onnx.Transpose"(%365) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc368)
    %368 = torch.operator "onnx.MatMul"(%350, %367) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc369)
    %369 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc370)
    %370 = torch.operator "onnx.Div"(%368, %369) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc371)
    %371 = torch.operator "onnx.Add"(%370, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc372)
    %372 = torch.operator "onnx.Softmax"(%371) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc373)
    %373 = torch.operator "onnx.Cast"(%372) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc374)
    %374 = torch.operator "onnx.Cast"(%373) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc375)
    %375 = torch.operator "onnx.MatMul"(%374, %326) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc376)
    %376 = torch.operator "onnx.Transpose"(%375) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc377)
    %377 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc378)
    %378 = torch.operator "onnx.Reshape"(%376, %377) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc379)
    %379 = torch.operator "onnx.MatMul"(%378, %71) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc380)
    %380 = torch.operator "onnx.Add"(%303, %379) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc381)
    %381 = torch.operator "onnx.Cast"(%380) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc382)
    %382 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc383)
    %383 = torch.operator "onnx.Pow"(%381, %382) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc384)
    %384 = torch.operator "onnx.ReduceMean"(%383) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc385)
    %385 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc386)
    %386 = torch.operator "onnx.Add"(%384, %385) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc387)
    %387 = torch.operator "onnx.Sqrt"(%386) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc388)
    %388 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.0_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc389)
    %389 = torch.operator "onnx.Div"(%388, %387) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc390)
    %390 = torch.operator "onnx.Mul"(%381, %389) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc391)
    %391 = torch.operator "onnx.Cast"(%390) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc392)
    %392 = torch.operator "onnx.Mul"(%4, %391) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc393)
    %393 = torch.operator "onnx.MatMul"(%392, %72) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc394)
    %394 = torch.operator "onnx.Sigmoid"(%393) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc395)
    %395 = torch.operator "onnx.Mul"(%393, %394) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc396)
    %396 = torch.operator "onnx.MatMul"(%392, %73) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc397)
    %397 = torch.operator "onnx.Mul"(%395, %396) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc398)
    %398 = torch.operator "onnx.MatMul"(%397, %74) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc399)
    %399 = torch.operator "onnx.Add"(%381, %398) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc400)
    %400 = torch.operator "onnx.Cast"(%399) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc401)
    %401 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc402)
    %402 = torch.operator "onnx.Pow"(%400, %401) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc403)
    %403 = torch.operator "onnx.ReduceMean"(%402) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc404)
    %404 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc405)
    %405 = torch.operator "onnx.Add"(%403, %404) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc406)
    %406 = torch.operator "onnx.Sqrt"(%405) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc407)
    %407 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc408)
    %408 = torch.operator "onnx.Div"(%407, %406) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc409)
    %409 = torch.operator "onnx.Mul"(%400, %408) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc410)
    %410 = torch.operator "onnx.Cast"(%409) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc411)
    %411 = torch.operator "onnx.Mul"(%5, %410) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc412)
    %412 = torch.operator "onnx.MatMul"(%411, %75) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc413)
    %413 = torch.operator "onnx.MatMul"(%411, %76) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc414)
    %414 = torch.operator "onnx.MatMul"(%411, %77) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc415)
    %415 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc416)
    %416 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc417)
    %417 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc418)
    %418 = torch.operator "onnx.Reshape"(%412, %415) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc419)
    %419 = torch.operator "onnx.Transpose"(%418) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc420)
    %420 = torch.operator "onnx.Reshape"(%413, %416) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc421)
    %421 = torch.operator "onnx.Transpose"(%420) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc422)
    %422 = torch.operator "onnx.Reshape"(%414, %417) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc423)
    %423 = torch.operator "onnx.Transpose"(%422) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc424)
    %424 = torch_c.to_builtin_tensor %423 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %425 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc425)
    %426 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc426)
    %427 = torch.operator "onnx.Gather"(%425, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc427)
    %428 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc428)
    %429 = torch.operator "onnx.Unsqueeze"(%427, %428) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc429)
    %430 = torch.operator "onnx.Gather"(%426, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc430)
    %431 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc431)
    %432 = torch.operator "onnx.Unsqueeze"(%430, %431) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc432)
    %433 = torch.operator "onnx.Mul"(%419, %429) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc433)
    %434 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc434)
    %435 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc435)
    %436 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc436)
    %437 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc437)
    %438 = torch.operator "onnx.Slice"(%419, %435, %436, %434, %437) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc438)
    %439 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc439)
    %440 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc440)
    %441 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc441)
    %442 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc442)
    %443 = torch.operator "onnx.Slice"(%419, %440, %441, %439, %442) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc443)
    %444 = torch.operator "onnx.Neg"(%443) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc444)
    %445 = torch.operator "onnx.Concat"(%444, %438) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc445)
    %446 = torch.operator "onnx.Mul"(%445, %432) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc446)
    %447 = torch.operator "onnx.Add"(%433, %446) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc447)
    %448 = torch.operator "onnx.Mul"(%421, %429) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc448)
    %449 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc449)
    %450 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc450)
    %451 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc451)
    %452 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc452)
    %453 = torch.operator "onnx.Slice"(%421, %450, %451, %449, %452) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc453)
    %454 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc454)
    %455 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc455)
    %456 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc456)
    %457 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc457)
    %458 = torch.operator "onnx.Slice"(%421, %455, %456, %454, %457) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc458)
    %459 = torch.operator "onnx.Neg"(%458) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc459)
    %460 = torch.operator "onnx.Concat"(%459, %453) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc460)
    %461 = torch.operator "onnx.Mul"(%460, %432) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc461)
    %462 = torch.operator "onnx.Add"(%448, %461) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc462)
    %463 = torch_c.to_builtin_tensor %462 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %464 = torch.operator "onnx.Transpose"(%462) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc463)
    %465 = torch.operator "onnx.MatMul"(%447, %464) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc464)
    %466 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc465)
    %467 = torch.operator "onnx.Div"(%465, %466) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc466)
    %468 = torch.operator "onnx.Add"(%467, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc467)
    %469 = torch.operator "onnx.Softmax"(%468) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc468)
    %470 = torch.operator "onnx.Cast"(%469) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc469)
    %471 = torch.operator "onnx.Cast"(%470) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc470)
    %472 = torch.operator "onnx.MatMul"(%471, %423) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc471)
    %473 = torch.operator "onnx.Transpose"(%472) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc472)
    %474 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc473)
    %475 = torch.operator "onnx.Reshape"(%473, %474) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc474)
    %476 = torch.operator "onnx.MatMul"(%475, %78) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc475)
    %477 = torch.operator "onnx.Add"(%400, %476) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc476)
    %478 = torch.operator "onnx.Cast"(%477) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc477)
    %479 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc478)
    %480 = torch.operator "onnx.Pow"(%478, %479) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc479)
    %481 = torch.operator "onnx.ReduceMean"(%480) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc480)
    %482 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc481)
    %483 = torch.operator "onnx.Add"(%481, %482) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc482)
    %484 = torch.operator "onnx.Sqrt"(%483) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc483)
    %485 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.1_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc484)
    %486 = torch.operator "onnx.Div"(%485, %484) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc485)
    %487 = torch.operator "onnx.Mul"(%478, %486) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc486)
    %488 = torch.operator "onnx.Cast"(%487) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc487)
    %489 = torch.operator "onnx.Mul"(%6, %488) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc488)
    %490 = torch.operator "onnx.MatMul"(%489, %79) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc489)
    %491 = torch.operator "onnx.Sigmoid"(%490) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc490)
    %492 = torch.operator "onnx.Mul"(%490, %491) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc491)
    %493 = torch.operator "onnx.MatMul"(%489, %80) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc492)
    %494 = torch.operator "onnx.Mul"(%492, %493) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc493)
    %495 = torch.operator "onnx.MatMul"(%494, %81) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc494)
    %496 = torch.operator "onnx.Add"(%478, %495) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc495)
    %497 = torch.operator "onnx.Cast"(%496) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc496)
    %498 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc497)
    %499 = torch.operator "onnx.Pow"(%497, %498) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc498)
    %500 = torch.operator "onnx.ReduceMean"(%499) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc499)
    %501 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc500)
    %502 = torch.operator "onnx.Add"(%500, %501) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc501)
    %503 = torch.operator "onnx.Sqrt"(%502) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc502)
    %504 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc503)
    %505 = torch.operator "onnx.Div"(%504, %503) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc504)
    %506 = torch.operator "onnx.Mul"(%497, %505) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc505)
    %507 = torch.operator "onnx.Cast"(%506) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc506)
    %508 = torch.operator "onnx.Mul"(%7, %507) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc507)
    %509 = torch.operator "onnx.MatMul"(%508, %82) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc508)
    %510 = torch.operator "onnx.MatMul"(%508, %83) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc509)
    %511 = torch.operator "onnx.MatMul"(%508, %84) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc510)
    %512 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc511)
    %513 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc512)
    %514 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc513)
    %515 = torch.operator "onnx.Reshape"(%509, %512) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc514)
    %516 = torch.operator "onnx.Transpose"(%515) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc515)
    %517 = torch.operator "onnx.Reshape"(%510, %513) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc516)
    %518 = torch.operator "onnx.Transpose"(%517) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc517)
    %519 = torch.operator "onnx.Reshape"(%511, %514) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc518)
    %520 = torch.operator "onnx.Transpose"(%519) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc519)
    %521 = torch_c.to_builtin_tensor %520 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %522 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc520)
    %523 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc521)
    %524 = torch.operator "onnx.Gather"(%522, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc522)
    %525 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc523)
    %526 = torch.operator "onnx.Unsqueeze"(%524, %525) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc524)
    %527 = torch.operator "onnx.Gather"(%523, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc525)
    %528 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc526)
    %529 = torch.operator "onnx.Unsqueeze"(%527, %528) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc527)
    %530 = torch.operator "onnx.Mul"(%516, %526) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc528)
    %531 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc529)
    %532 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc530)
    %533 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc531)
    %534 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc532)
    %535 = torch.operator "onnx.Slice"(%516, %532, %533, %531, %534) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc533)
    %536 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc534)
    %537 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc535)
    %538 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc536)
    %539 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc537)
    %540 = torch.operator "onnx.Slice"(%516, %537, %538, %536, %539) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc538)
    %541 = torch.operator "onnx.Neg"(%540) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc539)
    %542 = torch.operator "onnx.Concat"(%541, %535) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc540)
    %543 = torch.operator "onnx.Mul"(%542, %529) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc541)
    %544 = torch.operator "onnx.Add"(%530, %543) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc542)
    %545 = torch.operator "onnx.Mul"(%518, %526) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc543)
    %546 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc544)
    %547 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc545)
    %548 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc546)
    %549 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc547)
    %550 = torch.operator "onnx.Slice"(%518, %547, %548, %546, %549) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc548)
    %551 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc549)
    %552 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc550)
    %553 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc551)
    %554 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc552)
    %555 = torch.operator "onnx.Slice"(%518, %552, %553, %551, %554) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc553)
    %556 = torch.operator "onnx.Neg"(%555) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc554)
    %557 = torch.operator "onnx.Concat"(%556, %550) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc555)
    %558 = torch.operator "onnx.Mul"(%557, %529) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc556)
    %559 = torch.operator "onnx.Add"(%545, %558) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc557)
    %560 = torch_c.to_builtin_tensor %559 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %561 = torch.operator "onnx.Transpose"(%559) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc558)
    %562 = torch.operator "onnx.MatMul"(%544, %561) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc559)
    %563 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc560)
    %564 = torch.operator "onnx.Div"(%562, %563) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc561)
    %565 = torch.operator "onnx.Add"(%564, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc562)
    %566 = torch.operator "onnx.Softmax"(%565) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc563)
    %567 = torch.operator "onnx.Cast"(%566) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc564)
    %568 = torch.operator "onnx.Cast"(%567) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc565)
    %569 = torch.operator "onnx.MatMul"(%568, %520) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc566)
    %570 = torch.operator "onnx.Transpose"(%569) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc567)
    %571 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc568)
    %572 = torch.operator "onnx.Reshape"(%570, %571) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc569)
    %573 = torch.operator "onnx.MatMul"(%572, %85) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc570)
    %574 = torch.operator "onnx.Add"(%497, %573) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc571)
    %575 = torch.operator "onnx.Cast"(%574) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc572)
    %576 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc573)
    %577 = torch.operator "onnx.Pow"(%575, %576) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc574)
    %578 = torch.operator "onnx.ReduceMean"(%577) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc575)
    %579 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc576)
    %580 = torch.operator "onnx.Add"(%578, %579) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc577)
    %581 = torch.operator "onnx.Sqrt"(%580) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc578)
    %582 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.2_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc579)
    %583 = torch.operator "onnx.Div"(%582, %581) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc580)
    %584 = torch.operator "onnx.Mul"(%575, %583) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc581)
    %585 = torch.operator "onnx.Cast"(%584) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc582)
    %586 = torch.operator "onnx.Mul"(%8, %585) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc583)
    %587 = torch.operator "onnx.MatMul"(%586, %86) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc584)
    %588 = torch.operator "onnx.Sigmoid"(%587) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc585)
    %589 = torch.operator "onnx.Mul"(%587, %588) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc586)
    %590 = torch.operator "onnx.MatMul"(%586, %87) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc587)
    %591 = torch.operator "onnx.Mul"(%589, %590) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc588)
    %592 = torch.operator "onnx.MatMul"(%591, %88) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc589)
    %593 = torch.operator "onnx.Add"(%575, %592) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc590)
    %594 = torch.operator "onnx.Cast"(%593) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc591)
    %595 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc592)
    %596 = torch.operator "onnx.Pow"(%594, %595) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc593)
    %597 = torch.operator "onnx.ReduceMean"(%596) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc594)
    %598 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc595)
    %599 = torch.operator "onnx.Add"(%597, %598) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc596)
    %600 = torch.operator "onnx.Sqrt"(%599) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc597)
    %601 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc598)
    %602 = torch.operator "onnx.Div"(%601, %600) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc599)
    %603 = torch.operator "onnx.Mul"(%594, %602) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc600)
    %604 = torch.operator "onnx.Cast"(%603) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc601)
    %605 = torch.operator "onnx.Mul"(%9, %604) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc602)
    %606 = torch.operator "onnx.MatMul"(%605, %89) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc603)
    %607 = torch.operator "onnx.MatMul"(%605, %90) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc604)
    %608 = torch.operator "onnx.MatMul"(%605, %91) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc605)
    %609 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc606)
    %610 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc607)
    %611 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc608)
    %612 = torch.operator "onnx.Reshape"(%606, %609) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc609)
    %613 = torch.operator "onnx.Transpose"(%612) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc610)
    %614 = torch.operator "onnx.Reshape"(%607, %610) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc611)
    %615 = torch.operator "onnx.Transpose"(%614) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc612)
    %616 = torch.operator "onnx.Reshape"(%608, %611) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc613)
    %617 = torch.operator "onnx.Transpose"(%616) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc614)
    %618 = torch_c.to_builtin_tensor %617 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %619 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc615)
    %620 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc616)
    %621 = torch.operator "onnx.Gather"(%619, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc617)
    %622 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc618)
    %623 = torch.operator "onnx.Unsqueeze"(%621, %622) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc619)
    %624 = torch.operator "onnx.Gather"(%620, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc620)
    %625 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc621)
    %626 = torch.operator "onnx.Unsqueeze"(%624, %625) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc622)
    %627 = torch.operator "onnx.Mul"(%613, %623) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc623)
    %628 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc624)
    %629 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc625)
    %630 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc626)
    %631 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc627)
    %632 = torch.operator "onnx.Slice"(%613, %629, %630, %628, %631) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc628)
    %633 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc629)
    %634 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc630)
    %635 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc631)
    %636 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc632)
    %637 = torch.operator "onnx.Slice"(%613, %634, %635, %633, %636) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc633)
    %638 = torch.operator "onnx.Neg"(%637) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc634)
    %639 = torch.operator "onnx.Concat"(%638, %632) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc635)
    %640 = torch.operator "onnx.Mul"(%639, %626) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc636)
    %641 = torch.operator "onnx.Add"(%627, %640) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc637)
    %642 = torch.operator "onnx.Mul"(%615, %623) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc638)
    %643 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc639)
    %644 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc640)
    %645 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc641)
    %646 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc642)
    %647 = torch.operator "onnx.Slice"(%615, %644, %645, %643, %646) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc643)
    %648 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc644)
    %649 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc645)
    %650 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc646)
    %651 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc647)
    %652 = torch.operator "onnx.Slice"(%615, %649, %650, %648, %651) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc648)
    %653 = torch.operator "onnx.Neg"(%652) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc649)
    %654 = torch.operator "onnx.Concat"(%653, %647) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc650)
    %655 = torch.operator "onnx.Mul"(%654, %626) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc651)
    %656 = torch.operator "onnx.Add"(%642, %655) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc652)
    %657 = torch_c.to_builtin_tensor %656 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %658 = torch.operator "onnx.Transpose"(%656) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc653)
    %659 = torch.operator "onnx.MatMul"(%641, %658) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc654)
    %660 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc655)
    %661 = torch.operator "onnx.Div"(%659, %660) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc656)
    %662 = torch.operator "onnx.Add"(%661, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc657)
    %663 = torch.operator "onnx.Softmax"(%662) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc658)
    %664 = torch.operator "onnx.Cast"(%663) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc659)
    %665 = torch.operator "onnx.Cast"(%664) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc660)
    %666 = torch.operator "onnx.MatMul"(%665, %617) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc661)
    %667 = torch.operator "onnx.Transpose"(%666) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc662)
    %668 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc663)
    %669 = torch.operator "onnx.Reshape"(%667, %668) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc664)
    %670 = torch.operator "onnx.MatMul"(%669, %92) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc665)
    %671 = torch.operator "onnx.Add"(%594, %670) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc666)
    %672 = torch.operator "onnx.Cast"(%671) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc667)
    %673 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc668)
    %674 = torch.operator "onnx.Pow"(%672, %673) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc669)
    %675 = torch.operator "onnx.ReduceMean"(%674) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc670)
    %676 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc671)
    %677 = torch.operator "onnx.Add"(%675, %676) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc672)
    %678 = torch.operator "onnx.Sqrt"(%677) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc673)
    %679 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.3_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc674)
    %680 = torch.operator "onnx.Div"(%679, %678) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc675)
    %681 = torch.operator "onnx.Mul"(%672, %680) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc676)
    %682 = torch.operator "onnx.Cast"(%681) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc677)
    %683 = torch.operator "onnx.Mul"(%10, %682) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc678)
    %684 = torch.operator "onnx.MatMul"(%683, %93) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc679)
    %685 = torch.operator "onnx.Sigmoid"(%684) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc680)
    %686 = torch.operator "onnx.Mul"(%684, %685) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc681)
    %687 = torch.operator "onnx.MatMul"(%683, %94) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc682)
    %688 = torch.operator "onnx.Mul"(%686, %687) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc683)
    %689 = torch.operator "onnx.MatMul"(%688, %95) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc684)
    %690 = torch.operator "onnx.Add"(%672, %689) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc685)
    %691 = torch.operator "onnx.Cast"(%690) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc686)
    %692 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc687)
    %693 = torch.operator "onnx.Pow"(%691, %692) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc688)
    %694 = torch.operator "onnx.ReduceMean"(%693) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc689)
    %695 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc690)
    %696 = torch.operator "onnx.Add"(%694, %695) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc691)
    %697 = torch.operator "onnx.Sqrt"(%696) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc692)
    %698 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc693)
    %699 = torch.operator "onnx.Div"(%698, %697) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc694)
    %700 = torch.operator "onnx.Mul"(%691, %699) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc695)
    %701 = torch.operator "onnx.Cast"(%700) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc696)
    %702 = torch.operator "onnx.Mul"(%11, %701) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc697)
    %703 = torch.operator "onnx.MatMul"(%702, %96) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc698)
    %704 = torch.operator "onnx.MatMul"(%702, %97) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc699)
    %705 = torch.operator "onnx.MatMul"(%702, %98) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc700)
    %706 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc701)
    %707 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc702)
    %708 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc703)
    %709 = torch.operator "onnx.Reshape"(%703, %706) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc704)
    %710 = torch.operator "onnx.Transpose"(%709) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc705)
    %711 = torch.operator "onnx.Reshape"(%704, %707) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc706)
    %712 = torch.operator "onnx.Transpose"(%711) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc707)
    %713 = torch.operator "onnx.Reshape"(%705, %708) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc708)
    %714 = torch.operator "onnx.Transpose"(%713) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc709)
    %715 = torch_c.to_builtin_tensor %714 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %716 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc710)
    %717 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc711)
    %718 = torch.operator "onnx.Gather"(%716, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc712)
    %719 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc713)
    %720 = torch.operator "onnx.Unsqueeze"(%718, %719) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc714)
    %721 = torch.operator "onnx.Gather"(%717, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc715)
    %722 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc716)
    %723 = torch.operator "onnx.Unsqueeze"(%721, %722) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc717)
    %724 = torch.operator "onnx.Mul"(%710, %720) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc718)
    %725 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc719)
    %726 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc720)
    %727 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc721)
    %728 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc722)
    %729 = torch.operator "onnx.Slice"(%710, %726, %727, %725, %728) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc723)
    %730 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc724)
    %731 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc725)
    %732 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc726)
    %733 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc727)
    %734 = torch.operator "onnx.Slice"(%710, %731, %732, %730, %733) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc728)
    %735 = torch.operator "onnx.Neg"(%734) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc729)
    %736 = torch.operator "onnx.Concat"(%735, %729) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc730)
    %737 = torch.operator "onnx.Mul"(%736, %723) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc731)
    %738 = torch.operator "onnx.Add"(%724, %737) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc732)
    %739 = torch.operator "onnx.Mul"(%712, %720) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc733)
    %740 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc734)
    %741 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc735)
    %742 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc736)
    %743 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc737)
    %744 = torch.operator "onnx.Slice"(%712, %741, %742, %740, %743) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc738)
    %745 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc739)
    %746 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc740)
    %747 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc741)
    %748 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc742)
    %749 = torch.operator "onnx.Slice"(%712, %746, %747, %745, %748) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc743)
    %750 = torch.operator "onnx.Neg"(%749) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc744)
    %751 = torch.operator "onnx.Concat"(%750, %744) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc745)
    %752 = torch.operator "onnx.Mul"(%751, %723) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc746)
    %753 = torch.operator "onnx.Add"(%739, %752) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc747)
    %754 = torch_c.to_builtin_tensor %753 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %755 = torch.operator "onnx.Transpose"(%753) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc748)
    %756 = torch.operator "onnx.MatMul"(%738, %755) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc749)
    %757 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc750)
    %758 = torch.operator "onnx.Div"(%756, %757) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc751)
    %759 = torch.operator "onnx.Add"(%758, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc752)
    %760 = torch.operator "onnx.Softmax"(%759) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc753)
    %761 = torch.operator "onnx.Cast"(%760) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc754)
    %762 = torch.operator "onnx.Cast"(%761) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc755)
    %763 = torch.operator "onnx.MatMul"(%762, %714) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc756)
    %764 = torch.operator "onnx.Transpose"(%763) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc757)
    %765 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc758)
    %766 = torch.operator "onnx.Reshape"(%764, %765) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc759)
    %767 = torch.operator "onnx.MatMul"(%766, %99) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc760)
    %768 = torch.operator "onnx.Add"(%691, %767) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc761)
    %769 = torch.operator "onnx.Cast"(%768) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc762)
    %770 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc763)
    %771 = torch.operator "onnx.Pow"(%769, %770) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc764)
    %772 = torch.operator "onnx.ReduceMean"(%771) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc765)
    %773 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc766)
    %774 = torch.operator "onnx.Add"(%772, %773) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc767)
    %775 = torch.operator "onnx.Sqrt"(%774) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc768)
    %776 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.4_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc769)
    %777 = torch.operator "onnx.Div"(%776, %775) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc770)
    %778 = torch.operator "onnx.Mul"(%769, %777) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc771)
    %779 = torch.operator "onnx.Cast"(%778) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc772)
    %780 = torch.operator "onnx.Mul"(%12, %779) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc773)
    %781 = torch.operator "onnx.MatMul"(%780, %100) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc774)
    %782 = torch.operator "onnx.Sigmoid"(%781) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc775)
    %783 = torch.operator "onnx.Mul"(%781, %782) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc776)
    %784 = torch.operator "onnx.MatMul"(%780, %101) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc777)
    %785 = torch.operator "onnx.Mul"(%783, %784) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc778)
    %786 = torch.operator "onnx.MatMul"(%785, %102) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc779)
    %787 = torch.operator "onnx.Add"(%769, %786) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc780)
    %788 = torch.operator "onnx.Cast"(%787) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc781)
    %789 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc782)
    %790 = torch.operator "onnx.Pow"(%788, %789) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc783)
    %791 = torch.operator "onnx.ReduceMean"(%790) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc784)
    %792 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc785)
    %793 = torch.operator "onnx.Add"(%791, %792) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc786)
    %794 = torch.operator "onnx.Sqrt"(%793) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc787)
    %795 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc788)
    %796 = torch.operator "onnx.Div"(%795, %794) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc789)
    %797 = torch.operator "onnx.Mul"(%788, %796) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc790)
    %798 = torch.operator "onnx.Cast"(%797) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc791)
    %799 = torch.operator "onnx.Mul"(%13, %798) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc792)
    %800 = torch.operator "onnx.MatMul"(%799, %103) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc793)
    %801 = torch.operator "onnx.MatMul"(%799, %104) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc794)
    %802 = torch.operator "onnx.MatMul"(%799, %105) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc795)
    %803 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc796)
    %804 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc797)
    %805 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc798)
    %806 = torch.operator "onnx.Reshape"(%800, %803) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc799)
    %807 = torch.operator "onnx.Transpose"(%806) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc800)
    %808 = torch.operator "onnx.Reshape"(%801, %804) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc801)
    %809 = torch.operator "onnx.Transpose"(%808) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc802)
    %810 = torch.operator "onnx.Reshape"(%802, %805) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc803)
    %811 = torch.operator "onnx.Transpose"(%810) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc804)
    %812 = torch_c.to_builtin_tensor %811 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %813 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc805)
    %814 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc806)
    %815 = torch.operator "onnx.Gather"(%813, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc807)
    %816 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc808)
    %817 = torch.operator "onnx.Unsqueeze"(%815, %816) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc809)
    %818 = torch.operator "onnx.Gather"(%814, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc810)
    %819 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc811)
    %820 = torch.operator "onnx.Unsqueeze"(%818, %819) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc812)
    %821 = torch.operator "onnx.Mul"(%807, %817) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc813)
    %822 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc814)
    %823 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc815)
    %824 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc816)
    %825 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc817)
    %826 = torch.operator "onnx.Slice"(%807, %823, %824, %822, %825) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc818)
    %827 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc819)
    %828 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc820)
    %829 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc821)
    %830 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc822)
    %831 = torch.operator "onnx.Slice"(%807, %828, %829, %827, %830) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc823)
    %832 = torch.operator "onnx.Neg"(%831) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc824)
    %833 = torch.operator "onnx.Concat"(%832, %826) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc825)
    %834 = torch.operator "onnx.Mul"(%833, %820) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc826)
    %835 = torch.operator "onnx.Add"(%821, %834) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc827)
    %836 = torch.operator "onnx.Mul"(%809, %817) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc828)
    %837 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc829)
    %838 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc830)
    %839 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc831)
    %840 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc832)
    %841 = torch.operator "onnx.Slice"(%809, %838, %839, %837, %840) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc833)
    %842 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc834)
    %843 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc835)
    %844 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc836)
    %845 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc837)
    %846 = torch.operator "onnx.Slice"(%809, %843, %844, %842, %845) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc838)
    %847 = torch.operator "onnx.Neg"(%846) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc839)
    %848 = torch.operator "onnx.Concat"(%847, %841) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc840)
    %849 = torch.operator "onnx.Mul"(%848, %820) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc841)
    %850 = torch.operator "onnx.Add"(%836, %849) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc842)
    %851 = torch_c.to_builtin_tensor %850 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %852 = torch.operator "onnx.Transpose"(%850) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc843)
    %853 = torch.operator "onnx.MatMul"(%835, %852) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc844)
    %854 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc845)
    %855 = torch.operator "onnx.Div"(%853, %854) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc846)
    %856 = torch.operator "onnx.Add"(%855, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc847)
    %857 = torch.operator "onnx.Softmax"(%856) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc848)
    %858 = torch.operator "onnx.Cast"(%857) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc849)
    %859 = torch.operator "onnx.Cast"(%858) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc850)
    %860 = torch.operator "onnx.MatMul"(%859, %811) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc851)
    %861 = torch.operator "onnx.Transpose"(%860) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc852)
    %862 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc853)
    %863 = torch.operator "onnx.Reshape"(%861, %862) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc854)
    %864 = torch.operator "onnx.MatMul"(%863, %106) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc855)
    %865 = torch.operator "onnx.Add"(%788, %864) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc856)
    %866 = torch.operator "onnx.Cast"(%865) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc857)
    %867 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc858)
    %868 = torch.operator "onnx.Pow"(%866, %867) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc859)
    %869 = torch.operator "onnx.ReduceMean"(%868) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc860)
    %870 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc861)
    %871 = torch.operator "onnx.Add"(%869, %870) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc862)
    %872 = torch.operator "onnx.Sqrt"(%871) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc863)
    %873 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.5_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc864)
    %874 = torch.operator "onnx.Div"(%873, %872) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc865)
    %875 = torch.operator "onnx.Mul"(%866, %874) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc866)
    %876 = torch.operator "onnx.Cast"(%875) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc867)
    %877 = torch.operator "onnx.Mul"(%14, %876) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc868)
    %878 = torch.operator "onnx.MatMul"(%877, %107) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc869)
    %879 = torch.operator "onnx.Sigmoid"(%878) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc870)
    %880 = torch.operator "onnx.Mul"(%878, %879) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc871)
    %881 = torch.operator "onnx.MatMul"(%877, %108) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc872)
    %882 = torch.operator "onnx.Mul"(%880, %881) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc873)
    %883 = torch.operator "onnx.MatMul"(%882, %109) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc874)
    %884 = torch.operator "onnx.Add"(%866, %883) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc875)
    %885 = torch.operator "onnx.Cast"(%884) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc876)
    %886 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc877)
    %887 = torch.operator "onnx.Pow"(%885, %886) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc878)
    %888 = torch.operator "onnx.ReduceMean"(%887) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc879)
    %889 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc880)
    %890 = torch.operator "onnx.Add"(%888, %889) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc881)
    %891 = torch.operator "onnx.Sqrt"(%890) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc882)
    %892 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc883)
    %893 = torch.operator "onnx.Div"(%892, %891) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc884)
    %894 = torch.operator "onnx.Mul"(%885, %893) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc885)
    %895 = torch.operator "onnx.Cast"(%894) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc886)
    %896 = torch.operator "onnx.Mul"(%15, %895) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc887)
    %897 = torch.operator "onnx.MatMul"(%896, %110) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc888)
    %898 = torch.operator "onnx.MatMul"(%896, %111) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc889)
    %899 = torch.operator "onnx.MatMul"(%896, %112) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc890)
    %900 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc891)
    %901 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc892)
    %902 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc893)
    %903 = torch.operator "onnx.Reshape"(%897, %900) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc894)
    %904 = torch.operator "onnx.Transpose"(%903) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc895)
    %905 = torch.operator "onnx.Reshape"(%898, %901) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc896)
    %906 = torch.operator "onnx.Transpose"(%905) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc897)
    %907 = torch.operator "onnx.Reshape"(%899, %902) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc898)
    %908 = torch.operator "onnx.Transpose"(%907) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc899)
    %909 = torch_c.to_builtin_tensor %908 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %910 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc900)
    %911 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc901)
    %912 = torch.operator "onnx.Gather"(%910, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc902)
    %913 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc903)
    %914 = torch.operator "onnx.Unsqueeze"(%912, %913) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc904)
    %915 = torch.operator "onnx.Gather"(%911, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc905)
    %916 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc906)
    %917 = torch.operator "onnx.Unsqueeze"(%915, %916) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc907)
    %918 = torch.operator "onnx.Mul"(%904, %914) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc908)
    %919 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc909)
    %920 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc910)
    %921 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc911)
    %922 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc912)
    %923 = torch.operator "onnx.Slice"(%904, %920, %921, %919, %922) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc913)
    %924 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc914)
    %925 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc915)
    %926 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc916)
    %927 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc917)
    %928 = torch.operator "onnx.Slice"(%904, %925, %926, %924, %927) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc918)
    %929 = torch.operator "onnx.Neg"(%928) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc919)
    %930 = torch.operator "onnx.Concat"(%929, %923) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc920)
    %931 = torch.operator "onnx.Mul"(%930, %917) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc921)
    %932 = torch.operator "onnx.Add"(%918, %931) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc922)
    %933 = torch.operator "onnx.Mul"(%906, %914) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc923)
    %934 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc924)
    %935 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc925)
    %936 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc926)
    %937 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc927)
    %938 = torch.operator "onnx.Slice"(%906, %935, %936, %934, %937) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc928)
    %939 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc929)
    %940 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc930)
    %941 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc931)
    %942 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc932)
    %943 = torch.operator "onnx.Slice"(%906, %940, %941, %939, %942) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc933)
    %944 = torch.operator "onnx.Neg"(%943) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc934)
    %945 = torch.operator "onnx.Concat"(%944, %938) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc935)
    %946 = torch.operator "onnx.Mul"(%945, %917) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc936)
    %947 = torch.operator "onnx.Add"(%933, %946) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc937)
    %948 = torch_c.to_builtin_tensor %947 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %949 = torch.operator "onnx.Transpose"(%947) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc938)
    %950 = torch.operator "onnx.MatMul"(%932, %949) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc939)
    %951 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc940)
    %952 = torch.operator "onnx.Div"(%950, %951) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc941)
    %953 = torch.operator "onnx.Add"(%952, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc942)
    %954 = torch.operator "onnx.Softmax"(%953) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc943)
    %955 = torch.operator "onnx.Cast"(%954) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc944)
    %956 = torch.operator "onnx.Cast"(%955) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc945)
    %957 = torch.operator "onnx.MatMul"(%956, %908) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc946)
    %958 = torch.operator "onnx.Transpose"(%957) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc947)
    %959 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc948)
    %960 = torch.operator "onnx.Reshape"(%958, %959) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc949)
    %961 = torch.operator "onnx.MatMul"(%960, %113) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc950)
    %962 = torch.operator "onnx.Add"(%885, %961) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc951)
    %963 = torch.operator "onnx.Cast"(%962) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc952)
    %964 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc953)
    %965 = torch.operator "onnx.Pow"(%963, %964) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc954)
    %966 = torch.operator "onnx.ReduceMean"(%965) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc955)
    %967 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc956)
    %968 = torch.operator "onnx.Add"(%966, %967) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc957)
    %969 = torch.operator "onnx.Sqrt"(%968) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc958)
    %970 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.6_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc959)
    %971 = torch.operator "onnx.Div"(%970, %969) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc960)
    %972 = torch.operator "onnx.Mul"(%963, %971) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc961)
    %973 = torch.operator "onnx.Cast"(%972) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc962)
    %974 = torch.operator "onnx.Mul"(%16, %973) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc963)
    %975 = torch.operator "onnx.MatMul"(%974, %114) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc964)
    %976 = torch.operator "onnx.Sigmoid"(%975) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc965)
    %977 = torch.operator "onnx.Mul"(%975, %976) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc966)
    %978 = torch.operator "onnx.MatMul"(%974, %115) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc967)
    %979 = torch.operator "onnx.Mul"(%977, %978) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc968)
    %980 = torch.operator "onnx.MatMul"(%979, %116) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc969)
    %981 = torch.operator "onnx.Add"(%963, %980) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc970)
    %982 = torch.operator "onnx.Cast"(%981) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc971)
    %983 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc972)
    %984 = torch.operator "onnx.Pow"(%982, %983) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc973)
    %985 = torch.operator "onnx.ReduceMean"(%984) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc974)
    %986 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc975)
    %987 = torch.operator "onnx.Add"(%985, %986) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc976)
    %988 = torch.operator "onnx.Sqrt"(%987) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc977)
    %989 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc978)
    %990 = torch.operator "onnx.Div"(%989, %988) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc979)
    %991 = torch.operator "onnx.Mul"(%982, %990) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc980)
    %992 = torch.operator "onnx.Cast"(%991) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc981)
    %993 = torch.operator "onnx.Mul"(%17, %992) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc982)
    %994 = torch.operator "onnx.MatMul"(%993, %117) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc983)
    %995 = torch.operator "onnx.MatMul"(%993, %118) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc984)
    %996 = torch.operator "onnx.MatMul"(%993, %119) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc985)
    %997 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc986)
    %998 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc987)
    %999 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc988)
    %1000 = torch.operator "onnx.Reshape"(%994, %997) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc989)
    %1001 = torch.operator "onnx.Transpose"(%1000) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc990)
    %1002 = torch.operator "onnx.Reshape"(%995, %998) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc991)
    %1003 = torch.operator "onnx.Transpose"(%1002) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc992)
    %1004 = torch.operator "onnx.Reshape"(%996, %999) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc993)
    %1005 = torch.operator "onnx.Transpose"(%1004) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc994)
    %1006 = torch_c.to_builtin_tensor %1005 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1007 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc995)
    %1008 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc996)
    %1009 = torch.operator "onnx.Gather"(%1007, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc997)
    %1010 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc998)
    %1011 = torch.operator "onnx.Unsqueeze"(%1009, %1010) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc999)
    %1012 = torch.operator "onnx.Gather"(%1008, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1000)
    %1013 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1001)
    %1014 = torch.operator "onnx.Unsqueeze"(%1012, %1013) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1002)
    %1015 = torch.operator "onnx.Mul"(%1001, %1011) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1003)
    %1016 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1004)
    %1017 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1005)
    %1018 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1006)
    %1019 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1007)
    %1020 = torch.operator "onnx.Slice"(%1001, %1017, %1018, %1016, %1019) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1008)
    %1021 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1009)
    %1022 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1010)
    %1023 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1011)
    %1024 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1012)
    %1025 = torch.operator "onnx.Slice"(%1001, %1022, %1023, %1021, %1024) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1013)
    %1026 = torch.operator "onnx.Neg"(%1025) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1014)
    %1027 = torch.operator "onnx.Concat"(%1026, %1020) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1015)
    %1028 = torch.operator "onnx.Mul"(%1027, %1014) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1016)
    %1029 = torch.operator "onnx.Add"(%1015, %1028) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1017)
    %1030 = torch.operator "onnx.Mul"(%1003, %1011) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1018)
    %1031 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1019)
    %1032 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1020)
    %1033 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1021)
    %1034 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1022)
    %1035 = torch.operator "onnx.Slice"(%1003, %1032, %1033, %1031, %1034) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1023)
    %1036 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1024)
    %1037 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1025)
    %1038 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1026)
    %1039 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1027)
    %1040 = torch.operator "onnx.Slice"(%1003, %1037, %1038, %1036, %1039) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1028)
    %1041 = torch.operator "onnx.Neg"(%1040) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1029)
    %1042 = torch.operator "onnx.Concat"(%1041, %1035) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1030)
    %1043 = torch.operator "onnx.Mul"(%1042, %1014) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1031)
    %1044 = torch.operator "onnx.Add"(%1030, %1043) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1032)
    %1045 = torch_c.to_builtin_tensor %1044 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1046 = torch.operator "onnx.Transpose"(%1044) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1033)
    %1047 = torch.operator "onnx.MatMul"(%1029, %1046) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1034)
    %1048 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1035)
    %1049 = torch.operator "onnx.Div"(%1047, %1048) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1036)
    %1050 = torch.operator "onnx.Add"(%1049, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1037)
    %1051 = torch.operator "onnx.Softmax"(%1050) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1038)
    %1052 = torch.operator "onnx.Cast"(%1051) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1039)
    %1053 = torch.operator "onnx.Cast"(%1052) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1040)
    %1054 = torch.operator "onnx.MatMul"(%1053, %1005) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1041)
    %1055 = torch.operator "onnx.Transpose"(%1054) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1042)
    %1056 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1043)
    %1057 = torch.operator "onnx.Reshape"(%1055, %1056) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1044)
    %1058 = torch.operator "onnx.MatMul"(%1057, %120) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1045)
    %1059 = torch.operator "onnx.Add"(%982, %1058) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1046)
    %1060 = torch.operator "onnx.Cast"(%1059) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1047)
    %1061 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1048)
    %1062 = torch.operator "onnx.Pow"(%1060, %1061) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1049)
    %1063 = torch.operator "onnx.ReduceMean"(%1062) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1050)
    %1064 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1051)
    %1065 = torch.operator "onnx.Add"(%1063, %1064) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1052)
    %1066 = torch.operator "onnx.Sqrt"(%1065) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1053)
    %1067 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.7_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1054)
    %1068 = torch.operator "onnx.Div"(%1067, %1066) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1055)
    %1069 = torch.operator "onnx.Mul"(%1060, %1068) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1056)
    %1070 = torch.operator "onnx.Cast"(%1069) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1057)
    %1071 = torch.operator "onnx.Mul"(%18, %1070) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1058)
    %1072 = torch.operator "onnx.MatMul"(%1071, %121) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1059)
    %1073 = torch.operator "onnx.Sigmoid"(%1072) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1060)
    %1074 = torch.operator "onnx.Mul"(%1072, %1073) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1061)
    %1075 = torch.operator "onnx.MatMul"(%1071, %122) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1062)
    %1076 = torch.operator "onnx.Mul"(%1074, %1075) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1063)
    %1077 = torch.operator "onnx.MatMul"(%1076, %123) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1064)
    %1078 = torch.operator "onnx.Add"(%1060, %1077) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1065)
    %1079 = torch.operator "onnx.Cast"(%1078) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1066)
    %1080 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1067)
    %1081 = torch.operator "onnx.Pow"(%1079, %1080) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1068)
    %1082 = torch.operator "onnx.ReduceMean"(%1081) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1069)
    %1083 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1070)
    %1084 = torch.operator "onnx.Add"(%1082, %1083) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1071)
    %1085 = torch.operator "onnx.Sqrt"(%1084) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1072)
    %1086 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1073)
    %1087 = torch.operator "onnx.Div"(%1086, %1085) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1074)
    %1088 = torch.operator "onnx.Mul"(%1079, %1087) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1075)
    %1089 = torch.operator "onnx.Cast"(%1088) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1076)
    %1090 = torch.operator "onnx.Mul"(%19, %1089) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1077)
    %1091 = torch.operator "onnx.MatMul"(%1090, %124) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1078)
    %1092 = torch.operator "onnx.MatMul"(%1090, %125) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1079)
    %1093 = torch.operator "onnx.MatMul"(%1090, %126) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1080)
    %1094 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1081)
    %1095 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1082)
    %1096 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1083)
    %1097 = torch.operator "onnx.Reshape"(%1091, %1094) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1084)
    %1098 = torch.operator "onnx.Transpose"(%1097) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1085)
    %1099 = torch.operator "onnx.Reshape"(%1092, %1095) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1086)
    %1100 = torch.operator "onnx.Transpose"(%1099) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1087)
    %1101 = torch.operator "onnx.Reshape"(%1093, %1096) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1088)
    %1102 = torch.operator "onnx.Transpose"(%1101) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1089)
    %1103 = torch_c.to_builtin_tensor %1102 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1104 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1090)
    %1105 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1091)
    %1106 = torch.operator "onnx.Gather"(%1104, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1092)
    %1107 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1093)
    %1108 = torch.operator "onnx.Unsqueeze"(%1106, %1107) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1094)
    %1109 = torch.operator "onnx.Gather"(%1105, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1095)
    %1110 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1096)
    %1111 = torch.operator "onnx.Unsqueeze"(%1109, %1110) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1097)
    %1112 = torch.operator "onnx.Mul"(%1098, %1108) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1098)
    %1113 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1099)
    %1114 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1100)
    %1115 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1101)
    %1116 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1102)
    %1117 = torch.operator "onnx.Slice"(%1098, %1114, %1115, %1113, %1116) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1103)
    %1118 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1104)
    %1119 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1105)
    %1120 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1106)
    %1121 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1107)
    %1122 = torch.operator "onnx.Slice"(%1098, %1119, %1120, %1118, %1121) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1108)
    %1123 = torch.operator "onnx.Neg"(%1122) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1109)
    %1124 = torch.operator "onnx.Concat"(%1123, %1117) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1110)
    %1125 = torch.operator "onnx.Mul"(%1124, %1111) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1111)
    %1126 = torch.operator "onnx.Add"(%1112, %1125) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1112)
    %1127 = torch.operator "onnx.Mul"(%1100, %1108) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1113)
    %1128 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1114)
    %1129 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1115)
    %1130 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1116)
    %1131 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1117)
    %1132 = torch.operator "onnx.Slice"(%1100, %1129, %1130, %1128, %1131) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1118)
    %1133 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1119)
    %1134 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1120)
    %1135 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1121)
    %1136 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1122)
    %1137 = torch.operator "onnx.Slice"(%1100, %1134, %1135, %1133, %1136) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1123)
    %1138 = torch.operator "onnx.Neg"(%1137) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1124)
    %1139 = torch.operator "onnx.Concat"(%1138, %1132) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1125)
    %1140 = torch.operator "onnx.Mul"(%1139, %1111) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1126)
    %1141 = torch.operator "onnx.Add"(%1127, %1140) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1127)
    %1142 = torch_c.to_builtin_tensor %1141 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1143 = torch.operator "onnx.Transpose"(%1141) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1128)
    %1144 = torch.operator "onnx.MatMul"(%1126, %1143) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1129)
    %1145 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1130)
    %1146 = torch.operator "onnx.Div"(%1144, %1145) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1131)
    %1147 = torch.operator "onnx.Add"(%1146, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1132)
    %1148 = torch.operator "onnx.Softmax"(%1147) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1133)
    %1149 = torch.operator "onnx.Cast"(%1148) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1134)
    %1150 = torch.operator "onnx.Cast"(%1149) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1135)
    %1151 = torch.operator "onnx.MatMul"(%1150, %1102) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1136)
    %1152 = torch.operator "onnx.Transpose"(%1151) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1137)
    %1153 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1138)
    %1154 = torch.operator "onnx.Reshape"(%1152, %1153) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1139)
    %1155 = torch.operator "onnx.MatMul"(%1154, %127) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1140)
    %1156 = torch.operator "onnx.Add"(%1079, %1155) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1141)
    %1157 = torch.operator "onnx.Cast"(%1156) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1142)
    %1158 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1143)
    %1159 = torch.operator "onnx.Pow"(%1157, %1158) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1144)
    %1160 = torch.operator "onnx.ReduceMean"(%1159) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1145)
    %1161 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1146)
    %1162 = torch.operator "onnx.Add"(%1160, %1161) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1147)
    %1163 = torch.operator "onnx.Sqrt"(%1162) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1148)
    %1164 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.8_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1149)
    %1165 = torch.operator "onnx.Div"(%1164, %1163) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1150)
    %1166 = torch.operator "onnx.Mul"(%1157, %1165) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1151)
    %1167 = torch.operator "onnx.Cast"(%1166) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1152)
    %1168 = torch.operator "onnx.Mul"(%20, %1167) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1153)
    %1169 = torch.operator "onnx.MatMul"(%1168, %128) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1154)
    %1170 = torch.operator "onnx.Sigmoid"(%1169) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1155)
    %1171 = torch.operator "onnx.Mul"(%1169, %1170) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1156)
    %1172 = torch.operator "onnx.MatMul"(%1168, %129) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1157)
    %1173 = torch.operator "onnx.Mul"(%1171, %1172) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1158)
    %1174 = torch.operator "onnx.MatMul"(%1173, %130) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1159)
    %1175 = torch.operator "onnx.Add"(%1157, %1174) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1160)
    %1176 = torch.operator "onnx.Cast"(%1175) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1161)
    %1177 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1162)
    %1178 = torch.operator "onnx.Pow"(%1176, %1177) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1163)
    %1179 = torch.operator "onnx.ReduceMean"(%1178) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1164)
    %1180 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1165)
    %1181 = torch.operator "onnx.Add"(%1179, %1180) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1166)
    %1182 = torch.operator "onnx.Sqrt"(%1181) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1167)
    %1183 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1168)
    %1184 = torch.operator "onnx.Div"(%1183, %1182) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1169)
    %1185 = torch.operator "onnx.Mul"(%1176, %1184) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1170)
    %1186 = torch.operator "onnx.Cast"(%1185) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1171)
    %1187 = torch.operator "onnx.Mul"(%21, %1186) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1172)
    %1188 = torch.operator "onnx.MatMul"(%1187, %131) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1173)
    %1189 = torch.operator "onnx.MatMul"(%1187, %132) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1174)
    %1190 = torch.operator "onnx.MatMul"(%1187, %133) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1175)
    %1191 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1176)
    %1192 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1177)
    %1193 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1178)
    %1194 = torch.operator "onnx.Reshape"(%1188, %1191) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1179)
    %1195 = torch.operator "onnx.Transpose"(%1194) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1180)
    %1196 = torch.operator "onnx.Reshape"(%1189, %1192) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1181)
    %1197 = torch.operator "onnx.Transpose"(%1196) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1182)
    %1198 = torch.operator "onnx.Reshape"(%1190, %1193) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1183)
    %1199 = torch.operator "onnx.Transpose"(%1198) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1184)
    %1200 = torch_c.to_builtin_tensor %1199 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1201 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1185)
    %1202 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1186)
    %1203 = torch.operator "onnx.Gather"(%1201, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1187)
    %1204 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1188)
    %1205 = torch.operator "onnx.Unsqueeze"(%1203, %1204) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1189)
    %1206 = torch.operator "onnx.Gather"(%1202, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1190)
    %1207 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1191)
    %1208 = torch.operator "onnx.Unsqueeze"(%1206, %1207) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1192)
    %1209 = torch.operator "onnx.Mul"(%1195, %1205) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1193)
    %1210 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1194)
    %1211 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1195)
    %1212 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1196)
    %1213 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1197)
    %1214 = torch.operator "onnx.Slice"(%1195, %1211, %1212, %1210, %1213) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1198)
    %1215 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1199)
    %1216 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1200)
    %1217 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1201)
    %1218 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1202)
    %1219 = torch.operator "onnx.Slice"(%1195, %1216, %1217, %1215, %1218) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1203)
    %1220 = torch.operator "onnx.Neg"(%1219) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1204)
    %1221 = torch.operator "onnx.Concat"(%1220, %1214) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1205)
    %1222 = torch.operator "onnx.Mul"(%1221, %1208) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1206)
    %1223 = torch.operator "onnx.Add"(%1209, %1222) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1207)
    %1224 = torch.operator "onnx.Mul"(%1197, %1205) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1208)
    %1225 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1209)
    %1226 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1210)
    %1227 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1211)
    %1228 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1212)
    %1229 = torch.operator "onnx.Slice"(%1197, %1226, %1227, %1225, %1228) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1213)
    %1230 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1214)
    %1231 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1215)
    %1232 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1216)
    %1233 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1217)
    %1234 = torch.operator "onnx.Slice"(%1197, %1231, %1232, %1230, %1233) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1218)
    %1235 = torch.operator "onnx.Neg"(%1234) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1219)
    %1236 = torch.operator "onnx.Concat"(%1235, %1229) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1220)
    %1237 = torch.operator "onnx.Mul"(%1236, %1208) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1221)
    %1238 = torch.operator "onnx.Add"(%1224, %1237) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1222)
    %1239 = torch_c.to_builtin_tensor %1238 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1240 = torch.operator "onnx.Transpose"(%1238) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1223)
    %1241 = torch.operator "onnx.MatMul"(%1223, %1240) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1224)
    %1242 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1225)
    %1243 = torch.operator "onnx.Div"(%1241, %1242) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1226)
    %1244 = torch.operator "onnx.Add"(%1243, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1227)
    %1245 = torch.operator "onnx.Softmax"(%1244) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1228)
    %1246 = torch.operator "onnx.Cast"(%1245) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1229)
    %1247 = torch.operator "onnx.Cast"(%1246) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1230)
    %1248 = torch.operator "onnx.MatMul"(%1247, %1199) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1231)
    %1249 = torch.operator "onnx.Transpose"(%1248) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1232)
    %1250 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1233)
    %1251 = torch.operator "onnx.Reshape"(%1249, %1250) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1234)
    %1252 = torch.operator "onnx.MatMul"(%1251, %134) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1235)
    %1253 = torch.operator "onnx.Add"(%1176, %1252) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1236)
    %1254 = torch.operator "onnx.Cast"(%1253) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1237)
    %1255 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1238)
    %1256 = torch.operator "onnx.Pow"(%1254, %1255) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1239)
    %1257 = torch.operator "onnx.ReduceMean"(%1256) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1240)
    %1258 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1241)
    %1259 = torch.operator "onnx.Add"(%1257, %1258) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1242)
    %1260 = torch.operator "onnx.Sqrt"(%1259) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1243)
    %1261 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.9_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1244)
    %1262 = torch.operator "onnx.Div"(%1261, %1260) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1245)
    %1263 = torch.operator "onnx.Mul"(%1254, %1262) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1246)
    %1264 = torch.operator "onnx.Cast"(%1263) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1247)
    %1265 = torch.operator "onnx.Mul"(%22, %1264) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1248)
    %1266 = torch.operator "onnx.MatMul"(%1265, %135) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1249)
    %1267 = torch.operator "onnx.Sigmoid"(%1266) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1250)
    %1268 = torch.operator "onnx.Mul"(%1266, %1267) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1251)
    %1269 = torch.operator "onnx.MatMul"(%1265, %136) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1252)
    %1270 = torch.operator "onnx.Mul"(%1268, %1269) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1253)
    %1271 = torch.operator "onnx.MatMul"(%1270, %137) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1254)
    %1272 = torch.operator "onnx.Add"(%1254, %1271) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1255)
    %1273 = torch.operator "onnx.Cast"(%1272) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1256)
    %1274 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1257)
    %1275 = torch.operator "onnx.Pow"(%1273, %1274) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1258)
    %1276 = torch.operator "onnx.ReduceMean"(%1275) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1259)
    %1277 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1260)
    %1278 = torch.operator "onnx.Add"(%1276, %1277) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1261)
    %1279 = torch.operator "onnx.Sqrt"(%1278) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1262)
    %1280 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1263)
    %1281 = torch.operator "onnx.Div"(%1280, %1279) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1264)
    %1282 = torch.operator "onnx.Mul"(%1273, %1281) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1265)
    %1283 = torch.operator "onnx.Cast"(%1282) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1266)
    %1284 = torch.operator "onnx.Mul"(%23, %1283) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1267)
    %1285 = torch.operator "onnx.MatMul"(%1284, %138) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1268)
    %1286 = torch.operator "onnx.MatMul"(%1284, %139) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1269)
    %1287 = torch.operator "onnx.MatMul"(%1284, %140) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1270)
    %1288 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1271)
    %1289 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1272)
    %1290 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1273)
    %1291 = torch.operator "onnx.Reshape"(%1285, %1288) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1274)
    %1292 = torch.operator "onnx.Transpose"(%1291) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1275)
    %1293 = torch.operator "onnx.Reshape"(%1286, %1289) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1276)
    %1294 = torch.operator "onnx.Transpose"(%1293) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1277)
    %1295 = torch.operator "onnx.Reshape"(%1287, %1290) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1278)
    %1296 = torch.operator "onnx.Transpose"(%1295) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1279)
    %1297 = torch_c.to_builtin_tensor %1296 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1298 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1280)
    %1299 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1281)
    %1300 = torch.operator "onnx.Gather"(%1298, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1282)
    %1301 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1283)
    %1302 = torch.operator "onnx.Unsqueeze"(%1300, %1301) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1284)
    %1303 = torch.operator "onnx.Gather"(%1299, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1285)
    %1304 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1286)
    %1305 = torch.operator "onnx.Unsqueeze"(%1303, %1304) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1287)
    %1306 = torch.operator "onnx.Mul"(%1292, %1302) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1288)
    %1307 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1289)
    %1308 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1290)
    %1309 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1291)
    %1310 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1292)
    %1311 = torch.operator "onnx.Slice"(%1292, %1308, %1309, %1307, %1310) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1293)
    %1312 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1294)
    %1313 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1295)
    %1314 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1296)
    %1315 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1297)
    %1316 = torch.operator "onnx.Slice"(%1292, %1313, %1314, %1312, %1315) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1298)
    %1317 = torch.operator "onnx.Neg"(%1316) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1299)
    %1318 = torch.operator "onnx.Concat"(%1317, %1311) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1300)
    %1319 = torch.operator "onnx.Mul"(%1318, %1305) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1301)
    %1320 = torch.operator "onnx.Add"(%1306, %1319) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1302)
    %1321 = torch.operator "onnx.Mul"(%1294, %1302) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1303)
    %1322 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1304)
    %1323 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1305)
    %1324 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1306)
    %1325 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1307)
    %1326 = torch.operator "onnx.Slice"(%1294, %1323, %1324, %1322, %1325) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1308)
    %1327 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1309)
    %1328 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1310)
    %1329 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1311)
    %1330 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1312)
    %1331 = torch.operator "onnx.Slice"(%1294, %1328, %1329, %1327, %1330) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1313)
    %1332 = torch.operator "onnx.Neg"(%1331) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1314)
    %1333 = torch.operator "onnx.Concat"(%1332, %1326) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1315)
    %1334 = torch.operator "onnx.Mul"(%1333, %1305) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1316)
    %1335 = torch.operator "onnx.Add"(%1321, %1334) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1317)
    %1336 = torch_c.to_builtin_tensor %1335 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1337 = torch.operator "onnx.Transpose"(%1335) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1318)
    %1338 = torch.operator "onnx.MatMul"(%1320, %1337) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1319)
    %1339 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1320)
    %1340 = torch.operator "onnx.Div"(%1338, %1339) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1321)
    %1341 = torch.operator "onnx.Add"(%1340, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1322)
    %1342 = torch.operator "onnx.Softmax"(%1341) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1323)
    %1343 = torch.operator "onnx.Cast"(%1342) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1324)
    %1344 = torch.operator "onnx.Cast"(%1343) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1325)
    %1345 = torch.operator "onnx.MatMul"(%1344, %1296) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1326)
    %1346 = torch.operator "onnx.Transpose"(%1345) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1327)
    %1347 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1328)
    %1348 = torch.operator "onnx.Reshape"(%1346, %1347) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1329)
    %1349 = torch.operator "onnx.MatMul"(%1348, %141) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1330)
    %1350 = torch.operator "onnx.Add"(%1273, %1349) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1331)
    %1351 = torch.operator "onnx.Cast"(%1350) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1332)
    %1352 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1333)
    %1353 = torch.operator "onnx.Pow"(%1351, %1352) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1334)
    %1354 = torch.operator "onnx.ReduceMean"(%1353) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1335)
    %1355 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1336)
    %1356 = torch.operator "onnx.Add"(%1354, %1355) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1337)
    %1357 = torch.operator "onnx.Sqrt"(%1356) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1338)
    %1358 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.10_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1339)
    %1359 = torch.operator "onnx.Div"(%1358, %1357) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1340)
    %1360 = torch.operator "onnx.Mul"(%1351, %1359) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1341)
    %1361 = torch.operator "onnx.Cast"(%1360) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1342)
    %1362 = torch.operator "onnx.Mul"(%24, %1361) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1343)
    %1363 = torch.operator "onnx.MatMul"(%1362, %142) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1344)
    %1364 = torch.operator "onnx.Sigmoid"(%1363) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1345)
    %1365 = torch.operator "onnx.Mul"(%1363, %1364) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1346)
    %1366 = torch.operator "onnx.MatMul"(%1362, %143) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1347)
    %1367 = torch.operator "onnx.Mul"(%1365, %1366) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1348)
    %1368 = torch.operator "onnx.MatMul"(%1367, %144) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1349)
    %1369 = torch.operator "onnx.Add"(%1351, %1368) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1350)
    %1370 = torch.operator "onnx.Cast"(%1369) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1351)
    %1371 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1352)
    %1372 = torch.operator "onnx.Pow"(%1370, %1371) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1353)
    %1373 = torch.operator "onnx.ReduceMean"(%1372) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1354)
    %1374 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1355)
    %1375 = torch.operator "onnx.Add"(%1373, %1374) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1356)
    %1376 = torch.operator "onnx.Sqrt"(%1375) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1357)
    %1377 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1358)
    %1378 = torch.operator "onnx.Div"(%1377, %1376) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1359)
    %1379 = torch.operator "onnx.Mul"(%1370, %1378) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1360)
    %1380 = torch.operator "onnx.Cast"(%1379) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1361)
    %1381 = torch.operator "onnx.Mul"(%25, %1380) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1362)
    %1382 = torch.operator "onnx.MatMul"(%1381, %145) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1363)
    %1383 = torch.operator "onnx.MatMul"(%1381, %146) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1364)
    %1384 = torch.operator "onnx.MatMul"(%1381, %147) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1365)
    %1385 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1366)
    %1386 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1367)
    %1387 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1368)
    %1388 = torch.operator "onnx.Reshape"(%1382, %1385) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1369)
    %1389 = torch.operator "onnx.Transpose"(%1388) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1370)
    %1390 = torch.operator "onnx.Reshape"(%1383, %1386) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1371)
    %1391 = torch.operator "onnx.Transpose"(%1390) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1372)
    %1392 = torch.operator "onnx.Reshape"(%1384, %1387) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1373)
    %1393 = torch.operator "onnx.Transpose"(%1392) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1374)
    %1394 = torch_c.to_builtin_tensor %1393 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1395 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1375)
    %1396 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1376)
    %1397 = torch.operator "onnx.Gather"(%1395, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1377)
    %1398 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1378)
    %1399 = torch.operator "onnx.Unsqueeze"(%1397, %1398) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1379)
    %1400 = torch.operator "onnx.Gather"(%1396, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1380)
    %1401 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1381)
    %1402 = torch.operator "onnx.Unsqueeze"(%1400, %1401) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1382)
    %1403 = torch.operator "onnx.Mul"(%1389, %1399) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1383)
    %1404 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1384)
    %1405 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1385)
    %1406 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1386)
    %1407 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1387)
    %1408 = torch.operator "onnx.Slice"(%1389, %1405, %1406, %1404, %1407) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1388)
    %1409 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1389)
    %1410 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1390)
    %1411 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1391)
    %1412 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1392)
    %1413 = torch.operator "onnx.Slice"(%1389, %1410, %1411, %1409, %1412) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1393)
    %1414 = torch.operator "onnx.Neg"(%1413) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1394)
    %1415 = torch.operator "onnx.Concat"(%1414, %1408) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1395)
    %1416 = torch.operator "onnx.Mul"(%1415, %1402) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1396)
    %1417 = torch.operator "onnx.Add"(%1403, %1416) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1397)
    %1418 = torch.operator "onnx.Mul"(%1391, %1399) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1398)
    %1419 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1399)
    %1420 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1400)
    %1421 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1401)
    %1422 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1402)
    %1423 = torch.operator "onnx.Slice"(%1391, %1420, %1421, %1419, %1422) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1403)
    %1424 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1404)
    %1425 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1405)
    %1426 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1406)
    %1427 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1407)
    %1428 = torch.operator "onnx.Slice"(%1391, %1425, %1426, %1424, %1427) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1408)
    %1429 = torch.operator "onnx.Neg"(%1428) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1409)
    %1430 = torch.operator "onnx.Concat"(%1429, %1423) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1410)
    %1431 = torch.operator "onnx.Mul"(%1430, %1402) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1411)
    %1432 = torch.operator "onnx.Add"(%1418, %1431) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1412)
    %1433 = torch_c.to_builtin_tensor %1432 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1434 = torch.operator "onnx.Transpose"(%1432) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1413)
    %1435 = torch.operator "onnx.MatMul"(%1417, %1434) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1414)
    %1436 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1415)
    %1437 = torch.operator "onnx.Div"(%1435, %1436) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1416)
    %1438 = torch.operator "onnx.Add"(%1437, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1417)
    %1439 = torch.operator "onnx.Softmax"(%1438) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1418)
    %1440 = torch.operator "onnx.Cast"(%1439) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1419)
    %1441 = torch.operator "onnx.Cast"(%1440) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1420)
    %1442 = torch.operator "onnx.MatMul"(%1441, %1393) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1421)
    %1443 = torch.operator "onnx.Transpose"(%1442) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1422)
    %1444 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1423)
    %1445 = torch.operator "onnx.Reshape"(%1443, %1444) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1424)
    %1446 = torch.operator "onnx.MatMul"(%1445, %148) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1425)
    %1447 = torch.operator "onnx.Add"(%1370, %1446) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1426)
    %1448 = torch.operator "onnx.Cast"(%1447) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1427)
    %1449 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1428)
    %1450 = torch.operator "onnx.Pow"(%1448, %1449) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1429)
    %1451 = torch.operator "onnx.ReduceMean"(%1450) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1430)
    %1452 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1431)
    %1453 = torch.operator "onnx.Add"(%1451, %1452) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1432)
    %1454 = torch.operator "onnx.Sqrt"(%1453) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1433)
    %1455 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.11_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1434)
    %1456 = torch.operator "onnx.Div"(%1455, %1454) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1435)
    %1457 = torch.operator "onnx.Mul"(%1448, %1456) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1436)
    %1458 = torch.operator "onnx.Cast"(%1457) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1437)
    %1459 = torch.operator "onnx.Mul"(%26, %1458) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1438)
    %1460 = torch.operator "onnx.MatMul"(%1459, %149) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1439)
    %1461 = torch.operator "onnx.Sigmoid"(%1460) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1440)
    %1462 = torch.operator "onnx.Mul"(%1460, %1461) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1441)
    %1463 = torch.operator "onnx.MatMul"(%1459, %150) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1442)
    %1464 = torch.operator "onnx.Mul"(%1462, %1463) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1443)
    %1465 = torch.operator "onnx.MatMul"(%1464, %151) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1444)
    %1466 = torch.operator "onnx.Add"(%1448, %1465) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1445)
    %1467 = torch.operator "onnx.Cast"(%1466) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1446)
    %1468 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1447)
    %1469 = torch.operator "onnx.Pow"(%1467, %1468) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1448)
    %1470 = torch.operator "onnx.ReduceMean"(%1469) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1449)
    %1471 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1450)
    %1472 = torch.operator "onnx.Add"(%1470, %1471) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1451)
    %1473 = torch.operator "onnx.Sqrt"(%1472) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1452)
    %1474 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1453)
    %1475 = torch.operator "onnx.Div"(%1474, %1473) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1454)
    %1476 = torch.operator "onnx.Mul"(%1467, %1475) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1455)
    %1477 = torch.operator "onnx.Cast"(%1476) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1456)
    %1478 = torch.operator "onnx.Mul"(%27, %1477) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1457)
    %1479 = torch.operator "onnx.MatMul"(%1478, %152) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1458)
    %1480 = torch.operator "onnx.MatMul"(%1478, %153) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1459)
    %1481 = torch.operator "onnx.MatMul"(%1478, %154) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1460)
    %1482 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1461)
    %1483 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1462)
    %1484 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1463)
    %1485 = torch.operator "onnx.Reshape"(%1479, %1482) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1464)
    %1486 = torch.operator "onnx.Transpose"(%1485) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1465)
    %1487 = torch.operator "onnx.Reshape"(%1480, %1483) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1466)
    %1488 = torch.operator "onnx.Transpose"(%1487) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1467)
    %1489 = torch.operator "onnx.Reshape"(%1481, %1484) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1468)
    %1490 = torch.operator "onnx.Transpose"(%1489) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1469)
    %1491 = torch_c.to_builtin_tensor %1490 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1492 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1470)
    %1493 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1471)
    %1494 = torch.operator "onnx.Gather"(%1492, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1472)
    %1495 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1473)
    %1496 = torch.operator "onnx.Unsqueeze"(%1494, %1495) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1474)
    %1497 = torch.operator "onnx.Gather"(%1493, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1475)
    %1498 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1476)
    %1499 = torch.operator "onnx.Unsqueeze"(%1497, %1498) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1477)
    %1500 = torch.operator "onnx.Mul"(%1486, %1496) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1478)
    %1501 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1479)
    %1502 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1480)
    %1503 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1481)
    %1504 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1482)
    %1505 = torch.operator "onnx.Slice"(%1486, %1502, %1503, %1501, %1504) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1483)
    %1506 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1484)
    %1507 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1485)
    %1508 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1486)
    %1509 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1487)
    %1510 = torch.operator "onnx.Slice"(%1486, %1507, %1508, %1506, %1509) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1488)
    %1511 = torch.operator "onnx.Neg"(%1510) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1489)
    %1512 = torch.operator "onnx.Concat"(%1511, %1505) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1490)
    %1513 = torch.operator "onnx.Mul"(%1512, %1499) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1491)
    %1514 = torch.operator "onnx.Add"(%1500, %1513) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1492)
    %1515 = torch.operator "onnx.Mul"(%1488, %1496) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1493)
    %1516 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1494)
    %1517 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1495)
    %1518 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1496)
    %1519 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1497)
    %1520 = torch.operator "onnx.Slice"(%1488, %1517, %1518, %1516, %1519) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1498)
    %1521 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1499)
    %1522 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1500)
    %1523 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1501)
    %1524 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1502)
    %1525 = torch.operator "onnx.Slice"(%1488, %1522, %1523, %1521, %1524) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1503)
    %1526 = torch.operator "onnx.Neg"(%1525) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1504)
    %1527 = torch.operator "onnx.Concat"(%1526, %1520) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1505)
    %1528 = torch.operator "onnx.Mul"(%1527, %1499) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1506)
    %1529 = torch.operator "onnx.Add"(%1515, %1528) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1507)
    %1530 = torch_c.to_builtin_tensor %1529 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1531 = torch.operator "onnx.Transpose"(%1529) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1508)
    %1532 = torch.operator "onnx.MatMul"(%1514, %1531) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1509)
    %1533 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1510)
    %1534 = torch.operator "onnx.Div"(%1532, %1533) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1511)
    %1535 = torch.operator "onnx.Add"(%1534, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1512)
    %1536 = torch.operator "onnx.Softmax"(%1535) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1513)
    %1537 = torch.operator "onnx.Cast"(%1536) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1514)
    %1538 = torch.operator "onnx.Cast"(%1537) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1515)
    %1539 = torch.operator "onnx.MatMul"(%1538, %1490) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1516)
    %1540 = torch.operator "onnx.Transpose"(%1539) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1517)
    %1541 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1518)
    %1542 = torch.operator "onnx.Reshape"(%1540, %1541) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1519)
    %1543 = torch.operator "onnx.MatMul"(%1542, %155) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1520)
    %1544 = torch.operator "onnx.Add"(%1467, %1543) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1521)
    %1545 = torch.operator "onnx.Cast"(%1544) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1522)
    %1546 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1523)
    %1547 = torch.operator "onnx.Pow"(%1545, %1546) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1524)
    %1548 = torch.operator "onnx.ReduceMean"(%1547) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1525)
    %1549 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1526)
    %1550 = torch.operator "onnx.Add"(%1548, %1549) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1527)
    %1551 = torch.operator "onnx.Sqrt"(%1550) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1528)
    %1552 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.12_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1529)
    %1553 = torch.operator "onnx.Div"(%1552, %1551) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1530)
    %1554 = torch.operator "onnx.Mul"(%1545, %1553) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1531)
    %1555 = torch.operator "onnx.Cast"(%1554) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1532)
    %1556 = torch.operator "onnx.Mul"(%28, %1555) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1533)
    %1557 = torch.operator "onnx.MatMul"(%1556, %156) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1534)
    %1558 = torch.operator "onnx.Sigmoid"(%1557) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1535)
    %1559 = torch.operator "onnx.Mul"(%1557, %1558) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1536)
    %1560 = torch.operator "onnx.MatMul"(%1556, %157) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1537)
    %1561 = torch.operator "onnx.Mul"(%1559, %1560) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1538)
    %1562 = torch.operator "onnx.MatMul"(%1561, %158) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1539)
    %1563 = torch.operator "onnx.Add"(%1545, %1562) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1540)
    %1564 = torch.operator "onnx.Cast"(%1563) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1541)
    %1565 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1542)
    %1566 = torch.operator "onnx.Pow"(%1564, %1565) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1543)
    %1567 = torch.operator "onnx.ReduceMean"(%1566) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1544)
    %1568 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1545)
    %1569 = torch.operator "onnx.Add"(%1567, %1568) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1546)
    %1570 = torch.operator "onnx.Sqrt"(%1569) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1547)
    %1571 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1548)
    %1572 = torch.operator "onnx.Div"(%1571, %1570) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1549)
    %1573 = torch.operator "onnx.Mul"(%1564, %1572) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1550)
    %1574 = torch.operator "onnx.Cast"(%1573) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1551)
    %1575 = torch.operator "onnx.Mul"(%29, %1574) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1552)
    %1576 = torch.operator "onnx.MatMul"(%1575, %159) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1553)
    %1577 = torch.operator "onnx.MatMul"(%1575, %160) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1554)
    %1578 = torch.operator "onnx.MatMul"(%1575, %161) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1555)
    %1579 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1556)
    %1580 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1557)
    %1581 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1558)
    %1582 = torch.operator "onnx.Reshape"(%1576, %1579) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1559)
    %1583 = torch.operator "onnx.Transpose"(%1582) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1560)
    %1584 = torch.operator "onnx.Reshape"(%1577, %1580) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1561)
    %1585 = torch.operator "onnx.Transpose"(%1584) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1562)
    %1586 = torch.operator "onnx.Reshape"(%1578, %1581) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1563)
    %1587 = torch.operator "onnx.Transpose"(%1586) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1564)
    %1588 = torch_c.to_builtin_tensor %1587 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1589 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1565)
    %1590 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1566)
    %1591 = torch.operator "onnx.Gather"(%1589, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1567)
    %1592 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1568)
    %1593 = torch.operator "onnx.Unsqueeze"(%1591, %1592) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1569)
    %1594 = torch.operator "onnx.Gather"(%1590, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1570)
    %1595 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1571)
    %1596 = torch.operator "onnx.Unsqueeze"(%1594, %1595) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1572)
    %1597 = torch.operator "onnx.Mul"(%1583, %1593) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1573)
    %1598 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1574)
    %1599 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1575)
    %1600 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1576)
    %1601 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1577)
    %1602 = torch.operator "onnx.Slice"(%1583, %1599, %1600, %1598, %1601) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1578)
    %1603 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1579)
    %1604 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1580)
    %1605 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1581)
    %1606 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1582)
    %1607 = torch.operator "onnx.Slice"(%1583, %1604, %1605, %1603, %1606) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1583)
    %1608 = torch.operator "onnx.Neg"(%1607) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1584)
    %1609 = torch.operator "onnx.Concat"(%1608, %1602) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1585)
    %1610 = torch.operator "onnx.Mul"(%1609, %1596) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1586)
    %1611 = torch.operator "onnx.Add"(%1597, %1610) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1587)
    %1612 = torch.operator "onnx.Mul"(%1585, %1593) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1588)
    %1613 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1589)
    %1614 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1590)
    %1615 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1591)
    %1616 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1592)
    %1617 = torch.operator "onnx.Slice"(%1585, %1614, %1615, %1613, %1616) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1593)
    %1618 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1594)
    %1619 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1595)
    %1620 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1596)
    %1621 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1597)
    %1622 = torch.operator "onnx.Slice"(%1585, %1619, %1620, %1618, %1621) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1598)
    %1623 = torch.operator "onnx.Neg"(%1622) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1599)
    %1624 = torch.operator "onnx.Concat"(%1623, %1617) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1600)
    %1625 = torch.operator "onnx.Mul"(%1624, %1596) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1601)
    %1626 = torch.operator "onnx.Add"(%1612, %1625) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1602)
    %1627 = torch_c.to_builtin_tensor %1626 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1628 = torch.operator "onnx.Transpose"(%1626) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1603)
    %1629 = torch.operator "onnx.MatMul"(%1611, %1628) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1604)
    %1630 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1605)
    %1631 = torch.operator "onnx.Div"(%1629, %1630) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1606)
    %1632 = torch.operator "onnx.Add"(%1631, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1607)
    %1633 = torch.operator "onnx.Softmax"(%1632) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1608)
    %1634 = torch.operator "onnx.Cast"(%1633) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1609)
    %1635 = torch.operator "onnx.Cast"(%1634) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1610)
    %1636 = torch.operator "onnx.MatMul"(%1635, %1587) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1611)
    %1637 = torch.operator "onnx.Transpose"(%1636) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1612)
    %1638 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1613)
    %1639 = torch.operator "onnx.Reshape"(%1637, %1638) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1614)
    %1640 = torch.operator "onnx.MatMul"(%1639, %162) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1615)
    %1641 = torch.operator "onnx.Add"(%1564, %1640) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1616)
    %1642 = torch.operator "onnx.Cast"(%1641) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1617)
    %1643 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1618)
    %1644 = torch.operator "onnx.Pow"(%1642, %1643) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1619)
    %1645 = torch.operator "onnx.ReduceMean"(%1644) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1620)
    %1646 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1621)
    %1647 = torch.operator "onnx.Add"(%1645, %1646) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1622)
    %1648 = torch.operator "onnx.Sqrt"(%1647) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1623)
    %1649 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.13_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1624)
    %1650 = torch.operator "onnx.Div"(%1649, %1648) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1625)
    %1651 = torch.operator "onnx.Mul"(%1642, %1650) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1626)
    %1652 = torch.operator "onnx.Cast"(%1651) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1627)
    %1653 = torch.operator "onnx.Mul"(%30, %1652) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1628)
    %1654 = torch.operator "onnx.MatMul"(%1653, %163) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1629)
    %1655 = torch.operator "onnx.Sigmoid"(%1654) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1630)
    %1656 = torch.operator "onnx.Mul"(%1654, %1655) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1631)
    %1657 = torch.operator "onnx.MatMul"(%1653, %164) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1632)
    %1658 = torch.operator "onnx.Mul"(%1656, %1657) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1633)
    %1659 = torch.operator "onnx.MatMul"(%1658, %165) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1634)
    %1660 = torch.operator "onnx.Add"(%1642, %1659) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1635)
    %1661 = torch.operator "onnx.Cast"(%1660) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1636)
    %1662 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1637)
    %1663 = torch.operator "onnx.Pow"(%1661, %1662) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1638)
    %1664 = torch.operator "onnx.ReduceMean"(%1663) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1639)
    %1665 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1640)
    %1666 = torch.operator "onnx.Add"(%1664, %1665) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1641)
    %1667 = torch.operator "onnx.Sqrt"(%1666) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1642)
    %1668 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1643)
    %1669 = torch.operator "onnx.Div"(%1668, %1667) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1644)
    %1670 = torch.operator "onnx.Mul"(%1661, %1669) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1645)
    %1671 = torch.operator "onnx.Cast"(%1670) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1646)
    %1672 = torch.operator "onnx.Mul"(%31, %1671) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1647)
    %1673 = torch.operator "onnx.MatMul"(%1672, %166) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1648)
    %1674 = torch.operator "onnx.MatMul"(%1672, %167) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1649)
    %1675 = torch.operator "onnx.MatMul"(%1672, %168) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1650)
    %1676 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1651)
    %1677 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1652)
    %1678 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1653)
    %1679 = torch.operator "onnx.Reshape"(%1673, %1676) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1654)
    %1680 = torch.operator "onnx.Transpose"(%1679) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1655)
    %1681 = torch.operator "onnx.Reshape"(%1674, %1677) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1656)
    %1682 = torch.operator "onnx.Transpose"(%1681) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1657)
    %1683 = torch.operator "onnx.Reshape"(%1675, %1678) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1658)
    %1684 = torch.operator "onnx.Transpose"(%1683) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1659)
    %1685 = torch_c.to_builtin_tensor %1684 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1686 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1660)
    %1687 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1661)
    %1688 = torch.operator "onnx.Gather"(%1686, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1662)
    %1689 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1663)
    %1690 = torch.operator "onnx.Unsqueeze"(%1688, %1689) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1664)
    %1691 = torch.operator "onnx.Gather"(%1687, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1665)
    %1692 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1666)
    %1693 = torch.operator "onnx.Unsqueeze"(%1691, %1692) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1667)
    %1694 = torch.operator "onnx.Mul"(%1680, %1690) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1668)
    %1695 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1669)
    %1696 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1670)
    %1697 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1671)
    %1698 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1672)
    %1699 = torch.operator "onnx.Slice"(%1680, %1696, %1697, %1695, %1698) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1673)
    %1700 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1674)
    %1701 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1675)
    %1702 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1676)
    %1703 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1677)
    %1704 = torch.operator "onnx.Slice"(%1680, %1701, %1702, %1700, %1703) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1678)
    %1705 = torch.operator "onnx.Neg"(%1704) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1679)
    %1706 = torch.operator "onnx.Concat"(%1705, %1699) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1680)
    %1707 = torch.operator "onnx.Mul"(%1706, %1693) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1681)
    %1708 = torch.operator "onnx.Add"(%1694, %1707) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1682)
    %1709 = torch.operator "onnx.Mul"(%1682, %1690) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1683)
    %1710 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1684)
    %1711 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1685)
    %1712 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1686)
    %1713 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1687)
    %1714 = torch.operator "onnx.Slice"(%1682, %1711, %1712, %1710, %1713) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1688)
    %1715 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1689)
    %1716 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1690)
    %1717 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1691)
    %1718 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1692)
    %1719 = torch.operator "onnx.Slice"(%1682, %1716, %1717, %1715, %1718) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1693)
    %1720 = torch.operator "onnx.Neg"(%1719) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1694)
    %1721 = torch.operator "onnx.Concat"(%1720, %1714) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1695)
    %1722 = torch.operator "onnx.Mul"(%1721, %1693) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1696)
    %1723 = torch.operator "onnx.Add"(%1709, %1722) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1697)
    %1724 = torch_c.to_builtin_tensor %1723 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1725 = torch.operator "onnx.Transpose"(%1723) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1698)
    %1726 = torch.operator "onnx.MatMul"(%1708, %1725) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1699)
    %1727 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1700)
    %1728 = torch.operator "onnx.Div"(%1726, %1727) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1701)
    %1729 = torch.operator "onnx.Add"(%1728, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1702)
    %1730 = torch.operator "onnx.Softmax"(%1729) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1703)
    %1731 = torch.operator "onnx.Cast"(%1730) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1704)
    %1732 = torch.operator "onnx.Cast"(%1731) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1705)
    %1733 = torch.operator "onnx.MatMul"(%1732, %1684) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1706)
    %1734 = torch.operator "onnx.Transpose"(%1733) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1707)
    %1735 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1708)
    %1736 = torch.operator "onnx.Reshape"(%1734, %1735) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1709)
    %1737 = torch.operator "onnx.MatMul"(%1736, %169) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1710)
    %1738 = torch.operator "onnx.Add"(%1661, %1737) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1711)
    %1739 = torch.operator "onnx.Cast"(%1738) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1712)
    %1740 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1713)
    %1741 = torch.operator "onnx.Pow"(%1739, %1740) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1714)
    %1742 = torch.operator "onnx.ReduceMean"(%1741) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1715)
    %1743 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1716)
    %1744 = torch.operator "onnx.Add"(%1742, %1743) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1717)
    %1745 = torch.operator "onnx.Sqrt"(%1744) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1718)
    %1746 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.14_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1719)
    %1747 = torch.operator "onnx.Div"(%1746, %1745) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1720)
    %1748 = torch.operator "onnx.Mul"(%1739, %1747) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1721)
    %1749 = torch.operator "onnx.Cast"(%1748) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1722)
    %1750 = torch.operator "onnx.Mul"(%32, %1749) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1723)
    %1751 = torch.operator "onnx.MatMul"(%1750, %170) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1724)
    %1752 = torch.operator "onnx.Sigmoid"(%1751) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1725)
    %1753 = torch.operator "onnx.Mul"(%1751, %1752) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1726)
    %1754 = torch.operator "onnx.MatMul"(%1750, %171) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1727)
    %1755 = torch.operator "onnx.Mul"(%1753, %1754) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1728)
    %1756 = torch.operator "onnx.MatMul"(%1755, %172) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1729)
    %1757 = torch.operator "onnx.Add"(%1739, %1756) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1730)
    %1758 = torch.operator "onnx.Cast"(%1757) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1731)
    %1759 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1732)
    %1760 = torch.operator "onnx.Pow"(%1758, %1759) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1733)
    %1761 = torch.operator "onnx.ReduceMean"(%1760) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1734)
    %1762 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1735)
    %1763 = torch.operator "onnx.Add"(%1761, %1762) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1736)
    %1764 = torch.operator "onnx.Sqrt"(%1763) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1737)
    %1765 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1738)
    %1766 = torch.operator "onnx.Div"(%1765, %1764) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1739)
    %1767 = torch.operator "onnx.Mul"(%1758, %1766) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1740)
    %1768 = torch.operator "onnx.Cast"(%1767) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1741)
    %1769 = torch.operator "onnx.Mul"(%33, %1768) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1742)
    %1770 = torch.operator "onnx.MatMul"(%1769, %173) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1743)
    %1771 = torch.operator "onnx.MatMul"(%1769, %174) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1744)
    %1772 = torch.operator "onnx.MatMul"(%1769, %175) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1745)
    %1773 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1746)
    %1774 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1747)
    %1775 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1748)
    %1776 = torch.operator "onnx.Reshape"(%1770, %1773) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1749)
    %1777 = torch.operator "onnx.Transpose"(%1776) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1750)
    %1778 = torch.operator "onnx.Reshape"(%1771, %1774) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1751)
    %1779 = torch.operator "onnx.Transpose"(%1778) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1752)
    %1780 = torch.operator "onnx.Reshape"(%1772, %1775) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1753)
    %1781 = torch.operator "onnx.Transpose"(%1780) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1754)
    %1782 = torch_c.to_builtin_tensor %1781 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1783 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1755)
    %1784 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1756)
    %1785 = torch.operator "onnx.Gather"(%1783, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1757)
    %1786 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1758)
    %1787 = torch.operator "onnx.Unsqueeze"(%1785, %1786) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1759)
    %1788 = torch.operator "onnx.Gather"(%1784, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1760)
    %1789 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1761)
    %1790 = torch.operator "onnx.Unsqueeze"(%1788, %1789) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1762)
    %1791 = torch.operator "onnx.Mul"(%1777, %1787) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1763)
    %1792 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1764)
    %1793 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1765)
    %1794 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1766)
    %1795 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1767)
    %1796 = torch.operator "onnx.Slice"(%1777, %1793, %1794, %1792, %1795) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1768)
    %1797 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1769)
    %1798 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1770)
    %1799 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1771)
    %1800 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1772)
    %1801 = torch.operator "onnx.Slice"(%1777, %1798, %1799, %1797, %1800) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1773)
    %1802 = torch.operator "onnx.Neg"(%1801) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1774)
    %1803 = torch.operator "onnx.Concat"(%1802, %1796) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1775)
    %1804 = torch.operator "onnx.Mul"(%1803, %1790) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1776)
    %1805 = torch.operator "onnx.Add"(%1791, %1804) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1777)
    %1806 = torch.operator "onnx.Mul"(%1779, %1787) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1778)
    %1807 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1779)
    %1808 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1780)
    %1809 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1781)
    %1810 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1782)
    %1811 = torch.operator "onnx.Slice"(%1779, %1808, %1809, %1807, %1810) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1783)
    %1812 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1784)
    %1813 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1785)
    %1814 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1786)
    %1815 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1787)
    %1816 = torch.operator "onnx.Slice"(%1779, %1813, %1814, %1812, %1815) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1788)
    %1817 = torch.operator "onnx.Neg"(%1816) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1789)
    %1818 = torch.operator "onnx.Concat"(%1817, %1811) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1790)
    %1819 = torch.operator "onnx.Mul"(%1818, %1790) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1791)
    %1820 = torch.operator "onnx.Add"(%1806, %1819) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1792)
    %1821 = torch_c.to_builtin_tensor %1820 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1822 = torch.operator "onnx.Transpose"(%1820) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1793)
    %1823 = torch.operator "onnx.MatMul"(%1805, %1822) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1794)
    %1824 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1795)
    %1825 = torch.operator "onnx.Div"(%1823, %1824) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1796)
    %1826 = torch.operator "onnx.Add"(%1825, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1797)
    %1827 = torch.operator "onnx.Softmax"(%1826) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1798)
    %1828 = torch.operator "onnx.Cast"(%1827) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1799)
    %1829 = torch.operator "onnx.Cast"(%1828) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1800)
    %1830 = torch.operator "onnx.MatMul"(%1829, %1781) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1801)
    %1831 = torch.operator "onnx.Transpose"(%1830) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1802)
    %1832 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1803)
    %1833 = torch.operator "onnx.Reshape"(%1831, %1832) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1804)
    %1834 = torch.operator "onnx.MatMul"(%1833, %176) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1805)
    %1835 = torch.operator "onnx.Add"(%1758, %1834) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1806)
    %1836 = torch.operator "onnx.Cast"(%1835) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1807)
    %1837 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1808)
    %1838 = torch.operator "onnx.Pow"(%1836, %1837) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1809)
    %1839 = torch.operator "onnx.ReduceMean"(%1838) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1810)
    %1840 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1811)
    %1841 = torch.operator "onnx.Add"(%1839, %1840) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1812)
    %1842 = torch.operator "onnx.Sqrt"(%1841) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1813)
    %1843 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.15_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1814)
    %1844 = torch.operator "onnx.Div"(%1843, %1842) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1815)
    %1845 = torch.operator "onnx.Mul"(%1836, %1844) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1816)
    %1846 = torch.operator "onnx.Cast"(%1845) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1817)
    %1847 = torch.operator "onnx.Mul"(%34, %1846) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1818)
    %1848 = torch.operator "onnx.MatMul"(%1847, %177) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1819)
    %1849 = torch.operator "onnx.Sigmoid"(%1848) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1820)
    %1850 = torch.operator "onnx.Mul"(%1848, %1849) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1821)
    %1851 = torch.operator "onnx.MatMul"(%1847, %178) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1822)
    %1852 = torch.operator "onnx.Mul"(%1850, %1851) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1823)
    %1853 = torch.operator "onnx.MatMul"(%1852, %179) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1824)
    %1854 = torch.operator "onnx.Add"(%1836, %1853) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1825)
    %1855 = torch.operator "onnx.Cast"(%1854) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1826)
    %1856 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1827)
    %1857 = torch.operator "onnx.Pow"(%1855, %1856) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1828)
    %1858 = torch.operator "onnx.ReduceMean"(%1857) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1829)
    %1859 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1830)
    %1860 = torch.operator "onnx.Add"(%1858, %1859) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1831)
    %1861 = torch.operator "onnx.Sqrt"(%1860) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1832)
    %1862 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1833)
    %1863 = torch.operator "onnx.Div"(%1862, %1861) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1834)
    %1864 = torch.operator "onnx.Mul"(%1855, %1863) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1835)
    %1865 = torch.operator "onnx.Cast"(%1864) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1836)
    %1866 = torch.operator "onnx.Mul"(%35, %1865) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1837)
    %1867 = torch.operator "onnx.MatMul"(%1866, %180) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1838)
    %1868 = torch.operator "onnx.MatMul"(%1866, %181) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1839)
    %1869 = torch.operator "onnx.MatMul"(%1866, %182) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1840)
    %1870 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1841)
    %1871 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1842)
    %1872 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1843)
    %1873 = torch.operator "onnx.Reshape"(%1867, %1870) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1844)
    %1874 = torch.operator "onnx.Transpose"(%1873) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1845)
    %1875 = torch.operator "onnx.Reshape"(%1868, %1871) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1846)
    %1876 = torch.operator "onnx.Transpose"(%1875) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1847)
    %1877 = torch.operator "onnx.Reshape"(%1869, %1872) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1848)
    %1878 = torch.operator "onnx.Transpose"(%1877) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1849)
    %1879 = torch_c.to_builtin_tensor %1878 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1880 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1850)
    %1881 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1851)
    %1882 = torch.operator "onnx.Gather"(%1880, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1852)
    %1883 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1853)
    %1884 = torch.operator "onnx.Unsqueeze"(%1882, %1883) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1854)
    %1885 = torch.operator "onnx.Gather"(%1881, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1855)
    %1886 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1856)
    %1887 = torch.operator "onnx.Unsqueeze"(%1885, %1886) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1857)
    %1888 = torch.operator "onnx.Mul"(%1874, %1884) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1858)
    %1889 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1859)
    %1890 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1860)
    %1891 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1861)
    %1892 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1862)
    %1893 = torch.operator "onnx.Slice"(%1874, %1890, %1891, %1889, %1892) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1863)
    %1894 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1864)
    %1895 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1865)
    %1896 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1866)
    %1897 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1867)
    %1898 = torch.operator "onnx.Slice"(%1874, %1895, %1896, %1894, %1897) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1868)
    %1899 = torch.operator "onnx.Neg"(%1898) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1869)
    %1900 = torch.operator "onnx.Concat"(%1899, %1893) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1870)
    %1901 = torch.operator "onnx.Mul"(%1900, %1887) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1871)
    %1902 = torch.operator "onnx.Add"(%1888, %1901) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1872)
    %1903 = torch.operator "onnx.Mul"(%1876, %1884) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1873)
    %1904 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1874)
    %1905 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1875)
    %1906 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1876)
    %1907 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1877)
    %1908 = torch.operator "onnx.Slice"(%1876, %1905, %1906, %1904, %1907) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1878)
    %1909 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1879)
    %1910 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1880)
    %1911 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1881)
    %1912 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1882)
    %1913 = torch.operator "onnx.Slice"(%1876, %1910, %1911, %1909, %1912) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1883)
    %1914 = torch.operator "onnx.Neg"(%1913) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1884)
    %1915 = torch.operator "onnx.Concat"(%1914, %1908) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1885)
    %1916 = torch.operator "onnx.Mul"(%1915, %1887) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1886)
    %1917 = torch.operator "onnx.Add"(%1903, %1916) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1887)
    %1918 = torch_c.to_builtin_tensor %1917 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1919 = torch.operator "onnx.Transpose"(%1917) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1888)
    %1920 = torch.operator "onnx.MatMul"(%1902, %1919) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1889)
    %1921 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1890)
    %1922 = torch.operator "onnx.Div"(%1920, %1921) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1891)
    %1923 = torch.operator "onnx.Add"(%1922, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1892)
    %1924 = torch.operator "onnx.Softmax"(%1923) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1893)
    %1925 = torch.operator "onnx.Cast"(%1924) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1894)
    %1926 = torch.operator "onnx.Cast"(%1925) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1895)
    %1927 = torch.operator "onnx.MatMul"(%1926, %1878) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1896)
    %1928 = torch.operator "onnx.Transpose"(%1927) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1897)
    %1929 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1898)
    %1930 = torch.operator "onnx.Reshape"(%1928, %1929) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1899)
    %1931 = torch.operator "onnx.MatMul"(%1930, %183) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1900)
    %1932 = torch.operator "onnx.Add"(%1855, %1931) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1901)
    %1933 = torch.operator "onnx.Cast"(%1932) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1902)
    %1934 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1903)
    %1935 = torch.operator "onnx.Pow"(%1933, %1934) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1904)
    %1936 = torch.operator "onnx.ReduceMean"(%1935) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1905)
    %1937 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1906)
    %1938 = torch.operator "onnx.Add"(%1936, %1937) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1907)
    %1939 = torch.operator "onnx.Sqrt"(%1938) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1908)
    %1940 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.16_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1909)
    %1941 = torch.operator "onnx.Div"(%1940, %1939) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1910)
    %1942 = torch.operator "onnx.Mul"(%1933, %1941) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1911)
    %1943 = torch.operator "onnx.Cast"(%1942) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1912)
    %1944 = torch.operator "onnx.Mul"(%36, %1943) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1913)
    %1945 = torch.operator "onnx.MatMul"(%1944, %184) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1914)
    %1946 = torch.operator "onnx.Sigmoid"(%1945) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1915)
    %1947 = torch.operator "onnx.Mul"(%1945, %1946) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1916)
    %1948 = torch.operator "onnx.MatMul"(%1944, %185) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1917)
    %1949 = torch.operator "onnx.Mul"(%1947, %1948) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc1918)
    %1950 = torch.operator "onnx.MatMul"(%1949, %186) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1919)
    %1951 = torch.operator "onnx.Add"(%1933, %1950) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1920)
    %1952 = torch.operator "onnx.Cast"(%1951) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1921)
    %1953 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1922)
    %1954 = torch.operator "onnx.Pow"(%1952, %1953) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1923)
    %1955 = torch.operator "onnx.ReduceMean"(%1954) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1924)
    %1956 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1925)
    %1957 = torch.operator "onnx.Add"(%1955, %1956) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1926)
    %1958 = torch.operator "onnx.Sqrt"(%1957) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1927)
    %1959 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1928)
    %1960 = torch.operator "onnx.Div"(%1959, %1958) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc1929)
    %1961 = torch.operator "onnx.Mul"(%1952, %1960) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1930)
    %1962 = torch.operator "onnx.Cast"(%1961) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1931)
    %1963 = torch.operator "onnx.Mul"(%37, %1962) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1932)
    %1964 = torch.operator "onnx.MatMul"(%1963, %187) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1933)
    %1965 = torch.operator "onnx.MatMul"(%1963, %188) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1934)
    %1966 = torch.operator "onnx.MatMul"(%1963, %189) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1935)
    %1967 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1936)
    %1968 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1937)
    %1969 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc1938)
    %1970 = torch.operator "onnx.Reshape"(%1964, %1967) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1939)
    %1971 = torch.operator "onnx.Transpose"(%1970) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1940)
    %1972 = torch.operator "onnx.Reshape"(%1965, %1968) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1941)
    %1973 = torch.operator "onnx.Transpose"(%1972) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1942)
    %1974 = torch.operator "onnx.Reshape"(%1966, %1969) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc1943)
    %1975 = torch.operator "onnx.Transpose"(%1974) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1944)
    %1976 = torch_c.to_builtin_tensor %1975 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %1977 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1945)
    %1978 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc1946)
    %1979 = torch.operator "onnx.Gather"(%1977, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1947)
    %1980 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1948)
    %1981 = torch.operator "onnx.Unsqueeze"(%1979, %1980) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1949)
    %1982 = torch.operator "onnx.Gather"(%1978, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc1950)
    %1983 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1951)
    %1984 = torch.operator "onnx.Unsqueeze"(%1982, %1983) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc1952)
    %1985 = torch.operator "onnx.Mul"(%1971, %1981) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1953)
    %1986 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1954)
    %1987 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1955)
    %1988 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1956)
    %1989 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1957)
    %1990 = torch.operator "onnx.Slice"(%1971, %1987, %1988, %1986, %1989) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1958)
    %1991 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1959)
    %1992 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1960)
    %1993 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1961)
    %1994 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1962)
    %1995 = torch.operator "onnx.Slice"(%1971, %1992, %1993, %1991, %1994) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1963)
    %1996 = torch.operator "onnx.Neg"(%1995) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1964)
    %1997 = torch.operator "onnx.Concat"(%1996, %1990) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1965)
    %1998 = torch.operator "onnx.Mul"(%1997, %1984) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1966)
    %1999 = torch.operator "onnx.Add"(%1985, %1998) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1967)
    %2000 = torch.operator "onnx.Mul"(%1973, %1981) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1968)
    %2001 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1969)
    %2002 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1970)
    %2003 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1971)
    %2004 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1972)
    %2005 = torch.operator "onnx.Slice"(%1973, %2002, %2003, %2001, %2004) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1973)
    %2006 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1974)
    %2007 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1975)
    %2008 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1976)
    %2009 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc1977)
    %2010 = torch.operator "onnx.Slice"(%1973, %2007, %2008, %2006, %2009) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1978)
    %2011 = torch.operator "onnx.Neg"(%2010) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc1979)
    %2012 = torch.operator "onnx.Concat"(%2011, %2005) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1980)
    %2013 = torch.operator "onnx.Mul"(%2012, %1984) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1981)
    %2014 = torch.operator "onnx.Add"(%2000, %2013) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc1982)
    %2015 = torch_c.to_builtin_tensor %2014 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2016 = torch.operator "onnx.Transpose"(%2014) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc1983)
    %2017 = torch.operator "onnx.MatMul"(%1999, %2016) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1984)
    %2018 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1985)
    %2019 = torch.operator "onnx.Div"(%2017, %2018) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc1986)
    %2020 = torch.operator "onnx.Add"(%2019, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1987)
    %2021 = torch.operator "onnx.Softmax"(%2020) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1988)
    %2022 = torch.operator "onnx.Cast"(%2021) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1989)
    %2023 = torch.operator "onnx.Cast"(%2022) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc1990)
    %2024 = torch.operator "onnx.MatMul"(%2023, %1975) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc1991)
    %2025 = torch.operator "onnx.Transpose"(%2024) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc1992)
    %2026 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc1993)
    %2027 = torch.operator "onnx.Reshape"(%2025, %2026) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1994)
    %2028 = torch.operator "onnx.MatMul"(%2027, %190) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1995)
    %2029 = torch.operator "onnx.Add"(%1952, %2028) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1996)
    %2030 = torch.operator "onnx.Cast"(%2029) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1997)
    %2031 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc1998)
    %2032 = torch.operator "onnx.Pow"(%2030, %2031) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc1999)
    %2033 = torch.operator "onnx.ReduceMean"(%2032) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2000)
    %2034 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2001)
    %2035 = torch.operator "onnx.Add"(%2033, %2034) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2002)
    %2036 = torch.operator "onnx.Sqrt"(%2035) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2003)
    %2037 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.17_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2004)
    %2038 = torch.operator "onnx.Div"(%2037, %2036) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2005)
    %2039 = torch.operator "onnx.Mul"(%2030, %2038) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2006)
    %2040 = torch.operator "onnx.Cast"(%2039) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2007)
    %2041 = torch.operator "onnx.Mul"(%38, %2040) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2008)
    %2042 = torch.operator "onnx.MatMul"(%2041, %191) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2009)
    %2043 = torch.operator "onnx.Sigmoid"(%2042) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2010)
    %2044 = torch.operator "onnx.Mul"(%2042, %2043) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2011)
    %2045 = torch.operator "onnx.MatMul"(%2041, %192) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2012)
    %2046 = torch.operator "onnx.Mul"(%2044, %2045) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2013)
    %2047 = torch.operator "onnx.MatMul"(%2046, %193) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2014)
    %2048 = torch.operator "onnx.Add"(%2030, %2047) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2015)
    %2049 = torch.operator "onnx.Cast"(%2048) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2016)
    %2050 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2017)
    %2051 = torch.operator "onnx.Pow"(%2049, %2050) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2018)
    %2052 = torch.operator "onnx.ReduceMean"(%2051) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2019)
    %2053 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2020)
    %2054 = torch.operator "onnx.Add"(%2052, %2053) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2021)
    %2055 = torch.operator "onnx.Sqrt"(%2054) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2022)
    %2056 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2023)
    %2057 = torch.operator "onnx.Div"(%2056, %2055) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2024)
    %2058 = torch.operator "onnx.Mul"(%2049, %2057) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2025)
    %2059 = torch.operator "onnx.Cast"(%2058) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2026)
    %2060 = torch.operator "onnx.Mul"(%39, %2059) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2027)
    %2061 = torch.operator "onnx.MatMul"(%2060, %194) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2028)
    %2062 = torch.operator "onnx.MatMul"(%2060, %195) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2029)
    %2063 = torch.operator "onnx.MatMul"(%2060, %196) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2030)
    %2064 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2031)
    %2065 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2032)
    %2066 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2033)
    %2067 = torch.operator "onnx.Reshape"(%2061, %2064) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2034)
    %2068 = torch.operator "onnx.Transpose"(%2067) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2035)
    %2069 = torch.operator "onnx.Reshape"(%2062, %2065) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2036)
    %2070 = torch.operator "onnx.Transpose"(%2069) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2037)
    %2071 = torch.operator "onnx.Reshape"(%2063, %2066) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2038)
    %2072 = torch.operator "onnx.Transpose"(%2071) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2039)
    %2073 = torch_c.to_builtin_tensor %2072 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2074 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2040)
    %2075 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2041)
    %2076 = torch.operator "onnx.Gather"(%2074, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2042)
    %2077 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2043)
    %2078 = torch.operator "onnx.Unsqueeze"(%2076, %2077) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2044)
    %2079 = torch.operator "onnx.Gather"(%2075, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2045)
    %2080 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2046)
    %2081 = torch.operator "onnx.Unsqueeze"(%2079, %2080) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2047)
    %2082 = torch.operator "onnx.Mul"(%2068, %2078) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2048)
    %2083 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2049)
    %2084 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2050)
    %2085 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2051)
    %2086 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2052)
    %2087 = torch.operator "onnx.Slice"(%2068, %2084, %2085, %2083, %2086) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2053)
    %2088 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2054)
    %2089 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2055)
    %2090 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2056)
    %2091 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2057)
    %2092 = torch.operator "onnx.Slice"(%2068, %2089, %2090, %2088, %2091) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2058)
    %2093 = torch.operator "onnx.Neg"(%2092) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2059)
    %2094 = torch.operator "onnx.Concat"(%2093, %2087) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2060)
    %2095 = torch.operator "onnx.Mul"(%2094, %2081) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2061)
    %2096 = torch.operator "onnx.Add"(%2082, %2095) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2062)
    %2097 = torch.operator "onnx.Mul"(%2070, %2078) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2063)
    %2098 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2064)
    %2099 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2065)
    %2100 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2066)
    %2101 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2067)
    %2102 = torch.operator "onnx.Slice"(%2070, %2099, %2100, %2098, %2101) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2068)
    %2103 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2069)
    %2104 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2070)
    %2105 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2071)
    %2106 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2072)
    %2107 = torch.operator "onnx.Slice"(%2070, %2104, %2105, %2103, %2106) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2073)
    %2108 = torch.operator "onnx.Neg"(%2107) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2074)
    %2109 = torch.operator "onnx.Concat"(%2108, %2102) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2075)
    %2110 = torch.operator "onnx.Mul"(%2109, %2081) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2076)
    %2111 = torch.operator "onnx.Add"(%2097, %2110) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2077)
    %2112 = torch_c.to_builtin_tensor %2111 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2113 = torch.operator "onnx.Transpose"(%2111) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2078)
    %2114 = torch.operator "onnx.MatMul"(%2096, %2113) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2079)
    %2115 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2080)
    %2116 = torch.operator "onnx.Div"(%2114, %2115) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2081)
    %2117 = torch.operator "onnx.Add"(%2116, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2082)
    %2118 = torch.operator "onnx.Softmax"(%2117) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2083)
    %2119 = torch.operator "onnx.Cast"(%2118) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2084)
    %2120 = torch.operator "onnx.Cast"(%2119) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2085)
    %2121 = torch.operator "onnx.MatMul"(%2120, %2072) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2086)
    %2122 = torch.operator "onnx.Transpose"(%2121) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2087)
    %2123 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2088)
    %2124 = torch.operator "onnx.Reshape"(%2122, %2123) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2089)
    %2125 = torch.operator "onnx.MatMul"(%2124, %197) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2090)
    %2126 = torch.operator "onnx.Add"(%2049, %2125) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2091)
    %2127 = torch.operator "onnx.Cast"(%2126) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2092)
    %2128 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2093)
    %2129 = torch.operator "onnx.Pow"(%2127, %2128) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2094)
    %2130 = torch.operator "onnx.ReduceMean"(%2129) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2095)
    %2131 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2096)
    %2132 = torch.operator "onnx.Add"(%2130, %2131) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2097)
    %2133 = torch.operator "onnx.Sqrt"(%2132) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2098)
    %2134 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.18_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2099)
    %2135 = torch.operator "onnx.Div"(%2134, %2133) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2100)
    %2136 = torch.operator "onnx.Mul"(%2127, %2135) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2101)
    %2137 = torch.operator "onnx.Cast"(%2136) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2102)
    %2138 = torch.operator "onnx.Mul"(%40, %2137) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2103)
    %2139 = torch.operator "onnx.MatMul"(%2138, %198) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2104)
    %2140 = torch.operator "onnx.Sigmoid"(%2139) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2105)
    %2141 = torch.operator "onnx.Mul"(%2139, %2140) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2106)
    %2142 = torch.operator "onnx.MatMul"(%2138, %199) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2107)
    %2143 = torch.operator "onnx.Mul"(%2141, %2142) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2108)
    %2144 = torch.operator "onnx.MatMul"(%2143, %200) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2109)
    %2145 = torch.operator "onnx.Add"(%2127, %2144) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2110)
    %2146 = torch.operator "onnx.Cast"(%2145) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2111)
    %2147 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2112)
    %2148 = torch.operator "onnx.Pow"(%2146, %2147) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2113)
    %2149 = torch.operator "onnx.ReduceMean"(%2148) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2114)
    %2150 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2115)
    %2151 = torch.operator "onnx.Add"(%2149, %2150) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2116)
    %2152 = torch.operator "onnx.Sqrt"(%2151) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2117)
    %2153 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2118)
    %2154 = torch.operator "onnx.Div"(%2153, %2152) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2119)
    %2155 = torch.operator "onnx.Mul"(%2146, %2154) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2120)
    %2156 = torch.operator "onnx.Cast"(%2155) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2121)
    %2157 = torch.operator "onnx.Mul"(%41, %2156) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2122)
    %2158 = torch.operator "onnx.MatMul"(%2157, %201) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2123)
    %2159 = torch.operator "onnx.MatMul"(%2157, %202) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2124)
    %2160 = torch.operator "onnx.MatMul"(%2157, %203) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2125)
    %2161 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2126)
    %2162 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2127)
    %2163 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2128)
    %2164 = torch.operator "onnx.Reshape"(%2158, %2161) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2129)
    %2165 = torch.operator "onnx.Transpose"(%2164) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2130)
    %2166 = torch.operator "onnx.Reshape"(%2159, %2162) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2131)
    %2167 = torch.operator "onnx.Transpose"(%2166) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2132)
    %2168 = torch.operator "onnx.Reshape"(%2160, %2163) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2133)
    %2169 = torch.operator "onnx.Transpose"(%2168) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2134)
    %2170 = torch_c.to_builtin_tensor %2169 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2171 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2135)
    %2172 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2136)
    %2173 = torch.operator "onnx.Gather"(%2171, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2137)
    %2174 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2138)
    %2175 = torch.operator "onnx.Unsqueeze"(%2173, %2174) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2139)
    %2176 = torch.operator "onnx.Gather"(%2172, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2140)
    %2177 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2141)
    %2178 = torch.operator "onnx.Unsqueeze"(%2176, %2177) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2142)
    %2179 = torch.operator "onnx.Mul"(%2165, %2175) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2143)
    %2180 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2144)
    %2181 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2145)
    %2182 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2146)
    %2183 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2147)
    %2184 = torch.operator "onnx.Slice"(%2165, %2181, %2182, %2180, %2183) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2148)
    %2185 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2149)
    %2186 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2150)
    %2187 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2151)
    %2188 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2152)
    %2189 = torch.operator "onnx.Slice"(%2165, %2186, %2187, %2185, %2188) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2153)
    %2190 = torch.operator "onnx.Neg"(%2189) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2154)
    %2191 = torch.operator "onnx.Concat"(%2190, %2184) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2155)
    %2192 = torch.operator "onnx.Mul"(%2191, %2178) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2156)
    %2193 = torch.operator "onnx.Add"(%2179, %2192) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2157)
    %2194 = torch.operator "onnx.Mul"(%2167, %2175) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2158)
    %2195 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2159)
    %2196 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2160)
    %2197 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2161)
    %2198 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2162)
    %2199 = torch.operator "onnx.Slice"(%2167, %2196, %2197, %2195, %2198) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2163)
    %2200 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2164)
    %2201 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2165)
    %2202 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2166)
    %2203 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2167)
    %2204 = torch.operator "onnx.Slice"(%2167, %2201, %2202, %2200, %2203) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2168)
    %2205 = torch.operator "onnx.Neg"(%2204) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2169)
    %2206 = torch.operator "onnx.Concat"(%2205, %2199) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2170)
    %2207 = torch.operator "onnx.Mul"(%2206, %2178) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2171)
    %2208 = torch.operator "onnx.Add"(%2194, %2207) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2172)
    %2209 = torch_c.to_builtin_tensor %2208 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2210 = torch.operator "onnx.Transpose"(%2208) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2173)
    %2211 = torch.operator "onnx.MatMul"(%2193, %2210) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2174)
    %2212 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2175)
    %2213 = torch.operator "onnx.Div"(%2211, %2212) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2176)
    %2214 = torch.operator "onnx.Add"(%2213, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2177)
    %2215 = torch.operator "onnx.Softmax"(%2214) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2178)
    %2216 = torch.operator "onnx.Cast"(%2215) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2179)
    %2217 = torch.operator "onnx.Cast"(%2216) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2180)
    %2218 = torch.operator "onnx.MatMul"(%2217, %2169) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2181)
    %2219 = torch.operator "onnx.Transpose"(%2218) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2182)
    %2220 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2183)
    %2221 = torch.operator "onnx.Reshape"(%2219, %2220) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2184)
    %2222 = torch.operator "onnx.MatMul"(%2221, %204) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2185)
    %2223 = torch.operator "onnx.Add"(%2146, %2222) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2186)
    %2224 = torch.operator "onnx.Cast"(%2223) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2187)
    %2225 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2188)
    %2226 = torch.operator "onnx.Pow"(%2224, %2225) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2189)
    %2227 = torch.operator "onnx.ReduceMean"(%2226) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2190)
    %2228 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2191)
    %2229 = torch.operator "onnx.Add"(%2227, %2228) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2192)
    %2230 = torch.operator "onnx.Sqrt"(%2229) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2193)
    %2231 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.19_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2194)
    %2232 = torch.operator "onnx.Div"(%2231, %2230) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2195)
    %2233 = torch.operator "onnx.Mul"(%2224, %2232) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2196)
    %2234 = torch.operator "onnx.Cast"(%2233) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2197)
    %2235 = torch.operator "onnx.Mul"(%42, %2234) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2198)
    %2236 = torch.operator "onnx.MatMul"(%2235, %205) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2199)
    %2237 = torch.operator "onnx.Sigmoid"(%2236) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2200)
    %2238 = torch.operator "onnx.Mul"(%2236, %2237) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2201)
    %2239 = torch.operator "onnx.MatMul"(%2235, %206) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2202)
    %2240 = torch.operator "onnx.Mul"(%2238, %2239) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2203)
    %2241 = torch.operator "onnx.MatMul"(%2240, %207) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2204)
    %2242 = torch.operator "onnx.Add"(%2224, %2241) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2205)
    %2243 = torch.operator "onnx.Cast"(%2242) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2206)
    %2244 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2207)
    %2245 = torch.operator "onnx.Pow"(%2243, %2244) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2208)
    %2246 = torch.operator "onnx.ReduceMean"(%2245) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2209)
    %2247 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2210)
    %2248 = torch.operator "onnx.Add"(%2246, %2247) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2211)
    %2249 = torch.operator "onnx.Sqrt"(%2248) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2212)
    %2250 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2213)
    %2251 = torch.operator "onnx.Div"(%2250, %2249) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2214)
    %2252 = torch.operator "onnx.Mul"(%2243, %2251) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2215)
    %2253 = torch.operator "onnx.Cast"(%2252) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2216)
    %2254 = torch.operator "onnx.Mul"(%43, %2253) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2217)
    %2255 = torch.operator "onnx.MatMul"(%2254, %208) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2218)
    %2256 = torch.operator "onnx.MatMul"(%2254, %209) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2219)
    %2257 = torch.operator "onnx.MatMul"(%2254, %210) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2220)
    %2258 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2221)
    %2259 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2222)
    %2260 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2223)
    %2261 = torch.operator "onnx.Reshape"(%2255, %2258) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2224)
    %2262 = torch.operator "onnx.Transpose"(%2261) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2225)
    %2263 = torch.operator "onnx.Reshape"(%2256, %2259) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2226)
    %2264 = torch.operator "onnx.Transpose"(%2263) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2227)
    %2265 = torch.operator "onnx.Reshape"(%2257, %2260) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2228)
    %2266 = torch.operator "onnx.Transpose"(%2265) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2229)
    %2267 = torch_c.to_builtin_tensor %2266 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2268 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2230)
    %2269 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2231)
    %2270 = torch.operator "onnx.Gather"(%2268, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2232)
    %2271 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2233)
    %2272 = torch.operator "onnx.Unsqueeze"(%2270, %2271) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2234)
    %2273 = torch.operator "onnx.Gather"(%2269, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2235)
    %2274 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2236)
    %2275 = torch.operator "onnx.Unsqueeze"(%2273, %2274) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2237)
    %2276 = torch.operator "onnx.Mul"(%2262, %2272) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2238)
    %2277 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2239)
    %2278 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2240)
    %2279 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2241)
    %2280 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2242)
    %2281 = torch.operator "onnx.Slice"(%2262, %2278, %2279, %2277, %2280) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2243)
    %2282 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2244)
    %2283 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2245)
    %2284 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2246)
    %2285 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2247)
    %2286 = torch.operator "onnx.Slice"(%2262, %2283, %2284, %2282, %2285) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2248)
    %2287 = torch.operator "onnx.Neg"(%2286) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2249)
    %2288 = torch.operator "onnx.Concat"(%2287, %2281) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2250)
    %2289 = torch.operator "onnx.Mul"(%2288, %2275) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2251)
    %2290 = torch.operator "onnx.Add"(%2276, %2289) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2252)
    %2291 = torch.operator "onnx.Mul"(%2264, %2272) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2253)
    %2292 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2254)
    %2293 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2255)
    %2294 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2256)
    %2295 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2257)
    %2296 = torch.operator "onnx.Slice"(%2264, %2293, %2294, %2292, %2295) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2258)
    %2297 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2259)
    %2298 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2260)
    %2299 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2261)
    %2300 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2262)
    %2301 = torch.operator "onnx.Slice"(%2264, %2298, %2299, %2297, %2300) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2263)
    %2302 = torch.operator "onnx.Neg"(%2301) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2264)
    %2303 = torch.operator "onnx.Concat"(%2302, %2296) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2265)
    %2304 = torch.operator "onnx.Mul"(%2303, %2275) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2266)
    %2305 = torch.operator "onnx.Add"(%2291, %2304) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2267)
    %2306 = torch_c.to_builtin_tensor %2305 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2307 = torch.operator "onnx.Transpose"(%2305) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2268)
    %2308 = torch.operator "onnx.MatMul"(%2290, %2307) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2269)
    %2309 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2270)
    %2310 = torch.operator "onnx.Div"(%2308, %2309) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2271)
    %2311 = torch.operator "onnx.Add"(%2310, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2272)
    %2312 = torch.operator "onnx.Softmax"(%2311) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2273)
    %2313 = torch.operator "onnx.Cast"(%2312) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2274)
    %2314 = torch.operator "onnx.Cast"(%2313) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2275)
    %2315 = torch.operator "onnx.MatMul"(%2314, %2266) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2276)
    %2316 = torch.operator "onnx.Transpose"(%2315) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2277)
    %2317 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2278)
    %2318 = torch.operator "onnx.Reshape"(%2316, %2317) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2279)
    %2319 = torch.operator "onnx.MatMul"(%2318, %211) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2280)
    %2320 = torch.operator "onnx.Add"(%2243, %2319) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2281)
    %2321 = torch.operator "onnx.Cast"(%2320) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2282)
    %2322 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2283)
    %2323 = torch.operator "onnx.Pow"(%2321, %2322) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2284)
    %2324 = torch.operator "onnx.ReduceMean"(%2323) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2285)
    %2325 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2286)
    %2326 = torch.operator "onnx.Add"(%2324, %2325) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2287)
    %2327 = torch.operator "onnx.Sqrt"(%2326) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2288)
    %2328 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.20_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2289)
    %2329 = torch.operator "onnx.Div"(%2328, %2327) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2290)
    %2330 = torch.operator "onnx.Mul"(%2321, %2329) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2291)
    %2331 = torch.operator "onnx.Cast"(%2330) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2292)
    %2332 = torch.operator "onnx.Mul"(%44, %2331) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2293)
    %2333 = torch.operator "onnx.MatMul"(%2332, %212) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2294)
    %2334 = torch.operator "onnx.Sigmoid"(%2333) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2295)
    %2335 = torch.operator "onnx.Mul"(%2333, %2334) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2296)
    %2336 = torch.operator "onnx.MatMul"(%2332, %213) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2297)
    %2337 = torch.operator "onnx.Mul"(%2335, %2336) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2298)
    %2338 = torch.operator "onnx.MatMul"(%2337, %214) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2299)
    %2339 = torch.operator "onnx.Add"(%2321, %2338) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2300)
    %2340 = torch.operator "onnx.Cast"(%2339) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2301)
    %2341 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2302)
    %2342 = torch.operator "onnx.Pow"(%2340, %2341) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2303)
    %2343 = torch.operator "onnx.ReduceMean"(%2342) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2304)
    %2344 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2305)
    %2345 = torch.operator "onnx.Add"(%2343, %2344) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2306)
    %2346 = torch.operator "onnx.Sqrt"(%2345) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2307)
    %2347 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2308)
    %2348 = torch.operator "onnx.Div"(%2347, %2346) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2309)
    %2349 = torch.operator "onnx.Mul"(%2340, %2348) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2310)
    %2350 = torch.operator "onnx.Cast"(%2349) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2311)
    %2351 = torch.operator "onnx.Mul"(%45, %2350) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2312)
    %2352 = torch.operator "onnx.MatMul"(%2351, %215) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2313)
    %2353 = torch.operator "onnx.MatMul"(%2351, %216) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2314)
    %2354 = torch.operator "onnx.MatMul"(%2351, %217) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2315)
    %2355 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2316)
    %2356 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2317)
    %2357 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2318)
    %2358 = torch.operator "onnx.Reshape"(%2352, %2355) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2319)
    %2359 = torch.operator "onnx.Transpose"(%2358) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2320)
    %2360 = torch.operator "onnx.Reshape"(%2353, %2356) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2321)
    %2361 = torch.operator "onnx.Transpose"(%2360) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2322)
    %2362 = torch.operator "onnx.Reshape"(%2354, %2357) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2323)
    %2363 = torch.operator "onnx.Transpose"(%2362) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2324)
    %2364 = torch_c.to_builtin_tensor %2363 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2365 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2325)
    %2366 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2326)
    %2367 = torch.operator "onnx.Gather"(%2365, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2327)
    %2368 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2328)
    %2369 = torch.operator "onnx.Unsqueeze"(%2367, %2368) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2329)
    %2370 = torch.operator "onnx.Gather"(%2366, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2330)
    %2371 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2331)
    %2372 = torch.operator "onnx.Unsqueeze"(%2370, %2371) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2332)
    %2373 = torch.operator "onnx.Mul"(%2359, %2369) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2333)
    %2374 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2334)
    %2375 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2335)
    %2376 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2336)
    %2377 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2337)
    %2378 = torch.operator "onnx.Slice"(%2359, %2375, %2376, %2374, %2377) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2338)
    %2379 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2339)
    %2380 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2340)
    %2381 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2341)
    %2382 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2342)
    %2383 = torch.operator "onnx.Slice"(%2359, %2380, %2381, %2379, %2382) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2343)
    %2384 = torch.operator "onnx.Neg"(%2383) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2344)
    %2385 = torch.operator "onnx.Concat"(%2384, %2378) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2345)
    %2386 = torch.operator "onnx.Mul"(%2385, %2372) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2346)
    %2387 = torch.operator "onnx.Add"(%2373, %2386) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2347)
    %2388 = torch.operator "onnx.Mul"(%2361, %2369) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2348)
    %2389 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2349)
    %2390 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2350)
    %2391 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2351)
    %2392 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2352)
    %2393 = torch.operator "onnx.Slice"(%2361, %2390, %2391, %2389, %2392) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2353)
    %2394 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2354)
    %2395 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2355)
    %2396 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2356)
    %2397 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2357)
    %2398 = torch.operator "onnx.Slice"(%2361, %2395, %2396, %2394, %2397) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2358)
    %2399 = torch.operator "onnx.Neg"(%2398) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2359)
    %2400 = torch.operator "onnx.Concat"(%2399, %2393) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2360)
    %2401 = torch.operator "onnx.Mul"(%2400, %2372) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2361)
    %2402 = torch.operator "onnx.Add"(%2388, %2401) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2362)
    %2403 = torch_c.to_builtin_tensor %2402 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2404 = torch.operator "onnx.Transpose"(%2402) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2363)
    %2405 = torch.operator "onnx.MatMul"(%2387, %2404) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2364)
    %2406 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2365)
    %2407 = torch.operator "onnx.Div"(%2405, %2406) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2366)
    %2408 = torch.operator "onnx.Add"(%2407, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2367)
    %2409 = torch.operator "onnx.Softmax"(%2408) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2368)
    %2410 = torch.operator "onnx.Cast"(%2409) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2369)
    %2411 = torch.operator "onnx.Cast"(%2410) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2370)
    %2412 = torch.operator "onnx.MatMul"(%2411, %2363) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2371)
    %2413 = torch.operator "onnx.Transpose"(%2412) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2372)
    %2414 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2373)
    %2415 = torch.operator "onnx.Reshape"(%2413, %2414) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2374)
    %2416 = torch.operator "onnx.MatMul"(%2415, %218) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2375)
    %2417 = torch.operator "onnx.Add"(%2340, %2416) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2376)
    %2418 = torch.operator "onnx.Cast"(%2417) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2377)
    %2419 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2378)
    %2420 = torch.operator "onnx.Pow"(%2418, %2419) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2379)
    %2421 = torch.operator "onnx.ReduceMean"(%2420) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2380)
    %2422 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2381)
    %2423 = torch.operator "onnx.Add"(%2421, %2422) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2382)
    %2424 = torch.operator "onnx.Sqrt"(%2423) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2383)
    %2425 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.21_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2384)
    %2426 = torch.operator "onnx.Div"(%2425, %2424) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2385)
    %2427 = torch.operator "onnx.Mul"(%2418, %2426) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2386)
    %2428 = torch.operator "onnx.Cast"(%2427) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2387)
    %2429 = torch.operator "onnx.Mul"(%46, %2428) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2388)
    %2430 = torch.operator "onnx.MatMul"(%2429, %219) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2389)
    %2431 = torch.operator "onnx.Sigmoid"(%2430) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2390)
    %2432 = torch.operator "onnx.Mul"(%2430, %2431) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2391)
    %2433 = torch.operator "onnx.MatMul"(%2429, %220) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2392)
    %2434 = torch.operator "onnx.Mul"(%2432, %2433) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2393)
    %2435 = torch.operator "onnx.MatMul"(%2434, %221) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2394)
    %2436 = torch.operator "onnx.Add"(%2418, %2435) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2395)
    %2437 = torch.operator "onnx.Cast"(%2436) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2396)
    %2438 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2397)
    %2439 = torch.operator "onnx.Pow"(%2437, %2438) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2398)
    %2440 = torch.operator "onnx.ReduceMean"(%2439) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2399)
    %2441 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2400)
    %2442 = torch.operator "onnx.Add"(%2440, %2441) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2401)
    %2443 = torch.operator "onnx.Sqrt"(%2442) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2402)
    %2444 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2403)
    %2445 = torch.operator "onnx.Div"(%2444, %2443) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2404)
    %2446 = torch.operator "onnx.Mul"(%2437, %2445) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2405)
    %2447 = torch.operator "onnx.Cast"(%2446) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2406)
    %2448 = torch.operator "onnx.Mul"(%47, %2447) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2407)
    %2449 = torch.operator "onnx.MatMul"(%2448, %222) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2408)
    %2450 = torch.operator "onnx.MatMul"(%2448, %223) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2409)
    %2451 = torch.operator "onnx.MatMul"(%2448, %224) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2410)
    %2452 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2411)
    %2453 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2412)
    %2454 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2413)
    %2455 = torch.operator "onnx.Reshape"(%2449, %2452) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2414)
    %2456 = torch.operator "onnx.Transpose"(%2455) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2415)
    %2457 = torch.operator "onnx.Reshape"(%2450, %2453) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2416)
    %2458 = torch.operator "onnx.Transpose"(%2457) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2417)
    %2459 = torch.operator "onnx.Reshape"(%2451, %2454) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2418)
    %2460 = torch.operator "onnx.Transpose"(%2459) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2419)
    %2461 = torch_c.to_builtin_tensor %2460 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2462 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2420)
    %2463 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2421)
    %2464 = torch.operator "onnx.Gather"(%2462, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2422)
    %2465 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2423)
    %2466 = torch.operator "onnx.Unsqueeze"(%2464, %2465) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2424)
    %2467 = torch.operator "onnx.Gather"(%2463, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2425)
    %2468 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2426)
    %2469 = torch.operator "onnx.Unsqueeze"(%2467, %2468) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2427)
    %2470 = torch.operator "onnx.Mul"(%2456, %2466) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2428)
    %2471 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2429)
    %2472 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2430)
    %2473 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2431)
    %2474 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2432)
    %2475 = torch.operator "onnx.Slice"(%2456, %2472, %2473, %2471, %2474) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2433)
    %2476 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2434)
    %2477 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2435)
    %2478 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2436)
    %2479 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2437)
    %2480 = torch.operator "onnx.Slice"(%2456, %2477, %2478, %2476, %2479) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2438)
    %2481 = torch.operator "onnx.Neg"(%2480) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2439)
    %2482 = torch.operator "onnx.Concat"(%2481, %2475) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2440)
    %2483 = torch.operator "onnx.Mul"(%2482, %2469) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2441)
    %2484 = torch.operator "onnx.Add"(%2470, %2483) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2442)
    %2485 = torch.operator "onnx.Mul"(%2458, %2466) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2443)
    %2486 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2444)
    %2487 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2445)
    %2488 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2446)
    %2489 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2447)
    %2490 = torch.operator "onnx.Slice"(%2458, %2487, %2488, %2486, %2489) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2448)
    %2491 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2449)
    %2492 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2450)
    %2493 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2451)
    %2494 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2452)
    %2495 = torch.operator "onnx.Slice"(%2458, %2492, %2493, %2491, %2494) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2453)
    %2496 = torch.operator "onnx.Neg"(%2495) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2454)
    %2497 = torch.operator "onnx.Concat"(%2496, %2490) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2455)
    %2498 = torch.operator "onnx.Mul"(%2497, %2469) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2456)
    %2499 = torch.operator "onnx.Add"(%2485, %2498) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2457)
    %2500 = torch_c.to_builtin_tensor %2499 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2501 = torch.operator "onnx.Transpose"(%2499) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2458)
    %2502 = torch.operator "onnx.MatMul"(%2484, %2501) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2459)
    %2503 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2460)
    %2504 = torch.operator "onnx.Div"(%2502, %2503) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2461)
    %2505 = torch.operator "onnx.Add"(%2504, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2462)
    %2506 = torch.operator "onnx.Softmax"(%2505) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2463)
    %2507 = torch.operator "onnx.Cast"(%2506) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2464)
    %2508 = torch.operator "onnx.Cast"(%2507) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2465)
    %2509 = torch.operator "onnx.MatMul"(%2508, %2460) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2466)
    %2510 = torch.operator "onnx.Transpose"(%2509) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2467)
    %2511 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2468)
    %2512 = torch.operator "onnx.Reshape"(%2510, %2511) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2469)
    %2513 = torch.operator "onnx.MatMul"(%2512, %225) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2470)
    %2514 = torch.operator "onnx.Add"(%2437, %2513) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2471)
    %2515 = torch.operator "onnx.Cast"(%2514) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2472)
    %2516 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2473)
    %2517 = torch.operator "onnx.Pow"(%2515, %2516) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2474)
    %2518 = torch.operator "onnx.ReduceMean"(%2517) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2475)
    %2519 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2476)
    %2520 = torch.operator "onnx.Add"(%2518, %2519) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2477)
    %2521 = torch.operator "onnx.Sqrt"(%2520) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2478)
    %2522 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.22_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2479)
    %2523 = torch.operator "onnx.Div"(%2522, %2521) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2480)
    %2524 = torch.operator "onnx.Mul"(%2515, %2523) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2481)
    %2525 = torch.operator "onnx.Cast"(%2524) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2482)
    %2526 = torch.operator "onnx.Mul"(%48, %2525) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2483)
    %2527 = torch.operator "onnx.MatMul"(%2526, %226) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2484)
    %2528 = torch.operator "onnx.Sigmoid"(%2527) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2485)
    %2529 = torch.operator "onnx.Mul"(%2527, %2528) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2486)
    %2530 = torch.operator "onnx.MatMul"(%2526, %227) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2487)
    %2531 = torch.operator "onnx.Mul"(%2529, %2530) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2488)
    %2532 = torch.operator "onnx.MatMul"(%2531, %228) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2489)
    %2533 = torch.operator "onnx.Add"(%2515, %2532) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2490)
    %2534 = torch.operator "onnx.Cast"(%2533) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2491)
    %2535 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2492)
    %2536 = torch.operator "onnx.Pow"(%2534, %2535) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2493)
    %2537 = torch.operator "onnx.ReduceMean"(%2536) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2494)
    %2538 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2495)
    %2539 = torch.operator "onnx.Add"(%2537, %2538) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2496)
    %2540 = torch.operator "onnx.Sqrt"(%2539) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2497)
    %2541 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2498)
    %2542 = torch.operator "onnx.Div"(%2541, %2540) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2499)
    %2543 = torch.operator "onnx.Mul"(%2534, %2542) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2500)
    %2544 = torch.operator "onnx.Cast"(%2543) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2501)
    %2545 = torch.operator "onnx.Mul"(%49, %2544) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2502)
    %2546 = torch.operator "onnx.MatMul"(%2545, %229) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2503)
    %2547 = torch.operator "onnx.MatMul"(%2545, %230) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2504)
    %2548 = torch.operator "onnx.MatMul"(%2545, %231) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2505)
    %2549 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2506)
    %2550 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2507)
    %2551 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2508)
    %2552 = torch.operator "onnx.Reshape"(%2546, %2549) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2509)
    %2553 = torch.operator "onnx.Transpose"(%2552) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2510)
    %2554 = torch.operator "onnx.Reshape"(%2547, %2550) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2511)
    %2555 = torch.operator "onnx.Transpose"(%2554) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2512)
    %2556 = torch.operator "onnx.Reshape"(%2548, %2551) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2513)
    %2557 = torch.operator "onnx.Transpose"(%2556) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2514)
    %2558 = torch_c.to_builtin_tensor %2557 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2559 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2515)
    %2560 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2516)
    %2561 = torch.operator "onnx.Gather"(%2559, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2517)
    %2562 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2518)
    %2563 = torch.operator "onnx.Unsqueeze"(%2561, %2562) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2519)
    %2564 = torch.operator "onnx.Gather"(%2560, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2520)
    %2565 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2521)
    %2566 = torch.operator "onnx.Unsqueeze"(%2564, %2565) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2522)
    %2567 = torch.operator "onnx.Mul"(%2553, %2563) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2523)
    %2568 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2524)
    %2569 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2525)
    %2570 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2526)
    %2571 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2527)
    %2572 = torch.operator "onnx.Slice"(%2553, %2569, %2570, %2568, %2571) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2528)
    %2573 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2529)
    %2574 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2530)
    %2575 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2531)
    %2576 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2532)
    %2577 = torch.operator "onnx.Slice"(%2553, %2574, %2575, %2573, %2576) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2533)
    %2578 = torch.operator "onnx.Neg"(%2577) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2534)
    %2579 = torch.operator "onnx.Concat"(%2578, %2572) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2535)
    %2580 = torch.operator "onnx.Mul"(%2579, %2566) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2536)
    %2581 = torch.operator "onnx.Add"(%2567, %2580) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2537)
    %2582 = torch.operator "onnx.Mul"(%2555, %2563) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2538)
    %2583 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2539)
    %2584 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2540)
    %2585 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2541)
    %2586 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2542)
    %2587 = torch.operator "onnx.Slice"(%2555, %2584, %2585, %2583, %2586) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2543)
    %2588 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2544)
    %2589 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2545)
    %2590 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2546)
    %2591 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2547)
    %2592 = torch.operator "onnx.Slice"(%2555, %2589, %2590, %2588, %2591) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2548)
    %2593 = torch.operator "onnx.Neg"(%2592) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2549)
    %2594 = torch.operator "onnx.Concat"(%2593, %2587) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2550)
    %2595 = torch.operator "onnx.Mul"(%2594, %2566) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2551)
    %2596 = torch.operator "onnx.Add"(%2582, %2595) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2552)
    %2597 = torch_c.to_builtin_tensor %2596 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2598 = torch.operator "onnx.Transpose"(%2596) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2553)
    %2599 = torch.operator "onnx.MatMul"(%2581, %2598) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2554)
    %2600 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2555)
    %2601 = torch.operator "onnx.Div"(%2599, %2600) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2556)
    %2602 = torch.operator "onnx.Add"(%2601, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2557)
    %2603 = torch.operator "onnx.Softmax"(%2602) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2558)
    %2604 = torch.operator "onnx.Cast"(%2603) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2559)
    %2605 = torch.operator "onnx.Cast"(%2604) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2560)
    %2606 = torch.operator "onnx.MatMul"(%2605, %2557) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2561)
    %2607 = torch.operator "onnx.Transpose"(%2606) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2562)
    %2608 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2563)
    %2609 = torch.operator "onnx.Reshape"(%2607, %2608) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2564)
    %2610 = torch.operator "onnx.MatMul"(%2609, %232) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2565)
    %2611 = torch.operator "onnx.Add"(%2534, %2610) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2566)
    %2612 = torch.operator "onnx.Cast"(%2611) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2567)
    %2613 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2568)
    %2614 = torch.operator "onnx.Pow"(%2612, %2613) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2569)
    %2615 = torch.operator "onnx.ReduceMean"(%2614) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2570)
    %2616 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2571)
    %2617 = torch.operator "onnx.Add"(%2615, %2616) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2572)
    %2618 = torch.operator "onnx.Sqrt"(%2617) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2573)
    %2619 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.23_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2574)
    %2620 = torch.operator "onnx.Div"(%2619, %2618) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2575)
    %2621 = torch.operator "onnx.Mul"(%2612, %2620) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2576)
    %2622 = torch.operator "onnx.Cast"(%2621) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2577)
    %2623 = torch.operator "onnx.Mul"(%50, %2622) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2578)
    %2624 = torch.operator "onnx.MatMul"(%2623, %233) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2579)
    %2625 = torch.operator "onnx.Sigmoid"(%2624) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2580)
    %2626 = torch.operator "onnx.Mul"(%2624, %2625) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2581)
    %2627 = torch.operator "onnx.MatMul"(%2623, %234) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2582)
    %2628 = torch.operator "onnx.Mul"(%2626, %2627) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2583)
    %2629 = torch.operator "onnx.MatMul"(%2628, %235) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2584)
    %2630 = torch.operator "onnx.Add"(%2612, %2629) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2585)
    %2631 = torch.operator "onnx.Cast"(%2630) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2586)
    %2632 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2587)
    %2633 = torch.operator "onnx.Pow"(%2631, %2632) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2588)
    %2634 = torch.operator "onnx.ReduceMean"(%2633) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2589)
    %2635 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2590)
    %2636 = torch.operator "onnx.Add"(%2634, %2635) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2591)
    %2637 = torch.operator "onnx.Sqrt"(%2636) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2592)
    %2638 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2593)
    %2639 = torch.operator "onnx.Div"(%2638, %2637) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2594)
    %2640 = torch.operator "onnx.Mul"(%2631, %2639) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2595)
    %2641 = torch.operator "onnx.Cast"(%2640) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2596)
    %2642 = torch.operator "onnx.Mul"(%51, %2641) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2597)
    %2643 = torch.operator "onnx.MatMul"(%2642, %236) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2598)
    %2644 = torch.operator "onnx.MatMul"(%2642, %237) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2599)
    %2645 = torch.operator "onnx.MatMul"(%2642, %238) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2600)
    %2646 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2601)
    %2647 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2602)
    %2648 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2603)
    %2649 = torch.operator "onnx.Reshape"(%2643, %2646) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2604)
    %2650 = torch.operator "onnx.Transpose"(%2649) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2605)
    %2651 = torch.operator "onnx.Reshape"(%2644, %2647) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2606)
    %2652 = torch.operator "onnx.Transpose"(%2651) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2607)
    %2653 = torch.operator "onnx.Reshape"(%2645, %2648) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2608)
    %2654 = torch.operator "onnx.Transpose"(%2653) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2609)
    %2655 = torch_c.to_builtin_tensor %2654 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2656 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2610)
    %2657 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2611)
    %2658 = torch.operator "onnx.Gather"(%2656, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2612)
    %2659 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2613)
    %2660 = torch.operator "onnx.Unsqueeze"(%2658, %2659) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2614)
    %2661 = torch.operator "onnx.Gather"(%2657, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2615)
    %2662 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2616)
    %2663 = torch.operator "onnx.Unsqueeze"(%2661, %2662) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2617)
    %2664 = torch.operator "onnx.Mul"(%2650, %2660) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2618)
    %2665 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2619)
    %2666 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2620)
    %2667 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2621)
    %2668 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2622)
    %2669 = torch.operator "onnx.Slice"(%2650, %2666, %2667, %2665, %2668) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2623)
    %2670 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2624)
    %2671 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2625)
    %2672 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2626)
    %2673 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2627)
    %2674 = torch.operator "onnx.Slice"(%2650, %2671, %2672, %2670, %2673) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2628)
    %2675 = torch.operator "onnx.Neg"(%2674) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2629)
    %2676 = torch.operator "onnx.Concat"(%2675, %2669) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2630)
    %2677 = torch.operator "onnx.Mul"(%2676, %2663) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2631)
    %2678 = torch.operator "onnx.Add"(%2664, %2677) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2632)
    %2679 = torch.operator "onnx.Mul"(%2652, %2660) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2633)
    %2680 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2634)
    %2681 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2635)
    %2682 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2636)
    %2683 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2637)
    %2684 = torch.operator "onnx.Slice"(%2652, %2681, %2682, %2680, %2683) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2638)
    %2685 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2639)
    %2686 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2640)
    %2687 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2641)
    %2688 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2642)
    %2689 = torch.operator "onnx.Slice"(%2652, %2686, %2687, %2685, %2688) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2643)
    %2690 = torch.operator "onnx.Neg"(%2689) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2644)
    %2691 = torch.operator "onnx.Concat"(%2690, %2684) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2645)
    %2692 = torch.operator "onnx.Mul"(%2691, %2663) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2646)
    %2693 = torch.operator "onnx.Add"(%2679, %2692) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2647)
    %2694 = torch_c.to_builtin_tensor %2693 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2695 = torch.operator "onnx.Transpose"(%2693) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2648)
    %2696 = torch.operator "onnx.MatMul"(%2678, %2695) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2649)
    %2697 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2650)
    %2698 = torch.operator "onnx.Div"(%2696, %2697) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2651)
    %2699 = torch.operator "onnx.Add"(%2698, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2652)
    %2700 = torch.operator "onnx.Softmax"(%2699) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2653)
    %2701 = torch.operator "onnx.Cast"(%2700) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2654)
    %2702 = torch.operator "onnx.Cast"(%2701) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2655)
    %2703 = torch.operator "onnx.MatMul"(%2702, %2654) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2656)
    %2704 = torch.operator "onnx.Transpose"(%2703) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2657)
    %2705 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2658)
    %2706 = torch.operator "onnx.Reshape"(%2704, %2705) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2659)
    %2707 = torch.operator "onnx.MatMul"(%2706, %239) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2660)
    %2708 = torch.operator "onnx.Add"(%2631, %2707) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2661)
    %2709 = torch.operator "onnx.Cast"(%2708) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2662)
    %2710 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2663)
    %2711 = torch.operator "onnx.Pow"(%2709, %2710) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2664)
    %2712 = torch.operator "onnx.ReduceMean"(%2711) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2665)
    %2713 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2666)
    %2714 = torch.operator "onnx.Add"(%2712, %2713) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2667)
    %2715 = torch.operator "onnx.Sqrt"(%2714) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2668)
    %2716 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.24_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2669)
    %2717 = torch.operator "onnx.Div"(%2716, %2715) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2670)
    %2718 = torch.operator "onnx.Mul"(%2709, %2717) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2671)
    %2719 = torch.operator "onnx.Cast"(%2718) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2672)
    %2720 = torch.operator "onnx.Mul"(%52, %2719) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2673)
    %2721 = torch.operator "onnx.MatMul"(%2720, %240) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2674)
    %2722 = torch.operator "onnx.Sigmoid"(%2721) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2675)
    %2723 = torch.operator "onnx.Mul"(%2721, %2722) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2676)
    %2724 = torch.operator "onnx.MatMul"(%2720, %241) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2677)
    %2725 = torch.operator "onnx.Mul"(%2723, %2724) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2678)
    %2726 = torch.operator "onnx.MatMul"(%2725, %242) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2679)
    %2727 = torch.operator "onnx.Add"(%2709, %2726) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2680)
    %2728 = torch.operator "onnx.Cast"(%2727) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2681)
    %2729 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2682)
    %2730 = torch.operator "onnx.Pow"(%2728, %2729) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2683)
    %2731 = torch.operator "onnx.ReduceMean"(%2730) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2684)
    %2732 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2685)
    %2733 = torch.operator "onnx.Add"(%2731, %2732) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2686)
    %2734 = torch.operator "onnx.Sqrt"(%2733) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2687)
    %2735 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2688)
    %2736 = torch.operator "onnx.Div"(%2735, %2734) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2689)
    %2737 = torch.operator "onnx.Mul"(%2728, %2736) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2690)
    %2738 = torch.operator "onnx.Cast"(%2737) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2691)
    %2739 = torch.operator "onnx.Mul"(%53, %2738) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2692)
    %2740 = torch.operator "onnx.MatMul"(%2739, %243) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2693)
    %2741 = torch.operator "onnx.MatMul"(%2739, %244) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2694)
    %2742 = torch.operator "onnx.MatMul"(%2739, %245) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2695)
    %2743 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2696)
    %2744 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2697)
    %2745 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2698)
    %2746 = torch.operator "onnx.Reshape"(%2740, %2743) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2699)
    %2747 = torch.operator "onnx.Transpose"(%2746) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2700)
    %2748 = torch.operator "onnx.Reshape"(%2741, %2744) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2701)
    %2749 = torch.operator "onnx.Transpose"(%2748) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2702)
    %2750 = torch.operator "onnx.Reshape"(%2742, %2745) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2703)
    %2751 = torch.operator "onnx.Transpose"(%2750) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2704)
    %2752 = torch_c.to_builtin_tensor %2751 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2753 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2705)
    %2754 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2706)
    %2755 = torch.operator "onnx.Gather"(%2753, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2707)
    %2756 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2708)
    %2757 = torch.operator "onnx.Unsqueeze"(%2755, %2756) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2709)
    %2758 = torch.operator "onnx.Gather"(%2754, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2710)
    %2759 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2711)
    %2760 = torch.operator "onnx.Unsqueeze"(%2758, %2759) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2712)
    %2761 = torch.operator "onnx.Mul"(%2747, %2757) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2713)
    %2762 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2714)
    %2763 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2715)
    %2764 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2716)
    %2765 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2717)
    %2766 = torch.operator "onnx.Slice"(%2747, %2763, %2764, %2762, %2765) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2718)
    %2767 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2719)
    %2768 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2720)
    %2769 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2721)
    %2770 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2722)
    %2771 = torch.operator "onnx.Slice"(%2747, %2768, %2769, %2767, %2770) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2723)
    %2772 = torch.operator "onnx.Neg"(%2771) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2724)
    %2773 = torch.operator "onnx.Concat"(%2772, %2766) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2725)
    %2774 = torch.operator "onnx.Mul"(%2773, %2760) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2726)
    %2775 = torch.operator "onnx.Add"(%2761, %2774) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2727)
    %2776 = torch.operator "onnx.Mul"(%2749, %2757) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2728)
    %2777 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2729)
    %2778 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2730)
    %2779 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2731)
    %2780 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2732)
    %2781 = torch.operator "onnx.Slice"(%2749, %2778, %2779, %2777, %2780) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2733)
    %2782 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2734)
    %2783 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2735)
    %2784 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2736)
    %2785 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2737)
    %2786 = torch.operator "onnx.Slice"(%2749, %2783, %2784, %2782, %2785) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2738)
    %2787 = torch.operator "onnx.Neg"(%2786) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2739)
    %2788 = torch.operator "onnx.Concat"(%2787, %2781) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2740)
    %2789 = torch.operator "onnx.Mul"(%2788, %2760) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2741)
    %2790 = torch.operator "onnx.Add"(%2776, %2789) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2742)
    %2791 = torch_c.to_builtin_tensor %2790 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2792 = torch.operator "onnx.Transpose"(%2790) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2743)
    %2793 = torch.operator "onnx.MatMul"(%2775, %2792) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2744)
    %2794 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2745)
    %2795 = torch.operator "onnx.Div"(%2793, %2794) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2746)
    %2796 = torch.operator "onnx.Add"(%2795, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2747)
    %2797 = torch.operator "onnx.Softmax"(%2796) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2748)
    %2798 = torch.operator "onnx.Cast"(%2797) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2749)
    %2799 = torch.operator "onnx.Cast"(%2798) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2750)
    %2800 = torch.operator "onnx.MatMul"(%2799, %2751) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2751)
    %2801 = torch.operator "onnx.Transpose"(%2800) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2752)
    %2802 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2753)
    %2803 = torch.operator "onnx.Reshape"(%2801, %2802) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2754)
    %2804 = torch.operator "onnx.MatMul"(%2803, %246) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2755)
    %2805 = torch.operator "onnx.Add"(%2728, %2804) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2756)
    %2806 = torch.operator "onnx.Cast"(%2805) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2757)
    %2807 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2758)
    %2808 = torch.operator "onnx.Pow"(%2806, %2807) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2759)
    %2809 = torch.operator "onnx.ReduceMean"(%2808) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2760)
    %2810 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2761)
    %2811 = torch.operator "onnx.Add"(%2809, %2810) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2762)
    %2812 = torch.operator "onnx.Sqrt"(%2811) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2763)
    %2813 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.25_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2764)
    %2814 = torch.operator "onnx.Div"(%2813, %2812) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2765)
    %2815 = torch.operator "onnx.Mul"(%2806, %2814) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2766)
    %2816 = torch.operator "onnx.Cast"(%2815) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2767)
    %2817 = torch.operator "onnx.Mul"(%54, %2816) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2768)
    %2818 = torch.operator "onnx.MatMul"(%2817, %247) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2769)
    %2819 = torch.operator "onnx.Sigmoid"(%2818) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2770)
    %2820 = torch.operator "onnx.Mul"(%2818, %2819) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2771)
    %2821 = torch.operator "onnx.MatMul"(%2817, %248) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2772)
    %2822 = torch.operator "onnx.Mul"(%2820, %2821) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2773)
    %2823 = torch.operator "onnx.MatMul"(%2822, %249) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2774)
    %2824 = torch.operator "onnx.Add"(%2806, %2823) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2775)
    %2825 = torch.operator "onnx.Cast"(%2824) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2776)
    %2826 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2777)
    %2827 = torch.operator "onnx.Pow"(%2825, %2826) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2778)
    %2828 = torch.operator "onnx.ReduceMean"(%2827) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2779)
    %2829 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2780)
    %2830 = torch.operator "onnx.Add"(%2828, %2829) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2781)
    %2831 = torch.operator "onnx.Sqrt"(%2830) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2782)
    %2832 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2783)
    %2833 = torch.operator "onnx.Div"(%2832, %2831) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2784)
    %2834 = torch.operator "onnx.Mul"(%2825, %2833) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2785)
    %2835 = torch.operator "onnx.Cast"(%2834) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2786)
    %2836 = torch.operator "onnx.Mul"(%55, %2835) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2787)
    %2837 = torch.operator "onnx.MatMul"(%2836, %250) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2788)
    %2838 = torch.operator "onnx.MatMul"(%2836, %251) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2789)
    %2839 = torch.operator "onnx.MatMul"(%2836, %252) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2790)
    %2840 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2791)
    %2841 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2792)
    %2842 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2793)
    %2843 = torch.operator "onnx.Reshape"(%2837, %2840) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2794)
    %2844 = torch.operator "onnx.Transpose"(%2843) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2795)
    %2845 = torch.operator "onnx.Reshape"(%2838, %2841) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2796)
    %2846 = torch.operator "onnx.Transpose"(%2845) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2797)
    %2847 = torch.operator "onnx.Reshape"(%2839, %2842) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2798)
    %2848 = torch.operator "onnx.Transpose"(%2847) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2799)
    %2849 = torch_c.to_builtin_tensor %2848 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2850 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2800)
    %2851 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2801)
    %2852 = torch.operator "onnx.Gather"(%2850, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2802)
    %2853 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2803)
    %2854 = torch.operator "onnx.Unsqueeze"(%2852, %2853) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2804)
    %2855 = torch.operator "onnx.Gather"(%2851, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2805)
    %2856 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2806)
    %2857 = torch.operator "onnx.Unsqueeze"(%2855, %2856) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2807)
    %2858 = torch.operator "onnx.Mul"(%2844, %2854) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2808)
    %2859 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2809)
    %2860 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2810)
    %2861 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2811)
    %2862 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2812)
    %2863 = torch.operator "onnx.Slice"(%2844, %2860, %2861, %2859, %2862) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2813)
    %2864 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2814)
    %2865 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2815)
    %2866 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2816)
    %2867 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2817)
    %2868 = torch.operator "onnx.Slice"(%2844, %2865, %2866, %2864, %2867) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2818)
    %2869 = torch.operator "onnx.Neg"(%2868) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2819)
    %2870 = torch.operator "onnx.Concat"(%2869, %2863) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2820)
    %2871 = torch.operator "onnx.Mul"(%2870, %2857) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2821)
    %2872 = torch.operator "onnx.Add"(%2858, %2871) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2822)
    %2873 = torch.operator "onnx.Mul"(%2846, %2854) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2823)
    %2874 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2824)
    %2875 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2825)
    %2876 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2826)
    %2877 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2827)
    %2878 = torch.operator "onnx.Slice"(%2846, %2875, %2876, %2874, %2877) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2828)
    %2879 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2829)
    %2880 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2830)
    %2881 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2831)
    %2882 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2832)
    %2883 = torch.operator "onnx.Slice"(%2846, %2880, %2881, %2879, %2882) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2833)
    %2884 = torch.operator "onnx.Neg"(%2883) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2834)
    %2885 = torch.operator "onnx.Concat"(%2884, %2878) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2835)
    %2886 = torch.operator "onnx.Mul"(%2885, %2857) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2836)
    %2887 = torch.operator "onnx.Add"(%2873, %2886) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2837)
    %2888 = torch_c.to_builtin_tensor %2887 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2889 = torch.operator "onnx.Transpose"(%2887) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2838)
    %2890 = torch.operator "onnx.MatMul"(%2872, %2889) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2839)
    %2891 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2840)
    %2892 = torch.operator "onnx.Div"(%2890, %2891) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2841)
    %2893 = torch.operator "onnx.Add"(%2892, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2842)
    %2894 = torch.operator "onnx.Softmax"(%2893) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2843)
    %2895 = torch.operator "onnx.Cast"(%2894) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2844)
    %2896 = torch.operator "onnx.Cast"(%2895) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2845)
    %2897 = torch.operator "onnx.MatMul"(%2896, %2848) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2846)
    %2898 = torch.operator "onnx.Transpose"(%2897) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2847)
    %2899 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2848)
    %2900 = torch.operator "onnx.Reshape"(%2898, %2899) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2849)
    %2901 = torch.operator "onnx.MatMul"(%2900, %253) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2850)
    %2902 = torch.operator "onnx.Add"(%2825, %2901) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2851)
    %2903 = torch.operator "onnx.Cast"(%2902) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2852)
    %2904 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2853)
    %2905 = torch.operator "onnx.Pow"(%2903, %2904) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2854)
    %2906 = torch.operator "onnx.ReduceMean"(%2905) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2855)
    %2907 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2856)
    %2908 = torch.operator "onnx.Add"(%2906, %2907) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2857)
    %2909 = torch.operator "onnx.Sqrt"(%2908) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2858)
    %2910 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.26_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2859)
    %2911 = torch.operator "onnx.Div"(%2910, %2909) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2860)
    %2912 = torch.operator "onnx.Mul"(%2903, %2911) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2861)
    %2913 = torch.operator "onnx.Cast"(%2912) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2862)
    %2914 = torch.operator "onnx.Mul"(%56, %2913) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2863)
    %2915 = torch.operator "onnx.MatMul"(%2914, %254) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2864)
    %2916 = torch.operator "onnx.Sigmoid"(%2915) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2865)
    %2917 = torch.operator "onnx.Mul"(%2915, %2916) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2866)
    %2918 = torch.operator "onnx.MatMul"(%2914, %255) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2867)
    %2919 = torch.operator "onnx.Mul"(%2917, %2918) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2868)
    %2920 = torch.operator "onnx.MatMul"(%2919, %256) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2869)
    %2921 = torch.operator "onnx.Add"(%2903, %2920) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2870)
    %2922 = torch.operator "onnx.Cast"(%2921) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2871)
    %2923 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2872)
    %2924 = torch.operator "onnx.Pow"(%2922, %2923) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2873)
    %2925 = torch.operator "onnx.ReduceMean"(%2924) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2874)
    %2926 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2875)
    %2927 = torch.operator "onnx.Add"(%2925, %2926) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2876)
    %2928 = torch.operator "onnx.Sqrt"(%2927) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2877)
    %2929 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2878)
    %2930 = torch.operator "onnx.Div"(%2929, %2928) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2879)
    %2931 = torch.operator "onnx.Mul"(%2922, %2930) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2880)
    %2932 = torch.operator "onnx.Cast"(%2931) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2881)
    %2933 = torch.operator "onnx.Mul"(%57, %2932) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2882)
    %2934 = torch.operator "onnx.MatMul"(%2933, %257) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2883)
    %2935 = torch.operator "onnx.MatMul"(%2933, %258) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2884)
    %2936 = torch.operator "onnx.MatMul"(%2933, %259) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2885)
    %2937 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2886)
    %2938 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2887)
    %2939 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2888)
    %2940 = torch.operator "onnx.Reshape"(%2934, %2937) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2889)
    %2941 = torch.operator "onnx.Transpose"(%2940) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2890)
    %2942 = torch.operator "onnx.Reshape"(%2935, %2938) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2891)
    %2943 = torch.operator "onnx.Transpose"(%2942) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2892)
    %2944 = torch.operator "onnx.Reshape"(%2936, %2939) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2893)
    %2945 = torch.operator "onnx.Transpose"(%2944) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2894)
    %2946 = torch_c.to_builtin_tensor %2945 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2947 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2895)
    %2948 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2896)
    %2949 = torch.operator "onnx.Gather"(%2947, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2897)
    %2950 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2898)
    %2951 = torch.operator "onnx.Unsqueeze"(%2949, %2950) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2899)
    %2952 = torch.operator "onnx.Gather"(%2948, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2900)
    %2953 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2901)
    %2954 = torch.operator "onnx.Unsqueeze"(%2952, %2953) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2902)
    %2955 = torch.operator "onnx.Mul"(%2941, %2951) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2903)
    %2956 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2904)
    %2957 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2905)
    %2958 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2906)
    %2959 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2907)
    %2960 = torch.operator "onnx.Slice"(%2941, %2957, %2958, %2956, %2959) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2908)
    %2961 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2909)
    %2962 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2910)
    %2963 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2911)
    %2964 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2912)
    %2965 = torch.operator "onnx.Slice"(%2941, %2962, %2963, %2961, %2964) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2913)
    %2966 = torch.operator "onnx.Neg"(%2965) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2914)
    %2967 = torch.operator "onnx.Concat"(%2966, %2960) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2915)
    %2968 = torch.operator "onnx.Mul"(%2967, %2954) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2916)
    %2969 = torch.operator "onnx.Add"(%2955, %2968) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2917)
    %2970 = torch.operator "onnx.Mul"(%2943, %2951) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2918)
    %2971 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2919)
    %2972 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2920)
    %2973 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2921)
    %2974 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2922)
    %2975 = torch.operator "onnx.Slice"(%2943, %2972, %2973, %2971, %2974) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2923)
    %2976 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2924)
    %2977 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2925)
    %2978 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2926)
    %2979 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2927)
    %2980 = torch.operator "onnx.Slice"(%2943, %2977, %2978, %2976, %2979) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2928)
    %2981 = torch.operator "onnx.Neg"(%2980) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc2929)
    %2982 = torch.operator "onnx.Concat"(%2981, %2975) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2930)
    %2983 = torch.operator "onnx.Mul"(%2982, %2954) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2931)
    %2984 = torch.operator "onnx.Add"(%2970, %2983) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2932)
    %2985 = torch_c.to_builtin_tensor %2984 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %2986 = torch.operator "onnx.Transpose"(%2984) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc2933)
    %2987 = torch.operator "onnx.MatMul"(%2969, %2986) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2934)
    %2988 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2935)
    %2989 = torch.operator "onnx.Div"(%2987, %2988) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc2936)
    %2990 = torch.operator "onnx.Add"(%2989, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2937)
    %2991 = torch.operator "onnx.Softmax"(%2990) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2938)
    %2992 = torch.operator "onnx.Cast"(%2991) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2939)
    %2993 = torch.operator "onnx.Cast"(%2992) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc2940)
    %2994 = torch.operator "onnx.MatMul"(%2993, %2945) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc2941)
    %2995 = torch.operator "onnx.Transpose"(%2994) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc2942)
    %2996 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc2943)
    %2997 = torch.operator "onnx.Reshape"(%2995, %2996) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2944)
    %2998 = torch.operator "onnx.MatMul"(%2997, %260) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2945)
    %2999 = torch.operator "onnx.Add"(%2922, %2998) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2946)
    %3000 = torch.operator "onnx.Cast"(%2999) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2947)
    %3001 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2948)
    %3002 = torch.operator "onnx.Pow"(%3000, %3001) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2949)
    %3003 = torch.operator "onnx.ReduceMean"(%3002) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2950)
    %3004 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2951)
    %3005 = torch.operator "onnx.Add"(%3003, %3004) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2952)
    %3006 = torch.operator "onnx.Sqrt"(%3005) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2953)
    %3007 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.27_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2954)
    %3008 = torch.operator "onnx.Div"(%3007, %3006) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2955)
    %3009 = torch.operator "onnx.Mul"(%3000, %3008) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2956)
    %3010 = torch.operator "onnx.Cast"(%3009) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2957)
    %3011 = torch.operator "onnx.Mul"(%58, %3010) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2958)
    %3012 = torch.operator "onnx.MatMul"(%3011, %261) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2959)
    %3013 = torch.operator "onnx.Sigmoid"(%3012) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2960)
    %3014 = torch.operator "onnx.Mul"(%3012, %3013) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2961)
    %3015 = torch.operator "onnx.MatMul"(%3011, %262) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2962)
    %3016 = torch.operator "onnx.Mul"(%3014, %3015) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc2963)
    %3017 = torch.operator "onnx.MatMul"(%3016, %263) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2964)
    %3018 = torch.operator "onnx.Add"(%3000, %3017) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2965)
    %3019 = torch.operator "onnx.Cast"(%3018) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2966)
    %3020 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2967)
    %3021 = torch.operator "onnx.Pow"(%3019, %3020) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2968)
    %3022 = torch.operator "onnx.ReduceMean"(%3021) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2969)
    %3023 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2970)
    %3024 = torch.operator "onnx.Add"(%3022, %3023) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2971)
    %3025 = torch.operator "onnx.Sqrt"(%3024) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2972)
    %3026 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc2973)
    %3027 = torch.operator "onnx.Div"(%3026, %3025) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc2974)
    %3028 = torch.operator "onnx.Mul"(%3019, %3027) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2975)
    %3029 = torch.operator "onnx.Cast"(%3028) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2976)
    %3030 = torch.operator "onnx.Mul"(%59, %3029) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2977)
    %3031 = torch.operator "onnx.MatMul"(%3030, %264) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2978)
    %3032 = torch.operator "onnx.MatMul"(%3030, %265) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2979)
    %3033 = torch.operator "onnx.MatMul"(%3030, %266) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc2980)
    %3034 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2981)
    %3035 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2982)
    %3036 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc2983)
    %3037 = torch.operator "onnx.Reshape"(%3031, %3034) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2984)
    %3038 = torch.operator "onnx.Transpose"(%3037) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2985)
    %3039 = torch.operator "onnx.Reshape"(%3032, %3035) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2986)
    %3040 = torch.operator "onnx.Transpose"(%3039) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2987)
    %3041 = torch.operator "onnx.Reshape"(%3033, %3036) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc2988)
    %3042 = torch.operator "onnx.Transpose"(%3041) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2989)
    %3043 = torch_c.to_builtin_tensor %3042 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %3044 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2990)
    %3045 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc2991)
    %3046 = torch.operator "onnx.Gather"(%3044, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2992)
    %3047 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2993)
    %3048 = torch.operator "onnx.Unsqueeze"(%3046, %3047) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2994)
    %3049 = torch.operator "onnx.Gather"(%3045, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc2995)
    %3050 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2996)
    %3051 = torch.operator "onnx.Unsqueeze"(%3049, %3050) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc2997)
    %3052 = torch.operator "onnx.Mul"(%3038, %3048) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc2998)
    %3053 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc2999)
    %3054 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3000)
    %3055 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3001)
    %3056 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3002)
    %3057 = torch.operator "onnx.Slice"(%3038, %3054, %3055, %3053, %3056) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3003)
    %3058 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3004)
    %3059 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3005)
    %3060 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3006)
    %3061 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3007)
    %3062 = torch.operator "onnx.Slice"(%3038, %3059, %3060, %3058, %3061) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3008)
    %3063 = torch.operator "onnx.Neg"(%3062) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3009)
    %3064 = torch.operator "onnx.Concat"(%3063, %3057) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3010)
    %3065 = torch.operator "onnx.Mul"(%3064, %3051) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3011)
    %3066 = torch.operator "onnx.Add"(%3052, %3065) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3012)
    %3067 = torch.operator "onnx.Mul"(%3040, %3048) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3013)
    %3068 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3014)
    %3069 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3015)
    %3070 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3016)
    %3071 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3017)
    %3072 = torch.operator "onnx.Slice"(%3040, %3069, %3070, %3068, %3071) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3018)
    %3073 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3019)
    %3074 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3020)
    %3075 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3021)
    %3076 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3022)
    %3077 = torch.operator "onnx.Slice"(%3040, %3074, %3075, %3073, %3076) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3023)
    %3078 = torch.operator "onnx.Neg"(%3077) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3024)
    %3079 = torch.operator "onnx.Concat"(%3078, %3072) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3025)
    %3080 = torch.operator "onnx.Mul"(%3079, %3051) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3026)
    %3081 = torch.operator "onnx.Add"(%3067, %3080) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3027)
    %3082 = torch_c.to_builtin_tensor %3081 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %3083 = torch.operator "onnx.Transpose"(%3081) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc3028)
    %3084 = torch.operator "onnx.MatMul"(%3066, %3083) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc3029)
    %3085 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3030)
    %3086 = torch.operator "onnx.Div"(%3084, %3085) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc3031)
    %3087 = torch.operator "onnx.Add"(%3086, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3032)
    %3088 = torch.operator "onnx.Softmax"(%3087) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3033)
    %3089 = torch.operator "onnx.Cast"(%3088) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3034)
    %3090 = torch.operator "onnx.Cast"(%3089) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3035)
    %3091 = torch.operator "onnx.MatMul"(%3090, %3042) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc3036)
    %3092 = torch.operator "onnx.Transpose"(%3091) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc3037)
    %3093 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc3038)
    %3094 = torch.operator "onnx.Reshape"(%3092, %3093) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3039)
    %3095 = torch.operator "onnx.MatMul"(%3094, %267) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3040)
    %3096 = torch.operator "onnx.Add"(%3019, %3095) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3041)
    %3097 = torch.operator "onnx.Cast"(%3096) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3042)
    %3098 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3043)
    %3099 = torch.operator "onnx.Pow"(%3097, %3098) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3044)
    %3100 = torch.operator "onnx.ReduceMean"(%3099) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3045)
    %3101 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3046)
    %3102 = torch.operator "onnx.Add"(%3100, %3101) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3047)
    %3103 = torch.operator "onnx.Sqrt"(%3102) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3048)
    %3104 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.28_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3049)
    %3105 = torch.operator "onnx.Div"(%3104, %3103) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3050)
    %3106 = torch.operator "onnx.Mul"(%3097, %3105) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3051)
    %3107 = torch.operator "onnx.Cast"(%3106) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3052)
    %3108 = torch.operator "onnx.Mul"(%60, %3107) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3053)
    %3109 = torch.operator "onnx.MatMul"(%3108, %268) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3054)
    %3110 = torch.operator "onnx.Sigmoid"(%3109) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3055)
    %3111 = torch.operator "onnx.Mul"(%3109, %3110) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3056)
    %3112 = torch.operator "onnx.MatMul"(%3108, %269) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3057)
    %3113 = torch.operator "onnx.Mul"(%3111, %3112) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3058)
    %3114 = torch.operator "onnx.MatMul"(%3113, %270) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3059)
    %3115 = torch.operator "onnx.Add"(%3097, %3114) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3060)
    %3116 = torch.operator "onnx.Cast"(%3115) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3061)
    %3117 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3062)
    %3118 = torch.operator "onnx.Pow"(%3116, %3117) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3063)
    %3119 = torch.operator "onnx.ReduceMean"(%3118) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3064)
    %3120 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3065)
    %3121 = torch.operator "onnx.Add"(%3119, %3120) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3066)
    %3122 = torch.operator "onnx.Sqrt"(%3121) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3067)
    %3123 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3068)
    %3124 = torch.operator "onnx.Div"(%3123, %3122) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3069)
    %3125 = torch.operator "onnx.Mul"(%3116, %3124) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3070)
    %3126 = torch.operator "onnx.Cast"(%3125) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3071)
    %3127 = torch.operator "onnx.Mul"(%61, %3126) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3072)
    %3128 = torch.operator "onnx.MatMul"(%3127, %271) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3073)
    %3129 = torch.operator "onnx.MatMul"(%3127, %272) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3074)
    %3130 = torch.operator "onnx.MatMul"(%3127, %273) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3075)
    %3131 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3076)
    %3132 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3077)
    %3133 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3078)
    %3134 = torch.operator "onnx.Reshape"(%3128, %3131) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3079)
    %3135 = torch.operator "onnx.Transpose"(%3134) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3080)
    %3136 = torch.operator "onnx.Reshape"(%3129, %3132) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3081)
    %3137 = torch.operator "onnx.Transpose"(%3136) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3082)
    %3138 = torch.operator "onnx.Reshape"(%3130, %3133) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3083)
    %3139 = torch.operator "onnx.Transpose"(%3138) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3084)
    %3140 = torch_c.to_builtin_tensor %3139 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %3141 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc3085)
    %3142 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc3086)
    %3143 = torch.operator "onnx.Gather"(%3141, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc3087)
    %3144 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3088)
    %3145 = torch.operator "onnx.Unsqueeze"(%3143, %3144) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc3089)
    %3146 = torch.operator "onnx.Gather"(%3142, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc3090)
    %3147 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3091)
    %3148 = torch.operator "onnx.Unsqueeze"(%3146, %3147) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc3092)
    %3149 = torch.operator "onnx.Mul"(%3135, %3145) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3093)
    %3150 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3094)
    %3151 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3095)
    %3152 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3096)
    %3153 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3097)
    %3154 = torch.operator "onnx.Slice"(%3135, %3151, %3152, %3150, %3153) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3098)
    %3155 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3099)
    %3156 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3100)
    %3157 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3101)
    %3158 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3102)
    %3159 = torch.operator "onnx.Slice"(%3135, %3156, %3157, %3155, %3158) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3103)
    %3160 = torch.operator "onnx.Neg"(%3159) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3104)
    %3161 = torch.operator "onnx.Concat"(%3160, %3154) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3105)
    %3162 = torch.operator "onnx.Mul"(%3161, %3148) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3106)
    %3163 = torch.operator "onnx.Add"(%3149, %3162) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3107)
    %3164 = torch.operator "onnx.Mul"(%3137, %3145) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3108)
    %3165 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3109)
    %3166 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3110)
    %3167 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3111)
    %3168 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3112)
    %3169 = torch.operator "onnx.Slice"(%3137, %3166, %3167, %3165, %3168) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3113)
    %3170 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3114)
    %3171 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3115)
    %3172 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3116)
    %3173 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3117)
    %3174 = torch.operator "onnx.Slice"(%3137, %3171, %3172, %3170, %3173) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3118)
    %3175 = torch.operator "onnx.Neg"(%3174) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3119)
    %3176 = torch.operator "onnx.Concat"(%3175, %3169) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3120)
    %3177 = torch.operator "onnx.Mul"(%3176, %3148) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3121)
    %3178 = torch.operator "onnx.Add"(%3164, %3177) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3122)
    %3179 = torch_c.to_builtin_tensor %3178 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %3180 = torch.operator "onnx.Transpose"(%3178) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc3123)
    %3181 = torch.operator "onnx.MatMul"(%3163, %3180) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc3124)
    %3182 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3125)
    %3183 = torch.operator "onnx.Div"(%3181, %3182) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc3126)
    %3184 = torch.operator "onnx.Add"(%3183, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3127)
    %3185 = torch.operator "onnx.Softmax"(%3184) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3128)
    %3186 = torch.operator "onnx.Cast"(%3185) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3129)
    %3187 = torch.operator "onnx.Cast"(%3186) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3130)
    %3188 = torch.operator "onnx.MatMul"(%3187, %3139) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc3131)
    %3189 = torch.operator "onnx.Transpose"(%3188) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc3132)
    %3190 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc3133)
    %3191 = torch.operator "onnx.Reshape"(%3189, %3190) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3134)
    %3192 = torch.operator "onnx.MatMul"(%3191, %274) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3135)
    %3193 = torch.operator "onnx.Add"(%3116, %3192) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3136)
    %3194 = torch.operator "onnx.Cast"(%3193) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3137)
    %3195 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3138)
    %3196 = torch.operator "onnx.Pow"(%3194, %3195) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3139)
    %3197 = torch.operator "onnx.ReduceMean"(%3196) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3140)
    %3198 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3141)
    %3199 = torch.operator "onnx.Add"(%3197, %3198) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3142)
    %3200 = torch.operator "onnx.Sqrt"(%3199) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3143)
    %3201 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.29_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3144)
    %3202 = torch.operator "onnx.Div"(%3201, %3200) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3145)
    %3203 = torch.operator "onnx.Mul"(%3194, %3202) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3146)
    %3204 = torch.operator "onnx.Cast"(%3203) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3147)
    %3205 = torch.operator "onnx.Mul"(%62, %3204) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3148)
    %3206 = torch.operator "onnx.MatMul"(%3205, %275) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3149)
    %3207 = torch.operator "onnx.Sigmoid"(%3206) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3150)
    %3208 = torch.operator "onnx.Mul"(%3206, %3207) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3151)
    %3209 = torch.operator "onnx.MatMul"(%3205, %276) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3152)
    %3210 = torch.operator "onnx.Mul"(%3208, %3209) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3153)
    %3211 = torch.operator "onnx.MatMul"(%3210, %277) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3154)
    %3212 = torch.operator "onnx.Add"(%3194, %3211) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3155)
    %3213 = torch.operator "onnx.Cast"(%3212) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3156)
    %3214 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3157)
    %3215 = torch.operator "onnx.Pow"(%3213, %3214) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3158)
    %3216 = torch.operator "onnx.ReduceMean"(%3215) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3159)
    %3217 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3160)
    %3218 = torch.operator "onnx.Add"(%3216, %3217) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3161)
    %3219 = torch.operator "onnx.Sqrt"(%3218) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3162)
    %3220 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3163)
    %3221 = torch.operator "onnx.Div"(%3220, %3219) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3164)
    %3222 = torch.operator "onnx.Mul"(%3213, %3221) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3165)
    %3223 = torch.operator "onnx.Cast"(%3222) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3166)
    %3224 = torch.operator "onnx.Mul"(%63, %3223) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3167)
    %3225 = torch.operator "onnx.MatMul"(%3224, %278) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3168)
    %3226 = torch.operator "onnx.MatMul"(%3224, %279) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3169)
    %3227 = torch.operator "onnx.MatMul"(%3224, %280) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3170)
    %3228 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3171)
    %3229 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3172)
    %3230 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3173)
    %3231 = torch.operator "onnx.Reshape"(%3225, %3228) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3174)
    %3232 = torch.operator "onnx.Transpose"(%3231) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3175)
    %3233 = torch.operator "onnx.Reshape"(%3226, %3229) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3176)
    %3234 = torch.operator "onnx.Transpose"(%3233) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3177)
    %3235 = torch.operator "onnx.Reshape"(%3227, %3230) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3178)
    %3236 = torch.operator "onnx.Transpose"(%3235) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3179)
    %3237 = torch_c.to_builtin_tensor %3236 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %3238 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc3180)
    %3239 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc3181)
    %3240 = torch.operator "onnx.Gather"(%3238, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc3182)
    %3241 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3183)
    %3242 = torch.operator "onnx.Unsqueeze"(%3240, %3241) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc3184)
    %3243 = torch.operator "onnx.Gather"(%3239, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc3185)
    %3244 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3186)
    %3245 = torch.operator "onnx.Unsqueeze"(%3243, %3244) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc3187)
    %3246 = torch.operator "onnx.Mul"(%3232, %3242) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3188)
    %3247 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3189)
    %3248 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3190)
    %3249 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3191)
    %3250 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3192)
    %3251 = torch.operator "onnx.Slice"(%3232, %3248, %3249, %3247, %3250) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3193)
    %3252 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3194)
    %3253 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3195)
    %3254 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3196)
    %3255 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3197)
    %3256 = torch.operator "onnx.Slice"(%3232, %3253, %3254, %3252, %3255) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3198)
    %3257 = torch.operator "onnx.Neg"(%3256) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3199)
    %3258 = torch.operator "onnx.Concat"(%3257, %3251) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3200)
    %3259 = torch.operator "onnx.Mul"(%3258, %3245) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3201)
    %3260 = torch.operator "onnx.Add"(%3246, %3259) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3202)
    %3261 = torch.operator "onnx.Mul"(%3234, %3242) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3203)
    %3262 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3204)
    %3263 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3205)
    %3264 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3206)
    %3265 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3207)
    %3266 = torch.operator "onnx.Slice"(%3234, %3263, %3264, %3262, %3265) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3208)
    %3267 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3209)
    %3268 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3210)
    %3269 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3211)
    %3270 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3212)
    %3271 = torch.operator "onnx.Slice"(%3234, %3268, %3269, %3267, %3270) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3213)
    %3272 = torch.operator "onnx.Neg"(%3271) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3214)
    %3273 = torch.operator "onnx.Concat"(%3272, %3266) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3215)
    %3274 = torch.operator "onnx.Mul"(%3273, %3245) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3216)
    %3275 = torch.operator "onnx.Add"(%3261, %3274) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3217)
    %3276 = torch_c.to_builtin_tensor %3275 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %3277 = torch.operator "onnx.Transpose"(%3275) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc3218)
    %3278 = torch.operator "onnx.MatMul"(%3260, %3277) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc3219)
    %3279 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3220)
    %3280 = torch.operator "onnx.Div"(%3278, %3279) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc3221)
    %3281 = torch.operator "onnx.Add"(%3280, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3222)
    %3282 = torch.operator "onnx.Softmax"(%3281) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3223)
    %3283 = torch.operator "onnx.Cast"(%3282) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3224)
    %3284 = torch.operator "onnx.Cast"(%3283) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3225)
    %3285 = torch.operator "onnx.MatMul"(%3284, %3236) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc3226)
    %3286 = torch.operator "onnx.Transpose"(%3285) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc3227)
    %3287 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc3228)
    %3288 = torch.operator "onnx.Reshape"(%3286, %3287) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3229)
    %3289 = torch.operator "onnx.MatMul"(%3288, %281) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3230)
    %3290 = torch.operator "onnx.Add"(%3213, %3289) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3231)
    %3291 = torch.operator "onnx.Cast"(%3290) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3232)
    %3292 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3233)
    %3293 = torch.operator "onnx.Pow"(%3291, %3292) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3234)
    %3294 = torch.operator "onnx.ReduceMean"(%3293) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3235)
    %3295 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3236)
    %3296 = torch.operator "onnx.Add"(%3294, %3295) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3237)
    %3297 = torch.operator "onnx.Sqrt"(%3296) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3238)
    %3298 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.30_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3239)
    %3299 = torch.operator "onnx.Div"(%3298, %3297) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3240)
    %3300 = torch.operator "onnx.Mul"(%3291, %3299) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3241)
    %3301 = torch.operator "onnx.Cast"(%3300) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3242)
    %3302 = torch.operator "onnx.Mul"(%64, %3301) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3243)
    %3303 = torch.operator "onnx.MatMul"(%3302, %282) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3244)
    %3304 = torch.operator "onnx.Sigmoid"(%3303) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3245)
    %3305 = torch.operator "onnx.Mul"(%3303, %3304) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3246)
    %3306 = torch.operator "onnx.MatMul"(%3302, %283) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3247)
    %3307 = torch.operator "onnx.Mul"(%3305, %3306) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3248)
    %3308 = torch.operator "onnx.MatMul"(%3307, %284) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3249)
    %3309 = torch.operator "onnx.Add"(%3291, %3308) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3250)
    %3310 = torch.operator "onnx.Cast"(%3309) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3251)
    %3311 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_input_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3252)
    %3312 = torch.operator "onnx.Pow"(%3310, %3311) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3253)
    %3313 = torch.operator "onnx.ReduceMean"(%3312) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3254)
    %3314 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_input_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3255)
    %3315 = torch.operator "onnx.Add"(%3313, %3314) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3256)
    %3316 = torch.operator "onnx.Sqrt"(%3315) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3257)
    %3317 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_input_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3258)
    %3318 = torch.operator "onnx.Div"(%3317, %3316) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3259)
    %3319 = torch.operator "onnx.Mul"(%3310, %3318) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3260)
    %3320 = torch.operator "onnx.Cast"(%3319) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3261)
    %3321 = torch.operator "onnx.Mul"(%65, %3320) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3262)
    %3322 = torch.operator "onnx.MatMul"(%3321, %285) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3263)
    %3323 = torch.operator "onnx.MatMul"(%3321, %286) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3264)
    %3324 = torch.operator "onnx.MatMul"(%3321, %287) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3265)
    %3325 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3266)
    %3326 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_1_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3267)
    %3327 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_2_attr__value> : tensor<4xsi64>} : () -> !torch.vtensor<[4],si64> loc(#loc3268)
    %3328 = torch.operator "onnx.Reshape"(%3322, %3325) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3269)
    %3329 = torch.operator "onnx.Transpose"(%3328) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3270)
    %3330 = torch.operator "onnx.Reshape"(%3323, %3326) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3271)
    %3331 = torch.operator "onnx.Transpose"(%3330) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3272)
    %3332 = torch.operator "onnx.Reshape"(%3324, %3327) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[1,8,32,128],f32> loc(#loc3273)
    %3333 = torch.operator "onnx.Transpose"(%3332) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[1,8,32,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3274)
    %3334 = torch_c.to_builtin_tensor %3333 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %3335 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_rotary_emb_Constant_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc3275)
    %3336 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_rotary_emb_Constant_1_attr__value> : tensor<8x128xf32>} : () -> !torch.vtensor<[8,128],f32> loc(#loc3276)
    %3337 = torch.operator "onnx.Gather"(%3335, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc3277)
    %3338 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_3_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3278)
    %3339 = torch.operator "onnx.Unsqueeze"(%3337, %3338) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc3279)
    %3340 = torch.operator "onnx.Gather"(%3336, %293) {torch.onnx.axis = 0 : si64} : (!torch.vtensor<[8,128],f32>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[1,8,128],f32> loc(#loc3280)
    %3341 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_4_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3281)
    %3342 = torch.operator "onnx.Unsqueeze"(%3340, %3341) : (!torch.vtensor<[1,8,128],f32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,1,8,128],f32> loc(#loc3282)
    %3343 = torch.operator "onnx.Mul"(%3329, %3339) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3283)
    %3344 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_5_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3284)
    %3345 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_6_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3285)
    %3346 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_7_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3286)
    %3347 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_8_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3287)
    %3348 = torch.operator "onnx.Slice"(%3329, %3345, %3346, %3344, %3347) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3288)
    %3349 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_9_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3289)
    %3350 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_10_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3290)
    %3351 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_11_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3291)
    %3352 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_12_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3292)
    %3353 = torch.operator "onnx.Slice"(%3329, %3350, %3351, %3349, %3352) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3293)
    %3354 = torch.operator "onnx.Neg"(%3353) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3294)
    %3355 = torch.operator "onnx.Concat"(%3354, %3348) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3295)
    %3356 = torch.operator "onnx.Mul"(%3355, %3342) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3296)
    %3357 = torch.operator "onnx.Add"(%3343, %3356) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3297)
    %3358 = torch.operator "onnx.Mul"(%3331, %3339) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3298)
    %3359 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_13_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3299)
    %3360 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_14_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3300)
    %3361 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_15_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3301)
    %3362 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_16_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3302)
    %3363 = torch.operator "onnx.Slice"(%3331, %3360, %3361, %3359, %3362) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3303)
    %3364 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_17_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3304)
    %3365 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_18_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3305)
    %3366 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_19_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3306)
    %3367 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_20_attr__value> : tensor<1xsi64>} : () -> !torch.vtensor<[1],si64> loc(#loc3307)
    %3368 = torch.operator "onnx.Slice"(%3331, %3365, %3366, %3364, %3367) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3308)
    %3369 = torch.operator "onnx.Neg"(%3368) : (!torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,64],f32> loc(#loc3309)
    %3370 = torch.operator "onnx.Concat"(%3369, %3363) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[1,32,8,64],f32>, !torch.vtensor<[1,32,8,64],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3310)
    %3371 = torch.operator "onnx.Mul"(%3370, %3342) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,1,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3311)
    %3372 = torch.operator "onnx.Add"(%3358, %3371) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,8,128],f32> loc(#loc3312)
    %3373 = torch_c.to_builtin_tensor %3372 : !torch.vtensor<[1,32,8,128],f32> -> tensor<1x32x8x128xf32> loc(#loc329)
    %3374 = torch.operator "onnx.Transpose"(%3372) {torch.onnx.perm = [0 : si64, 1 : si64, 3 : si64, 2 : si64]} : (!torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[1,32,128,8],f32> loc(#loc3313)
    %3375 = torch.operator "onnx.MatMul"(%3357, %3374) : (!torch.vtensor<[1,32,8,128],f32>, !torch.vtensor<[1,32,128,8],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc3314)
    %3376 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_21_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3315)
    %3377 = torch.operator "onnx.Div"(%3375, %3376) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,32,8,8],f32> loc(#loc3316)
    %3378 = torch.operator "onnx.Add"(%3377, %302) : (!torch.vtensor<[1,32,8,8],f32>, !torch.vtensor<[?,?,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3317)
    %3379 = torch.operator "onnx.Softmax"(%3378) {torch.onnx.axis = -1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3318)
    %3380 = torch.operator "onnx.Cast"(%3379) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3319)
    %3381 = torch.operator "onnx.Cast"(%3380) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[?,32,8,8],f32>) -> !torch.vtensor<[?,32,8,8],f32> loc(#loc3320)
    %3382 = torch.operator "onnx.MatMul"(%3381, %3333) : (!torch.vtensor<[?,32,8,8],f32>, !torch.vtensor<[1,32,8,128],f32>) -> !torch.vtensor<[?,32,8,128],f32> loc(#loc3321)
    %3383 = torch.operator "onnx.Transpose"(%3382) {torch.onnx.perm = [0 : si64, 2 : si64, 1 : si64, 3 : si64]} : (!torch.vtensor<[?,32,8,128],f32>) -> !torch.vtensor<[?,8,32,128],f32> loc(#loc3322)
    %3384 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_self_attn_Constant_22_attr__value> : tensor<3xsi64>} : () -> !torch.vtensor<[3],si64> loc(#loc3323)
    %3385 = torch.operator "onnx.Reshape"(%3383, %3384) {torch.onnx.allowzero = 0 : si64} : (!torch.vtensor<[?,8,32,128],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3324)
    %3386 = torch.operator "onnx.MatMul"(%3385, %288) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3325)
    %3387 = torch.operator "onnx.Add"(%3310, %3386) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3326)
    %3388 = torch.operator "onnx.Cast"(%3387) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3327)
    %3389 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_post_attention_layernorm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3328)
    %3390 = torch.operator "onnx.Pow"(%3388, %3389) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3329)
    %3391 = torch.operator "onnx.ReduceMean"(%3390) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3330)
    %3392 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_post_attention_layernorm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3331)
    %3393 = torch.operator "onnx.Add"(%3391, %3392) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3332)
    %3394 = torch.operator "onnx.Sqrt"(%3393) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3333)
    %3395 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_layers.31_post_attention_layernorm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3334)
    %3396 = torch.operator "onnx.Div"(%3395, %3394) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3335)
    %3397 = torch.operator "onnx.Mul"(%3388, %3396) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3336)
    %3398 = torch.operator "onnx.Cast"(%3397) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3337)
    %3399 = torch.operator "onnx.Mul"(%66, %3398) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3338)
    %3400 = torch.operator "onnx.MatMul"(%3399, %289) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3339)
    %3401 = torch.operator "onnx.Sigmoid"(%3400) : (!torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3340)
    %3402 = torch.operator "onnx.Mul"(%3400, %3401) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3341)
    %3403 = torch.operator "onnx.MatMul"(%3399, %290) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3342)
    %3404 = torch.operator "onnx.Mul"(%3402, %3403) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[1,8,11008],f32>) -> !torch.vtensor<[1,8,11008],f32> loc(#loc3343)
    %3405 = torch.operator "onnx.MatMul"(%3404, %291) : (!torch.vtensor<[1,8,11008],f32>, !torch.vtensor<[11008,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3344)
    %3406 = torch.operator "onnx.Add"(%3388, %3405) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3345)
    %3407 = torch.operator "onnx.Cast"(%3406) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3346)
    %3408 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_norm_Constant_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3347)
    %3409 = torch.operator "onnx.Pow"(%3407, %3408) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3348)
    %3410 = torch.operator "onnx.ReduceMean"(%3409) {torch.onnx.axes = [-1 : si64], torch.onnx.keepdims = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3349)
    %3411 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_norm_Constant_1_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3350)
    %3412 = torch.operator "onnx.Add"(%3410, %3411) : (!torch.vtensor<[1,8,1],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3351)
    %3413 = torch.operator "onnx.Sqrt"(%3412) : (!torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3352)
    %3414 = torch.operator "onnx.Constant"() {torch.onnx.value = dense_resource<__model_norm_Constant_2_attr__value> : tensor<f32>} : () -> !torch.vtensor<[],f32> loc(#loc3353)
    %3415 = torch.operator "onnx.Div"(%3414, %3413) : (!torch.vtensor<[],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,1],f32> loc(#loc3354)
    %3416 = torch.operator "onnx.Mul"(%3407, %3415) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[1,8,1],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3355)
    %3417 = torch.operator "onnx.Cast"(%3416) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3356)
    %3418 = torch.operator "onnx.Mul"(%67, %3417) : (!torch.vtensor<[4096],f32>, !torch.vtensor<[1,8,4096],f32>) -> !torch.vtensor<[1,8,4096],f32> loc(#loc3357)
    %3419 = torch.operator "onnx.MatMul"(%3418, %292) : (!torch.vtensor<[1,8,4096],f32>, !torch.vtensor<[4096,32000],f32>) -> !torch.vtensor<[1,8,32000],f32> loc(#loc3358)
    %3420 = torch.operator "onnx.Cast"(%3419) {torch.onnx.to = 1 : si64} : (!torch.vtensor<[1,8,32000],f32>) -> !torch.vtensor<[1,8,32000],f32> loc(#loc3359)
    %3421 = torch_c.to_builtin_tensor %3420 : !torch.vtensor<[1,8,32000],f32> -> tensor<1x8x32000xf32> loc(#loc329)
    return %3421, %366, %327, %463, %424, %560, %521, %657, %618, %754, %715, %851, %812, %948, %909, %1045, %1006, %1142, %1103, %1239, %1200, %1336, %1297, %1433, %1394, %1530, %1491, %1627, %1588, %1724, %1685, %1821, %1782, %1918, %1879, %2015, %1976, %2112, %2073, %2209, %2170, %2306, %2267, %2403, %2364, %2500, %2461, %2597, %2558, %2694, %2655, %2791, %2752, %2888, %2849, %2985, %2946, %3082, %3043, %3179, %3140, %3276, %3237, %3373, %3334 : tensor<1x8x32000xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32>, tensor<1x32x8x128xf32> loc(#loc329)
  } loc(#loc2)
} loc(#loc)
#loc = loc("./scratch/dave.mlir":1:1)
#loc1 = loc(unknown)
#loc2 = loc("./scratch/dave.mlir":2:3)
#loc4 = loc("./scratch/dave.mlir":3:10)
#loc5 = loc("./scratch/dave.mlir":4:10)
#loc6 = loc("./scratch/dave.mlir":5:10)
#loc7 = loc("./scratch/dave.mlir":6:10)
#loc8 = loc("./scratch/dave.mlir":7:10)
#loc9 = loc("./scratch/dave.mlir":8:10)
#loc10 = loc("./scratch/dave.mlir":9:10)
#loc11 = loc("./scratch/dave.mlir":10:10)
#loc12 = loc("./scratch/dave.mlir":11:10)
#loc13 = loc("./scratch/dave.mlir":12:10)
#loc14 = loc("./scratch/dave.mlir":13:11)
#loc15 = loc("./scratch/dave.mlir":14:11)
#loc16 = loc("./scratch/dave.mlir":15:11)
#loc17 = loc("./scratch/dave.mlir":16:11)
#loc18 = loc("./scratch/dave.mlir":17:11)
#loc19 = loc("./scratch/dave.mlir":18:11)
#loc20 = loc("./scratch/dave.mlir":19:11)
#loc21 = loc("./scratch/dave.mlir":20:11)
#loc22 = loc("./scratch/dave.mlir":21:11)
#loc23 = loc("./scratch/dave.mlir":22:11)
#loc24 = loc("./scratch/dave.mlir":23:11)
#loc25 = loc("./scratch/dave.mlir":24:11)
#loc26 = loc("./scratch/dave.mlir":25:11)
#loc27 = loc("./scratch/dave.mlir":26:11)
#loc28 = loc("./scratch/dave.mlir":27:11)
#loc29 = loc("./scratch/dave.mlir":28:11)
#loc30 = loc("./scratch/dave.mlir":29:11)
#loc31 = loc("./scratch/dave.mlir":30:11)
#loc32 = loc("./scratch/dave.mlir":31:11)
#loc33 = loc("./scratch/dave.mlir":32:11)
#loc34 = loc("./scratch/dave.mlir":33:11)
#loc35 = loc("./scratch/dave.mlir":34:11)
#loc36 = loc("./scratch/dave.mlir":35:11)
#loc37 = loc("./scratch/dave.mlir":36:11)
#loc38 = loc("./scratch/dave.mlir":37:11)
#loc39 = loc("./scratch/dave.mlir":38:11)
#loc40 = loc("./scratch/dave.mlir":39:11)
#loc41 = loc("./scratch/dave.mlir":40:11)
#loc42 = loc("./scratch/dave.mlir":41:11)
#loc43 = loc("./scratch/dave.mlir":42:11)
#loc44 = loc("./scratch/dave.mlir":43:11)
#loc45 = loc("./scratch/dave.mlir":44:11)
#loc46 = loc("./scratch/dave.mlir":45:11)
#loc47 = loc("./scratch/dave.mlir":46:11)
#loc48 = loc("./scratch/dave.mlir":47:11)
#loc49 = loc("./scratch/dave.mlir":48:11)
#loc50 = loc("./scratch/dave.mlir":49:11)
#loc51 = loc("./scratch/dave.mlir":50:11)
#loc52 = loc("./scratch/dave.mlir":51:11)
#loc53 = loc("./scratch/dave.mlir":52:11)
#loc54 = loc("./scratch/dave.mlir":53:11)
#loc55 = loc("./scratch/dave.mlir":54:11)
#loc56 = loc("./scratch/dave.mlir":55:11)
#loc57 = loc("./scratch/dave.mlir":56:11)
#loc58 = loc("./scratch/dave.mlir":57:11)
#loc59 = loc("./scratch/dave.mlir":58:11)
#loc60 = loc("./scratch/dave.mlir":59:11)
#loc61 = loc("./scratch/dave.mlir":60:11)
#loc62 = loc("./scratch/dave.mlir":61:11)
#loc63 = loc("./scratch/dave.mlir":62:11)
#loc64 = loc("./scratch/dave.mlir":63:11)
#loc65 = loc("./scratch/dave.mlir":64:11)
#loc66 = loc("./scratch/dave.mlir":65:11)
#loc67 = loc("./scratch/dave.mlir":66:11)
#loc68 = loc("./scratch/dave.mlir":67:11)
#loc69 = loc("./scratch/dave.mlir":68:11)
#loc70 = loc("./scratch/dave.mlir":69:11)
#loc71 = loc("./scratch/dave.mlir":70:11)
#loc72 = loc("./scratch/dave.mlir":71:11)
#loc73 = loc("./scratch/dave.mlir":72:11)
#loc74 = loc("./scratch/dave.mlir":73:11)
#loc75 = loc("./scratch/dave.mlir":74:11)
#loc76 = loc("./scratch/dave.mlir":75:11)
#loc77 = loc("./scratch/dave.mlir":76:11)
#loc78 = loc("./scratch/dave.mlir":77:11)
#loc79 = loc("./scratch/dave.mlir":78:11)
#loc80 = loc("./scratch/dave.mlir":79:11)
#loc81 = loc("./scratch/dave.mlir":80:11)
#loc82 = loc("./scratch/dave.mlir":81:11)
#loc83 = loc("./scratch/dave.mlir":82:11)
#loc84 = loc("./scratch/dave.mlir":83:11)
#loc85 = loc("./scratch/dave.mlir":84:11)
#loc86 = loc("./scratch/dave.mlir":85:11)
#loc87 = loc("./scratch/dave.mlir":86:11)
#loc88 = loc("./scratch/dave.mlir":87:11)
#loc89 = loc("./scratch/dave.mlir":88:11)
#loc90 = loc("./scratch/dave.mlir":89:11)
#loc91 = loc("./scratch/dave.mlir":90:11)
#loc92 = loc("./scratch/dave.mlir":91:11)
#loc93 = loc("./scratch/dave.mlir":92:11)
#loc94 = loc("./scratch/dave.mlir":93:11)
#loc95 = loc("./scratch/dave.mlir":94:11)
#loc96 = loc("./scratch/dave.mlir":95:11)
#loc97 = loc("./scratch/dave.mlir":96:11)
#loc98 = loc("./scratch/dave.mlir":97:11)
#loc99 = loc("./scratch/dave.mlir":98:11)
#loc100 = loc("./scratch/dave.mlir":99:11)
#loc101 = loc("./scratch/dave.mlir":100:11)
#loc102 = loc("./scratch/dave.mlir":101:11)
#loc103 = loc("./scratch/dave.mlir":102:11)
#loc104 = loc("./scratch/dave.mlir":103:12)
#loc105 = loc("./scratch/dave.mlir":104:12)
#loc106 = loc("./scratch/dave.mlir":105:12)
#loc107 = loc("./scratch/dave.mlir":106:12)
#loc108 = loc("./scratch/dave.mlir":107:12)
#loc109 = loc("./scratch/dave.mlir":108:12)
#loc110 = loc("./scratch/dave.mlir":109:12)
#loc111 = loc("./scratch/dave.mlir":110:12)
#loc112 = loc("./scratch/dave.mlir":111:12)
#loc113 = loc("./scratch/dave.mlir":112:12)
#loc114 = loc("./scratch/dave.mlir":113:12)
#loc115 = loc("./scratch/dave.mlir":114:12)
#loc116 = loc("./scratch/dave.mlir":115:12)
#loc117 = loc("./scratch/dave.mlir":116:12)
#loc118 = loc("./scratch/dave.mlir":117:12)
#loc119 = loc("./scratch/dave.mlir":118:12)
#loc120 = loc("./scratch/dave.mlir":119:12)
#loc121 = loc("./scratch/dave.mlir":120:12)
#loc122 = loc("./scratch/dave.mlir":121:12)
#loc123 = loc("./scratch/dave.mlir":122:12)
#loc124 = loc("./scratch/dave.mlir":123:12)
#loc125 = loc("./scratch/dave.mlir":124:12)
#loc126 = loc("./scratch/dave.mlir":125:12)
#loc127 = loc("./scratch/dave.mlir":126:12)
#loc128 = loc("./scratch/dave.mlir":127:12)
#loc129 = loc("./scratch/dave.mlir":128:12)
#loc130 = loc("./scratch/dave.mlir":129:12)
#loc131 = loc("./scratch/dave.mlir":130:12)
#loc132 = loc("./scratch/dave.mlir":131:12)
#loc133 = loc("./scratch/dave.mlir":132:12)
#loc134 = loc("./scratch/dave.mlir":133:12)
#loc135 = loc("./scratch/dave.mlir":134:12)
#loc136 = loc("./scratch/dave.mlir":135:12)
#loc137 = loc("./scratch/dave.mlir":136:12)
#loc138 = loc("./scratch/dave.mlir":137:12)
#loc139 = loc("./scratch/dave.mlir":138:12)
#loc140 = loc("./scratch/dave.mlir":139:12)
#loc141 = loc("./scratch/dave.mlir":140:12)
#loc142 = loc("./scratch/dave.mlir":141:12)
#loc143 = loc("./scratch/dave.mlir":142:12)
#loc144 = loc("./scratch/dave.mlir":143:12)
#loc145 = loc("./scratch/dave.mlir":144:12)
#loc146 = loc("./scratch/dave.mlir":145:12)
#loc147 = loc("./scratch/dave.mlir":146:12)
#loc148 = loc("./scratch/dave.mlir":147:12)
#loc149 = loc("./scratch/dave.mlir":148:12)
#loc150 = loc("./scratch/dave.mlir":149:12)
#loc151 = loc("./scratch/dave.mlir":150:12)
#loc152 = loc("./scratch/dave.mlir":151:12)
#loc153 = loc("./scratch/dave.mlir":152:12)
#loc154 = loc("./scratch/dave.mlir":153:12)
#loc155 = loc("./scratch/dave.mlir":154:12)
#loc156 = loc("./scratch/dave.mlir":155:12)
#loc157 = loc("./scratch/dave.mlir":156:12)
#loc158 = loc("./scratch/dave.mlir":157:12)
#loc159 = loc("./scratch/dave.mlir":158:12)
#loc160 = loc("./scratch/dave.mlir":159:12)
#loc161 = loc("./scratch/dave.mlir":160:12)
#loc162 = loc("./scratch/dave.mlir":161:12)
#loc163 = loc("./scratch/dave.mlir":162:12)
#loc164 = loc("./scratch/dave.mlir":163:12)
#loc165 = loc("./scratch/dave.mlir":164:12)
#loc166 = loc("./scratch/dave.mlir":165:12)
#loc167 = loc("./scratch/dave.mlir":166:12)
#loc168 = loc("./scratch/dave.mlir":167:12)
#loc169 = loc("./scratch/dave.mlir":168:12)
#loc170 = loc("./scratch/dave.mlir":169:12)
#loc171 = loc("./scratch/dave.mlir":170:12)
#loc172 = loc("./scratch/dave.mlir":171:12)
#loc173 = loc("./scratch/dave.mlir":172:12)
#loc174 = loc("./scratch/dave.mlir":173:12)
#loc175 = loc("./scratch/dave.mlir":174:12)
#loc176 = loc("./scratch/dave.mlir":175:12)
#loc177 = loc("./scratch/dave.mlir":176:12)
#loc178 = loc("./scratch/dave.mlir":177:12)
#loc179 = loc("./scratch/dave.mlir":178:12)
#loc180 = loc("./scratch/dave.mlir":179:12)
#loc181 = loc("./scratch/dave.mlir":180:12)
#loc182 = loc("./scratch/dave.mlir":181:12)
#loc183 = loc("./scratch/dave.mlir":182:12)
#loc184 = loc("./scratch/dave.mlir":183:12)
#loc185 = loc("./scratch/dave.mlir":184:12)
#loc186 = loc("./scratch/dave.mlir":185:12)
#loc187 = loc("./scratch/dave.mlir":186:12)
#loc188 = loc("./scratch/dave.mlir":187:12)
#loc189 = loc("./scratch/dave.mlir":188:12)
#loc190 = loc("./scratch/dave.mlir":189:12)
#loc191 = loc("./scratch/dave.mlir":190:12)
#loc192 = loc("./scratch/dave.mlir":191:12)
#loc193 = loc("./scratch/dave.mlir":192:12)
#loc194 = loc("./scratch/dave.mlir":193:12)
#loc195 = loc("./scratch/dave.mlir":194:12)
#loc196 = loc("./scratch/dave.mlir":195:12)
#loc197 = loc("./scratch/dave.mlir":196:12)
#loc198 = loc("./scratch/dave.mlir":197:12)
#loc199 = loc("./scratch/dave.mlir":198:12)
#loc200 = loc("./scratch/dave.mlir":199:12)
#loc201 = loc("./scratch/dave.mlir":200:12)
#loc202 = loc("./scratch/dave.mlir":201:12)
#loc203 = loc("./scratch/dave.mlir":202:12)
#loc204 = loc("./scratch/dave.mlir":203:12)
#loc205 = loc("./scratch/dave.mlir":204:12)
#loc206 = loc("./scratch/dave.mlir":205:12)
#loc207 = loc("./scratch/dave.mlir":206:12)
#loc208 = loc("./scratch/dave.mlir":207:12)
#loc209 = loc("./scratch/dave.mlir":208:12)
#loc210 = loc("./scratch/dave.mlir":209:12)
#loc211 = loc("./scratch/dave.mlir":210:12)
#loc212 = loc("./scratch/dave.mlir":211:12)
#loc213 = loc("./scratch/dave.mlir":212:12)
#loc214 = loc("./scratch/dave.mlir":213:12)
#loc215 = loc("./scratch/dave.mlir":214:12)
#loc216 = loc("./scratch/dave.mlir":215:12)
#loc217 = loc("./scratch/dave.mlir":216:12)
#loc218 = loc("./scratch/dave.mlir":217:12)
#loc219 = loc("./scratch/dave.mlir":218:12)
#loc220 = loc("./scratch/dave.mlir":219:12)
#loc221 = loc("./scratch/dave.mlir":220:12)
#loc222 = loc("./scratch/dave.mlir":221:12)
#loc223 = loc("./scratch/dave.mlir":222:12)
#loc224 = loc("./scratch/dave.mlir":223:12)
#loc225 = loc("./scratch/dave.mlir":224:12)
#loc226 = loc("./scratch/dave.mlir":225:12)
#loc227 = loc("./scratch/dave.mlir":226:12)
#loc228 = loc("./scratch/dave.mlir":227:12)
#loc229 = loc("./scratch/dave.mlir":228:12)
#loc230 = loc("./scratch/dave.mlir":229:12)
#loc231 = loc("./scratch/dave.mlir":230:12)
#loc232 = loc("./scratch/dave.mlir":231:12)
#loc233 = loc("./scratch/dave.mlir":232:12)
#loc234 = loc("./scratch/dave.mlir":233:12)
#loc235 = loc("./scratch/dave.mlir":234:12)
#loc236 = loc("./scratch/dave.mlir":235:12)
#loc237 = loc("./scratch/dave.mlir":236:12)
#loc238 = loc("./scratch/dave.mlir":237:12)
#loc239 = loc("./scratch/dave.mlir":238:12)
#loc240 = loc("./scratch/dave.mlir":239:12)
#loc241 = loc("./scratch/dave.mlir":240:12)
#loc242 = loc("./scratch/dave.mlir":241:12)
#loc243 = loc("./scratch/dave.mlir":242:12)
#loc244 = loc("./scratch/dave.mlir":243:12)
#loc245 = loc("./scratch/dave.mlir":244:12)
#loc246 = loc("./scratch/dave.mlir":245:12)
#loc247 = loc("./scratch/dave.mlir":246:12)
#loc248 = loc("./scratch/dave.mlir":247:12)
#loc249 = loc("./scratch/dave.mlir":248:12)
#loc250 = loc("./scratch/dave.mlir":249:12)
#loc251 = loc("./scratch/dave.mlir":250:12)
#loc252 = loc("./scratch/dave.mlir":251:12)
#loc253 = loc("./scratch/dave.mlir":252:12)
#loc254 = loc("./scratch/dave.mlir":253:12)
#loc255 = loc("./scratch/dave.mlir":254:12)
#loc256 = loc("./scratch/dave.mlir":255:12)
#loc257 = loc("./scratch/dave.mlir":256:12)
#loc258 = loc("./scratch/dave.mlir":257:12)
#loc259 = loc("./scratch/dave.mlir":258:12)
#loc260 = loc("./scratch/dave.mlir":259:12)
#loc261 = loc("./scratch/dave.mlir":260:12)
#loc262 = loc("./scratch/dave.mlir":261:12)
#loc263 = loc("./scratch/dave.mlir":262:12)
#loc264 = loc("./scratch/dave.mlir":263:12)
#loc265 = loc("./scratch/dave.mlir":264:12)
#loc266 = loc("./scratch/dave.mlir":265:12)
#loc267 = loc("./scratch/dave.mlir":266:12)
#loc268 = loc("./scratch/dave.mlir":267:12)
#loc269 = loc("./scratch/dave.mlir":268:12)
#loc270 = loc("./scratch/dave.mlir":269:12)
#loc271 = loc("./scratch/dave.mlir":270:12)
#loc272 = loc("./scratch/dave.mlir":271:12)
#loc273 = loc("./scratch/dave.mlir":272:12)
#loc274 = loc("./scratch/dave.mlir":273:12)
#loc275 = loc("./scratch/dave.mlir":274:12)
#loc276 = loc("./scratch/dave.mlir":275:12)
#loc277 = loc("./scratch/dave.mlir":276:12)
#loc278 = loc("./scratch/dave.mlir":277:12)
#loc279 = loc("./scratch/dave.mlir":278:12)
#loc280 = loc("./scratch/dave.mlir":279:12)
#loc281 = loc("./scratch/dave.mlir":280:12)
#loc282 = loc("./scratch/dave.mlir":281:12)
#loc283 = loc("./scratch/dave.mlir":282:12)
#loc284 = loc("./scratch/dave.mlir":283:12)
#loc285 = loc("./scratch/dave.mlir":284:12)
#loc286 = loc("./scratch/dave.mlir":285:12)
#loc287 = loc("./scratch/dave.mlir":286:12)
#loc288 = loc("./scratch/dave.mlir":287:12)
#loc289 = loc("./scratch/dave.mlir":288:12)
#loc290 = loc("./scratch/dave.mlir":289:12)
#loc291 = loc("./scratch/dave.mlir":290:12)
#loc292 = loc("./scratch/dave.mlir":291:12)
#loc293 = loc("./scratch/dave.mlir":292:12)
#loc294 = loc("./scratch/dave.mlir":293:12)
#loc295 = loc("./scratch/dave.mlir":294:12)
#loc296 = loc("./scratch/dave.mlir":295:12)
#loc297 = loc("./scratch/dave.mlir":296:12)
#loc298 = loc("./scratch/dave.mlir":297:12)
#loc299 = loc("./scratch/dave.mlir":298:12)
#loc300 = loc("./scratch/dave.mlir":300:12)
#loc301 = loc("./scratch/dave.mlir":301:12)
#loc302 = loc("./scratch/dave.mlir":302:12)
#loc303 = loc("./scratch/dave.mlir":303:12)
#loc304 = loc("./scratch/dave.mlir":304:12)
#loc305 = loc("./scratch/dave.mlir":305:12)
#loc306 = loc("./scratch/dave.mlir":306:12)
#loc307 = loc("./scratch/dave.mlir":307:12)
#loc308 = loc("./scratch/dave.mlir":308:12)
#loc309 = loc("./scratch/dave.mlir":309:12)
#loc310 = loc("./scratch/dave.mlir":310:12)
#loc311 = loc("./scratch/dave.mlir":311:12)
#loc312 = loc("./scratch/dave.mlir":312:12)
#loc313 = loc("./scratch/dave.mlir":313:12)
#loc314 = loc("./scratch/dave.mlir":314:12)
#loc315 = loc("./scratch/dave.mlir":315:12)
#loc316 = loc("./scratch/dave.mlir":316:12)
#loc317 = loc("./scratch/dave.mlir":317:12)
#loc318 = loc("./scratch/dave.mlir":318:12)
#loc319 = loc("./scratch/dave.mlir":319:12)
#loc320 = loc("./scratch/dave.mlir":320:12)
#loc321 = loc("./scratch/dave.mlir":321:12)
#loc322 = loc("./scratch/dave.mlir":322:12)
#loc323 = loc("./scratch/dave.mlir":323:12)
#loc324 = loc("./scratch/dave.mlir":324:12)
#loc325 = loc("./scratch/dave.mlir":325:12)
#loc326 = loc("./scratch/dave.mlir":326:12)
#loc327 = loc("./scratch/dave.mlir":327:12)
#loc328 = loc("./scratch/dave.mlir":328:12)
#loc329 = loc("./scratch/dave.mlir":3359:5)
#loc330 = loc("./scratch/dave.mlir":329:12)
#loc331 = loc("./scratch/dave.mlir":330:12)
#loc332 = loc("./scratch/dave.mlir":331:12)
#loc333 = loc("./scratch/dave.mlir":332:12)
#loc334 = loc("./scratch/dave.mlir":333:12)
#loc335 = loc("./scratch/dave.mlir":334:12)
#loc336 = loc("./scratch/dave.mlir":335:12)
#loc337 = loc("./scratch/dave.mlir":336:12)
#loc338 = loc("./scratch/dave.mlir":337:12)
#loc339 = loc("./scratch/dave.mlir":338:12)
#loc340 = loc("./scratch/dave.mlir":339:12)
#loc341 = loc("./scratch/dave.mlir":340:12)
#loc342 = loc("./scratch/dave.mlir":341:12)
#loc343 = loc("./scratch/dave.mlir":342:12)
#loc344 = loc("./scratch/dave.mlir":343:12)
#loc345 = loc("./scratch/dave.mlir":344:12)
#loc346 = loc("./scratch/dave.mlir":345:12)
#loc347 = loc("./scratch/dave.mlir":346:12)
#loc348 = loc("./scratch/dave.mlir":347:12)
#loc349 = loc("./scratch/dave.mlir":348:12)
#loc350 = loc("./scratch/dave.mlir":349:12)
#loc351 = loc("./scratch/dave.mlir":350:12)
#loc352 = loc("./scratch/dave.mlir":351:12)
#loc353 = loc("./scratch/dave.mlir":352:12)
#loc354 = loc("./scratch/dave.mlir":353:12)
#loc355 = loc("./scratch/dave.mlir":354:12)
#loc356 = loc("./scratch/dave.mlir":355:12)
#loc357 = loc("./scratch/dave.mlir":356:12)
#loc358 = loc("./scratch/dave.mlir":357:12)
#loc359 = loc("./scratch/dave.mlir":358:12)
#loc360 = loc("./scratch/dave.mlir":359:12)
#loc361 = loc("./scratch/dave.mlir":360:12)
#loc362 = loc("./scratch/dave.mlir":361:12)
#loc363 = loc("./scratch/dave.mlir":362:12)
#loc364 = loc("./scratch/dave.mlir":363:12)
#loc365 = loc("./scratch/dave.mlir":364:12)
#loc366 = loc("./scratch/dave.mlir":365:12)
#loc367 = loc("./scratch/dave.mlir":366:12)
#loc368 = loc("./scratch/dave.mlir":367:12)
#loc369 = loc("./scratch/dave.mlir":368:12)
#loc370 = loc("./scratch/dave.mlir":369:12)
#loc371 = loc("./scratch/dave.mlir":370:12)
#loc372 = loc("./scratch/dave.mlir":371:12)
#loc373 = loc("./scratch/dave.mlir":372:12)
#loc374 = loc("./scratch/dave.mlir":373:12)
#loc375 = loc("./scratch/dave.mlir":374:12)
#loc376 = loc("./scratch/dave.mlir":375:12)
#loc377 = loc("./scratch/dave.mlir":376:12)
#loc378 = loc("./scratch/dave.mlir":377:12)
#loc379 = loc("./scratch/dave.mlir":378:12)
#loc380 = loc("./scratch/dave.mlir":379:12)
#loc381 = loc("./scratch/dave.mlir":380:12)
#loc382 = loc("./scratch/dave.mlir":381:12)
#loc383 = loc("./scratch/dave.mlir":382:12)
#loc384 = loc("./scratch/dave.mlir":383:12)
#loc385 = loc("./scratch/dave.mlir":384:12)
#loc386 = loc("./scratch/dave.mlir":385:12)
#loc387 = loc("./scratch/dave.mlir":386:12)
#loc388 = loc("./scratch/dave.mlir":387:12)
#loc389 = loc("./scratch/dave.mlir":388:12)
#loc390 = loc("./scratch/dave.mlir":389:12)
#loc391 = loc("./scratch/dave.mlir":390:12)
#loc392 = loc("./scratch/dave.mlir":391:12)
#loc393 = loc("./scratch/dave.mlir":392:12)
#loc394 = loc("./scratch/dave.mlir":393:12)
#loc395 = loc("./scratch/dave.mlir":394:12)
#loc396 = loc("./scratch/dave.mlir":395:12)
#loc397 = loc("./scratch/dave.mlir":396:12)
#loc398 = loc("./scratch/dave.mlir":397:12)
#loc399 = loc("./scratch/dave.mlir":398:12)
#loc400 = loc("./scratch/dave.mlir":399:12)
#loc401 = loc("./scratch/dave.mlir":400:12)
#loc402 = loc("./scratch/dave.mlir":401:12)
#loc403 = loc("./scratch/dave.mlir":402:12)
#loc404 = loc("./scratch/dave.mlir":403:12)
#loc405 = loc("./scratch/dave.mlir":404:12)
#loc406 = loc("./scratch/dave.mlir":405:12)
#loc407 = loc("./scratch/dave.mlir":406:12)
#loc408 = loc("./scratch/dave.mlir":407:12)
#loc409 = loc("./scratch/dave.mlir":408:12)
#loc410 = loc("./scratch/dave.mlir":409:12)
#loc411 = loc("./scratch/dave.mlir":410:12)
#loc412 = loc("./scratch/dave.mlir":411:12)
#loc413 = loc("./scratch/dave.mlir":412:12)
#loc414 = loc("./scratch/dave.mlir":413:12)
#loc415 = loc("./scratch/dave.mlir":414:12)
#loc416 = loc("./scratch/dave.mlir":415:12)
#loc417 = loc("./scratch/dave.mlir":416:12)
#loc418 = loc("./scratch/dave.mlir":417:12)
#loc419 = loc("./scratch/dave.mlir":418:12)
#loc420 = loc("./scratch/dave.mlir":419:12)
#loc421 = loc("./scratch/dave.mlir":420:12)
#loc422 = loc("./scratch/dave.mlir":421:12)
#loc423 = loc("./scratch/dave.mlir":422:12)
#loc424 = loc("./scratch/dave.mlir":423:12)
#loc425 = loc("./scratch/dave.mlir":424:12)
#loc426 = loc("./scratch/dave.mlir":425:12)
#loc427 = loc("./scratch/dave.mlir":426:12)
#loc428 = loc("./scratch/dave.mlir":427:12)
#loc429 = loc("./scratch/dave.mlir":428:12)
#loc430 = loc("./scratch/dave.mlir":429:12)
#loc431 = loc("./scratch/dave.mlir":430:12)
#loc432 = loc("./scratch/dave.mlir":431:12)
#loc433 = loc("./scratch/dave.mlir":432:12)
#loc434 = loc("./scratch/dave.mlir":433:12)
#loc435 = loc("./scratch/dave.mlir":434:12)
#loc436 = loc("./scratch/dave.mlir":435:12)
#loc437 = loc("./scratch/dave.mlir":436:12)
#loc438 = loc("./scratch/dave.mlir":437:12)
#loc439 = loc("./scratch/dave.mlir":438:12)
#loc440 = loc("./scratch/dave.mlir":439:12)
#loc441 = loc("./scratch/dave.mlir":440:12)
#loc442 = loc("./scratch/dave.mlir":441:12)
#loc443 = loc("./scratch/dave.mlir":442:12)
#loc444 = loc("./scratch/dave.mlir":443:12)
#loc445 = loc("./scratch/dave.mlir":444:12)
#loc446 = loc("./scratch/dave.mlir":445:12)
#loc447 = loc("./scratch/dave.mlir":446:12)
#loc448 = loc("./scratch/dave.mlir":447:12)
#loc449 = loc("./scratch/dave.mlir":448:12)
#loc450 = loc("./scratch/dave.mlir":449:12)
#loc451 = loc("./scratch/dave.mlir":450:12)
#loc452 = loc("./scratch/dave.mlir":451:12)
#loc453 = loc("./scratch/dave.mlir":452:12)
#loc454 = loc("./scratch/dave.mlir":453:12)
#loc455 = loc("./scratch/dave.mlir":454:12)
#loc456 = loc("./scratch/dave.mlir":455:12)
#loc457 = loc("./scratch/dave.mlir":456:12)
#loc458 = loc("./scratch/dave.mlir":457:12)
#loc459 = loc("./scratch/dave.mlir":458:12)
#loc460 = loc("./scratch/dave.mlir":459:12)
#loc461 = loc("./scratch/dave.mlir":460:12)
#loc462 = loc("./scratch/dave.mlir":461:12)
#loc463 = loc("./scratch/dave.mlir":462:12)
#loc464 = loc("./scratch/dave.mlir":463:12)
#loc465 = loc("./scratch/dave.mlir":464:12)
#loc466 = loc("./scratch/dave.mlir":465:12)
#loc467 = loc("./scratch/dave.mlir":466:12)
#loc468 = loc("./scratch/dave.mlir":467:12)
#loc469 = loc("./scratch/dave.mlir":468:12)
#loc470 = loc("./scratch/dave.mlir":469:12)
#loc471 = loc("./scratch/dave.mlir":470:12)
#loc472 = loc("./scratch/dave.mlir":471:12)
#loc473 = loc("./scratch/dave.mlir":472:12)
#loc474 = loc("./scratch/dave.mlir":473:12)
#loc475 = loc("./scratch/dave.mlir":474:12)
#loc476 = loc("./scratch/dave.mlir":475:12)
#loc477 = loc("./scratch/dave.mlir":476:12)
#loc478 = loc("./scratch/dave.mlir":477:12)
#loc479 = loc("./scratch/dave.mlir":478:12)
#loc480 = loc("./scratch/dave.mlir":479:12)
#loc481 = loc("./scratch/dave.mlir":480:12)
#loc482 = loc("./scratch/dave.mlir":481:12)
#loc483 = loc("./scratch/dave.mlir":482:12)
#loc484 = loc("./scratch/dave.mlir":483:12)
#loc485 = loc("./scratch/dave.mlir":484:12)
#loc486 = loc("./scratch/dave.mlir":485:12)
#loc487 = loc("./scratch/dave.mlir":486:12)
#loc488 = loc("./scratch/dave.mlir":487:12)
#loc489 = loc("./scratch/dave.mlir":488:12)
#loc490 = loc("./scratch/dave.mlir":489:12)
#loc491 = loc("./scratch/dave.mlir":490:12)
#loc492 = loc("./scratch/dave.mlir":491:12)
#loc493 = loc("./scratch/dave.mlir":492:12)
#loc494 = loc("./scratch/dave.mlir":493:12)
#loc495 = loc("./scratch/dave.mlir":494:12)
#loc496 = loc("./scratch/dave.mlir":495:12)
#loc497 = loc("./scratch/dave.mlir":496:12)
#loc498 = loc("./scratch/dave.mlir":497:12)
#loc499 = loc("./scratch/dave.mlir":498:12)
#loc500 = loc("./scratch/dave.mlir":499:12)
#loc501 = loc("./scratch/dave.mlir":500:12)
#loc502 = loc("./scratch/dave.mlir":501:12)
#loc503 = loc("./scratch/dave.mlir":502:12)
#loc504 = loc("./scratch/dave.mlir":503:12)
#loc505 = loc("./scratch/dave.mlir":504:12)
#loc506 = loc("./scratch/dave.mlir":505:12)
#loc507 = loc("./scratch/dave.mlir":506:12)
#loc508 = loc("./scratch/dave.mlir":507:12)
#loc509 = loc("./scratch/dave.mlir":508:12)
#loc510 = loc("./scratch/dave.mlir":509:12)
#loc511 = loc("./scratch/dave.mlir":510:12)
#loc512 = loc("./scratch/dave.mlir":511:12)
#loc513 = loc("./scratch/dave.mlir":512:12)
#loc514 = loc("./scratch/dave.mlir":513:12)
#loc515 = loc("./scratch/dave.mlir":514:12)
#loc516 = loc("./scratch/dave.mlir":515:12)
#loc517 = loc("./scratch/dave.mlir":516:12)
#loc518 = loc("./scratch/dave.mlir":517:12)
#loc519 = loc("./scratch/dave.mlir":518:12)
#loc520 = loc("./scratch/dave.mlir":519:12)
#loc521 = loc("./scratch/dave.mlir":520:12)
#loc522 = loc("./scratch/dave.mlir":521:12)
#loc523 = loc("./scratch/dave.mlir":522:12)
#loc524 = loc("./scratch/dave.mlir":523:12)
#loc525 = loc("./scratch/dave.mlir":524:12)
#loc526 = loc("./scratch/dave.mlir":525:12)
#loc527 = loc("./scratch/dave.mlir":526:12)
#loc528 = loc("./scratch/dave.mlir":527:12)
#loc529 = loc("./scratch/dave.mlir":528:12)
#loc530 = loc("./scratch/dave.mlir":529:12)
#loc531 = loc("./scratch/dave.mlir":530:12)
#loc532 = loc("./scratch/dave.mlir":531:12)
#loc533 = loc("./scratch/dave.mlir":532:12)
#loc534 = loc("./scratch/dave.mlir":533:12)
#loc535 = loc("./scratch/dave.mlir":534:12)
#loc536 = loc("./scratch/dave.mlir":535:12)
#loc537 = loc("./scratch/dave.mlir":536:12)
#loc538 = loc("./scratch/dave.mlir":537:12)
#loc539 = loc("./scratch/dave.mlir":538:12)
#loc540 = loc("./scratch/dave.mlir":539:12)
#loc541 = loc("./scratch/dave.mlir":540:12)
#loc542 = loc("./scratch/dave.mlir":541:12)
#loc543 = loc("./scratch/dave.mlir":542:12)
#loc544 = loc("./scratch/dave.mlir":543:12)
#loc545 = loc("./scratch/dave.mlir":544:12)
#loc546 = loc("./scratch/dave.mlir":545:12)
#loc547 = loc("./scratch/dave.mlir":546:12)
#loc548 = loc("./scratch/dave.mlir":547:12)
#loc549 = loc("./scratch/dave.mlir":548:12)
#loc550 = loc("./scratch/dave.mlir":549:12)
#loc551 = loc("./scratch/dave.mlir":550:12)
#loc552 = loc("./scratch/dave.mlir":551:12)
#loc553 = loc("./scratch/dave.mlir":552:12)
#loc554 = loc("./scratch/dave.mlir":553:12)
#loc555 = loc("./scratch/dave.mlir":554:12)
#loc556 = loc("./scratch/dave.mlir":555:12)
#loc557 = loc("./scratch/dave.mlir":556:12)
#loc558 = loc("./scratch/dave.mlir":557:12)
#loc559 = loc("./scratch/dave.mlir":558:12)
#loc560 = loc("./scratch/dave.mlir":559:12)
#loc561 = loc("./scratch/dave.mlir":560:12)
#loc562 = loc("./scratch/dave.mlir":561:12)
#loc563 = loc("./scratch/dave.mlir":562:12)
#loc564 = loc("./scratch/dave.mlir":563:12)
#loc565 = loc("./scratch/dave.mlir":564:12)
#loc566 = loc("./scratch/dave.mlir":565:12)
#loc567 = loc("./scratch/dave.mlir":566:12)
#loc568 = loc("./scratch/dave.mlir":567:12)
#loc569 = loc("./scratch/dave.mlir":568:12)
#loc570 = loc("./scratch/dave.mlir":569:12)
#loc571 = loc("./scratch/dave.mlir":570:12)
#loc572 = loc("./scratch/dave.mlir":571:12)
#loc573 = loc("./scratch/dave.mlir":572:12)
#loc574 = loc("./scratch/dave.mlir":573:12)
#loc575 = loc("./scratch/dave.mlir":574:12)
#loc576 = loc("./scratch/dave.mlir":575:12)
#loc577 = loc("./scratch/dave.mlir":576:12)
#loc578 = loc("./scratch/dave.mlir":577:12)
#loc579 = loc("./scratch/dave.mlir":578:12)
#loc580 = loc("./scratch/dave.mlir":579:12)
#loc581 = loc("./scratch/dave.mlir":580:12)
#loc582 = loc("./scratch/dave.mlir":581:12)
#loc583 = loc("./scratch/dave.mlir":582:12)
#loc584 = loc("./scratch/dave.mlir":583:12)
#loc585 = loc("./scratch/dave.mlir":584:12)
#loc586 = loc("./scratch/dave.mlir":585:12)
#loc587 = loc("./scratch/dave.mlir":586:12)
#loc588 = loc("./scratch/dave.mlir":587:12)
#loc589 = loc("./scratch/dave.mlir":588:12)
#loc590 = loc("./scratch/dave.mlir":589:12)
#loc591 = loc("./scratch/dave.mlir":590:12)
#loc592 = loc("./scratch/dave.mlir":591:12)
#loc593 = loc("./scratch/dave.mlir":592:12)
#loc594 = loc("./scratch/dave.mlir":593:12)
#loc595 = loc("./scratch/dave.mlir":594:12)
#loc596 = loc("./scratch/dave.mlir":595:12)
#loc597 = loc("./scratch/dave.mlir":596:12)
#loc598 = loc("./scratch/dave.mlir":597:12)
#loc599 = loc("./scratch/dave.mlir":598:12)
#loc600 = loc("./scratch/dave.mlir":599:12)
#loc601 = loc("./scratch/dave.mlir":600:12)
#loc602 = loc("./scratch/dave.mlir":601:12)
#loc603 = loc("./scratch/dave.mlir":602:12)
#loc604 = loc("./scratch/dave.mlir":603:12)
#loc605 = loc("./scratch/dave.mlir":604:12)
#loc606 = loc("./scratch/dave.mlir":605:12)
#loc607 = loc("./scratch/dave.mlir":606:12)
#loc608 = loc("./scratch/dave.mlir":607:12)
#loc609 = loc("./scratch/dave.mlir":608:12)
#loc610 = loc("./scratch/dave.mlir":609:12)
#loc611 = loc("./scratch/dave.mlir":610:12)
#loc612 = loc("./scratch/dave.mlir":611:12)
#loc613 = loc("./scratch/dave.mlir":612:12)
#loc614 = loc("./scratch/dave.mlir":613:12)
#loc615 = loc("./scratch/dave.mlir":614:12)
#loc616 = loc("./scratch/dave.mlir":615:12)
#loc617 = loc("./scratch/dave.mlir":616:12)
#loc618 = loc("./scratch/dave.mlir":617:12)
#loc619 = loc("./scratch/dave.mlir":618:12)
#loc620 = loc("./scratch/dave.mlir":619:12)
#loc621 = loc("./scratch/dave.mlir":620:12)
#loc622 = loc("./scratch/dave.mlir":621:12)
#loc623 = loc("./scratch/dave.mlir":622:12)
#loc624 = loc("./scratch/dave.mlir":623:12)
#loc625 = loc("./scratch/dave.mlir":624:12)
#loc626 = loc("./scratch/dave.mlir":625:12)
#loc627 = loc("./scratch/dave.mlir":626:12)
#loc628 = loc("./scratch/dave.mlir":627:12)
#loc629 = loc("./scratch/dave.mlir":628:12)
#loc630 = loc("./scratch/dave.mlir":629:12)
#loc631 = loc("./scratch/dave.mlir":630:12)
#loc632 = loc("./scratch/dave.mlir":631:12)
#loc633 = loc("./scratch/dave.mlir":632:12)
#loc634 = loc("./scratch/dave.mlir":633:12)
#loc635 = loc("./scratch/dave.mlir":634:12)
#loc636 = loc("./scratch/dave.mlir":635:12)
#loc637 = loc("./scratch/dave.mlir":636:12)
#loc638 = loc("./scratch/dave.mlir":637:12)
#loc639 = loc("./scratch/dave.mlir":638:12)
#loc640 = loc("./scratch/dave.mlir":639:12)
#loc641 = loc("./scratch/dave.mlir":640:12)
#loc642 = loc("./scratch/dave.mlir":641:12)
#loc643 = loc("./scratch/dave.mlir":642:12)
#loc644 = loc("./scratch/dave.mlir":643:12)
#loc645 = loc("./scratch/dave.mlir":644:12)
#loc646 = loc("./scratch/dave.mlir":645:12)
#loc647 = loc("./scratch/dave.mlir":646:12)
#loc648 = loc("./scratch/dave.mlir":647:12)
#loc649 = loc("./scratch/dave.mlir":648:12)
#loc650 = loc("./scratch/dave.mlir":649:12)
#loc651 = loc("./scratch/dave.mlir":650:12)
#loc652 = loc("./scratch/dave.mlir":651:12)
#loc653 = loc("./scratch/dave.mlir":652:12)
#loc654 = loc("./scratch/dave.mlir":653:12)
#loc655 = loc("./scratch/dave.mlir":654:12)
#loc656 = loc("./scratch/dave.mlir":655:12)
#loc657 = loc("./scratch/dave.mlir":656:12)
#loc658 = loc("./scratch/dave.mlir":657:12)
#loc659 = loc("./scratch/dave.mlir":658:12)
#loc660 = loc("./scratch/dave.mlir":659:12)
#loc661 = loc("./scratch/dave.mlir":660:12)
#loc662 = loc("./scratch/dave.mlir":661:12)
#loc663 = loc("./scratch/dave.mlir":662:12)
#loc664 = loc("./scratch/dave.mlir":663:12)
#loc665 = loc("./scratch/dave.mlir":664:12)
#loc666 = loc("./scratch/dave.mlir":665:12)
#loc667 = loc("./scratch/dave.mlir":666:12)
#loc668 = loc("./scratch/dave.mlir":667:12)
#loc669 = loc("./scratch/dave.mlir":668:12)
#loc670 = loc("./scratch/dave.mlir":669:12)
#loc671 = loc("./scratch/dave.mlir":670:12)
#loc672 = loc("./scratch/dave.mlir":671:12)
#loc673 = loc("./scratch/dave.mlir":672:12)
#loc674 = loc("./scratch/dave.mlir":673:12)
#loc675 = loc("./scratch/dave.mlir":674:12)
#loc676 = loc("./scratch/dave.mlir":675:12)
#loc677 = loc("./scratch/dave.mlir":676:12)
#loc678 = loc("./scratch/dave.mlir":677:12)
#loc679 = loc("./scratch/dave.mlir":678:12)
#loc680 = loc("./scratch/dave.mlir":679:12)
#loc681 = loc("./scratch/dave.mlir":680:12)
#loc682 = loc("./scratch/dave.mlir":681:12)
#loc683 = loc("./scratch/dave.mlir":682:12)
#loc684 = loc("./scratch/dave.mlir":683:12)
#loc685 = loc("./scratch/dave.mlir":684:12)
#loc686 = loc("./scratch/dave.mlir":685:12)
#loc687 = loc("./scratch/dave.mlir":686:12)
#loc688 = loc("./scratch/dave.mlir":687:12)
#loc689 = loc("./scratch/dave.mlir":688:12)
#loc690 = loc("./scratch/dave.mlir":689:12)
#loc691 = loc("./scratch/dave.mlir":690:12)
#loc692 = loc("./scratch/dave.mlir":691:12)
#loc693 = loc("./scratch/dave.mlir":692:12)
#loc694 = loc("./scratch/dave.mlir":693:12)
#loc695 = loc("./scratch/dave.mlir":694:12)
#loc696 = loc("./scratch/dave.mlir":695:12)
#loc697 = loc("./scratch/dave.mlir":696:12)
#loc698 = loc("./scratch/dave.mlir":697:12)
#loc699 = loc("./scratch/dave.mlir":698:12)
#loc700 = loc("./scratch/dave.mlir":699:12)
#loc701 = loc("./scratch/dave.mlir":700:12)
#loc702 = loc("./scratch/dave.mlir":701:12)
#loc703 = loc("./scratch/dave.mlir":702:12)
#loc704 = loc("./scratch/dave.mlir":703:12)
#loc705 = loc("./scratch/dave.mlir":704:12)
#loc706 = loc("./scratch/dave.mlir":705:12)
#loc707 = loc("./scratch/dave.mlir":706:12)
#loc708 = loc("./scratch/dave.mlir":707:12)
#loc709 = loc("./scratch/dave.mlir":708:12)
#loc710 = loc("./scratch/dave.mlir":709:12)
#loc711 = loc("./scratch/dave.mlir":710:12)
#loc712 = loc("./scratch/dave.mlir":711:12)
#loc713 = loc("./scratch/dave.mlir":712:12)
#loc714 = loc("./scratch/dave.mlir":713:12)
#loc715 = loc("./scratch/dave.mlir":714:12)
#loc716 = loc("./scratch/dave.mlir":715:12)
#loc717 = loc("./scratch/dave.mlir":716:12)
#loc718 = loc("./scratch/dave.mlir":717:12)
#loc719 = loc("./scratch/dave.mlir":718:12)
#loc720 = loc("./scratch/dave.mlir":719:12)
#loc721 = loc("./scratch/dave.mlir":720:12)
#loc722 = loc("./scratch/dave.mlir":721:12)
#loc723 = loc("./scratch/dave.mlir":722:12)
#loc724 = loc("./scratch/dave.mlir":723:12)
#loc725 = loc("./scratch/dave.mlir":724:12)
#loc726 = loc("./scratch/dave.mlir":725:12)
#loc727 = loc("./scratch/dave.mlir":726:12)
#loc728 = loc("./scratch/dave.mlir":727:12)
#loc729 = loc("./scratch/dave.mlir":728:12)
#loc730 = loc("./scratch/dave.mlir":729:12)
#loc731 = loc("./scratch/dave.mlir":730:12)
#loc732 = loc("./scratch/dave.mlir":731:12)
#loc733 = loc("./scratch/dave.mlir":732:12)
#loc734 = loc("./scratch/dave.mlir":733:12)
#loc735 = loc("./scratch/dave.mlir":734:12)
#loc736 = loc("./scratch/dave.mlir":735:12)
#loc737 = loc("./scratch/dave.mlir":736:12)
#loc738 = loc("./scratch/dave.mlir":737:12)
#loc739 = loc("./scratch/dave.mlir":738:12)
#loc740 = loc("./scratch/dave.mlir":739:12)
#loc741 = loc("./scratch/dave.mlir":740:12)
#loc742 = loc("./scratch/dave.mlir":741:12)
#loc743 = loc("./scratch/dave.mlir":742:12)
#loc744 = loc("./scratch/dave.mlir":743:12)
#loc745 = loc("./scratch/dave.mlir":744:12)
#loc746 = loc("./scratch/dave.mlir":745:12)
#loc747 = loc("./scratch/dave.mlir":746:12)
#loc748 = loc("./scratch/dave.mlir":747:12)
#loc749 = loc("./scratch/dave.mlir":748:12)
#loc750 = loc("./scratch/dave.mlir":749:12)
#loc751 = loc("./scratch/dave.mlir":750:12)
#loc752 = loc("./scratch/dave.mlir":751:12)
#loc753 = loc("./scratch/dave.mlir":752:12)
#loc754 = loc("./scratch/dave.mlir":753:12)
#loc755 = loc("./scratch/dave.mlir":754:12)
#loc756 = loc("./scratch/dave.mlir":755:12)
#loc757 = loc("./scratch/dave.mlir":756:12)
#loc758 = loc("./scratch/dave.mlir":757:12)
#loc759 = loc("./scratch/dave.mlir":758:12)
#loc760 = loc("./scratch/dave.mlir":759:12)
#loc761 = loc("./scratch/dave.mlir":760:12)
#loc762 = loc("./scratch/dave.mlir":761:12)
#loc763 = loc("./scratch/dave.mlir":762:12)
#loc764 = loc("./scratch/dave.mlir":763:12)
#loc765 = loc("./scratch/dave.mlir":764:12)
#loc766 = loc("./scratch/dave.mlir":765:12)
#loc767 = loc("./scratch/dave.mlir":766:12)
#loc768 = loc("./scratch/dave.mlir":767:12)
#loc769 = loc("./scratch/dave.mlir":768:12)
#loc770 = loc("./scratch/dave.mlir":769:12)
#loc771 = loc("./scratch/dave.mlir":770:12)
#loc772 = loc("./scratch/dave.mlir":771:12)
#loc773 = loc("./scratch/dave.mlir":772:12)
#loc774 = loc("./scratch/dave.mlir":773:12)
#loc775 = loc("./scratch/dave.mlir":774:12)
#loc776 = loc("./scratch/dave.mlir":775:12)
#loc777 = loc("./scratch/dave.mlir":776:12)
#loc778 = loc("./scratch/dave.mlir":777:12)
#loc779 = loc("./scratch/dave.mlir":778:12)
#loc780 = loc("./scratch/dave.mlir":779:12)
#loc781 = loc("./scratch/dave.mlir":780:12)
#loc782 = loc("./scratch/dave.mlir":781:12)
#loc783 = loc("./scratch/dave.mlir":782:12)
#loc784 = loc("./scratch/dave.mlir":783:12)
#loc785 = loc("./scratch/dave.mlir":784:12)
#loc786 = loc("./scratch/dave.mlir":785:12)
#loc787 = loc("./scratch/dave.mlir":786:12)
#loc788 = loc("./scratch/dave.mlir":787:12)
#loc789 = loc("./scratch/dave.mlir":788:12)
#loc790 = loc("./scratch/dave.mlir":789:12)
#loc791 = loc("./scratch/dave.mlir":790:12)
#loc792 = loc("./scratch/dave.mlir":791:12)
#loc793 = loc("./scratch/dave.mlir":792:12)
#loc794 = loc("./scratch/dave.mlir":793:12)
#loc795 = loc("./scratch/dave.mlir":794:12)
#loc796 = loc("./scratch/dave.mlir":795:12)
#loc797 = loc("./scratch/dave.mlir":796:12)
#loc798 = loc("./scratch/dave.mlir":797:12)
#loc799 = loc("./scratch/dave.mlir":798:12)
#loc800 = loc("./scratch/dave.mlir":799:12)
#loc801 = loc("./scratch/dave.mlir":800:12)
#loc802 = loc("./scratch/dave.mlir":801:12)
#loc803 = loc("./scratch/dave.mlir":802:12)
#loc804 = loc("./scratch/dave.mlir":803:12)
#loc805 = loc("./scratch/dave.mlir":804:12)
#loc806 = loc("./scratch/dave.mlir":805:12)
#loc807 = loc("./scratch/dave.mlir":806:12)
#loc808 = loc("./scratch/dave.mlir":807:12)
#loc809 = loc("./scratch/dave.mlir":808:12)
#loc810 = loc("./scratch/dave.mlir":809:12)
#loc811 = loc("./scratch/dave.mlir":810:12)
#loc812 = loc("./scratch/dave.mlir":811:12)
#loc813 = loc("./scratch/dave.mlir":812:12)
#loc814 = loc("./scratch/dave.mlir":813:12)
#loc815 = loc("./scratch/dave.mlir":814:12)
#loc816 = loc("./scratch/dave.mlir":815:12)
#loc817 = loc("./scratch/dave.mlir":816:12)
#loc818 = loc("./scratch/dave.mlir":817:12)
#loc819 = loc("./scratch/dave.mlir":818:12)
#loc820 = loc("./scratch/dave.mlir":819:12)
#loc821 = loc("./scratch/dave.mlir":820:12)
#loc822 = loc("./scratch/dave.mlir":821:12)
#loc823 = loc("./scratch/dave.mlir":822:12)
#loc824 = loc("./scratch/dave.mlir":823:12)
#loc825 = loc("./scratch/dave.mlir":824:12)
#loc826 = loc("./scratch/dave.mlir":825:12)
#loc827 = loc("./scratch/dave.mlir":826:12)
#loc828 = loc("./scratch/dave.mlir":827:12)
#loc829 = loc("./scratch/dave.mlir":828:12)
#loc830 = loc("./scratch/dave.mlir":829:12)
#loc831 = loc("./scratch/dave.mlir":830:12)
#loc832 = loc("./scratch/dave.mlir":831:12)
#loc833 = loc("./scratch/dave.mlir":832:12)
#loc834 = loc("./scratch/dave.mlir":833:12)
#loc835 = loc("./scratch/dave.mlir":834:12)
#loc836 = loc("./scratch/dave.mlir":835:12)
#loc837 = loc("./scratch/dave.mlir":836:12)
#loc838 = loc("./scratch/dave.mlir":837:12)
#loc839 = loc("./scratch/dave.mlir":838:12)
#loc840 = loc("./scratch/dave.mlir":839:12)
#loc841 = loc("./scratch/dave.mlir":840:12)
#loc842 = loc("./scratch/dave.mlir":841:12)
#loc843 = loc("./scratch/dave.mlir":842:12)
#loc844 = loc("./scratch/dave.mlir":843:12)
#loc845 = loc("./scratch/dave.mlir":844:12)
#loc846 = loc("./scratch/dave.mlir":845:12)
#loc847 = loc("./scratch/dave.mlir":846:12)
#loc848 = loc("./scratch/dave.mlir":847:12)
#loc849 = loc("./scratch/dave.mlir":848:12)
#loc850 = loc("./scratch/dave.mlir":849:12)
#loc851 = loc("./scratch/dave.mlir":850:12)
#loc852 = loc("./scratch/dave.mlir":851:12)
#loc853 = loc("./scratch/dave.mlir":852:12)
#loc854 = loc("./scratch/dave.mlir":853:12)
#loc855 = loc("./scratch/dave.mlir":854:12)
#loc856 = loc("./scratch/dave.mlir":855:12)
#loc857 = loc("./scratch/dave.mlir":856:12)
#loc858 = loc("./scratch/dave.mlir":857:12)
#loc859 = loc("./scratch/dave.mlir":858:12)
#loc860 = loc("./scratch/dave.mlir":859:12)
#loc861 = loc("./scratch/dave.mlir":860:12)
#loc862 = loc("./scratch/dave.mlir":861:12)
#loc863 = loc("./scratch/dave.mlir":862:12)
#loc864 = loc("./scratch/dave.mlir":863:12)
#loc865 = loc("./scratch/dave.mlir":864:12)
#loc866 = loc("./scratch/dave.mlir":865:12)
#loc867 = loc("./scratch/dave.mlir":866:12)
#loc868 = loc("./scratch/dave.mlir":867:12)
#loc869 = loc("./scratch/dave.mlir":868:12)
#loc870 = loc("./scratch/dave.mlir":869:12)
#loc871 = loc("./scratch/dave.mlir":870:12)
#loc872 = loc("./scratch/dave.mlir":871:12)
#loc873 = loc("./scratch/dave.mlir":872:12)
#loc874 = loc("./scratch/dave.mlir":873:12)
#loc875 = loc("./scratch/dave.mlir":874:12)
#loc876 = loc("./scratch/dave.mlir":875:12)
#loc877 = loc("./scratch/dave.mlir":876:12)
#loc878 = loc("./scratch/dave.mlir":877:12)
#loc879 = loc("./scratch/dave.mlir":878:12)
#loc880 = loc("./scratch/dave.mlir":879:12)
#loc881 = loc("./scratch/dave.mlir":880:12)
#loc882 = loc("./scratch/dave.mlir":881:12)
#loc883 = loc("./scratch/dave.mlir":882:12)
#loc884 = loc("./scratch/dave.mlir":883:12)
#loc885 = loc("./scratch/dave.mlir":884:12)
#loc886 = loc("./scratch/dave.mlir":885:12)
#loc887 = loc("./scratch/dave.mlir":886:12)
#loc888 = loc("./scratch/dave.mlir":887:12)
#loc889 = loc("./scratch/dave.mlir":888:12)
#loc890 = loc("./scratch/dave.mlir":889:12)
#loc891 = loc("./scratch/dave.mlir":890:12)
#loc892 = loc("./scratch/dave.mlir":891:12)
#loc893 = loc("./scratch/dave.mlir":892:12)
#loc894 = loc("./scratch/dave.mlir":893:12)
#loc895 = loc("./scratch/dave.mlir":894:12)
#loc896 = loc("./scratch/dave.mlir":895:12)
#loc897 = loc("./scratch/dave.mlir":896:12)
#loc898 = loc("./scratch/dave.mlir":897:12)
#loc899 = loc("./scratch/dave.mlir":898:12)
#loc900 = loc("./scratch/dave.mlir":899:12)
#loc901 = loc("./scratch/dave.mlir":900:12)
#loc902 = loc("./scratch/dave.mlir":901:12)
#loc903 = loc("./scratch/dave.mlir":902:12)
#loc904 = loc("./scratch/dave.mlir":903:12)
#loc905 = loc("./scratch/dave.mlir":904:12)
#loc906 = loc("./scratch/dave.mlir":905:12)
#loc907 = loc("./scratch/dave.mlir":906:12)
#loc908 = loc("./scratch/dave.mlir":907:12)
#loc909 = loc("./scratch/dave.mlir":908:12)
#loc910 = loc("./scratch/dave.mlir":909:12)
#loc911 = loc("./scratch/dave.mlir":910:12)
#loc912 = loc("./scratch/dave.mlir":911:12)
#loc913 = loc("./scratch/dave.mlir":912:12)
#loc914 = loc("./scratch/dave.mlir":913:12)
#loc915 = loc("./scratch/dave.mlir":914:12)
#loc916 = loc("./scratch/dave.mlir":915:12)
#loc917 = loc("./scratch/dave.mlir":916:12)
#loc918 = loc("./scratch/dave.mlir":917:12)
#loc919 = loc("./scratch/dave.mlir":918:12)
#loc920 = loc("./scratch/dave.mlir":919:12)
#loc921 = loc("./scratch/dave.mlir":920:12)
#loc922 = loc("./scratch/dave.mlir":921:12)
#loc923 = loc("./scratch/dave.mlir":922:12)
#loc924 = loc("./scratch/dave.mlir":923:12)
#loc925 = loc("./scratch/dave.mlir":924:12)
#loc926 = loc("./scratch/dave.mlir":925:12)
#loc927 = loc("./scratch/dave.mlir":926:12)
#loc928 = loc("./scratch/dave.mlir":927:12)
#loc929 = loc("./scratch/dave.mlir":928:12)
#loc930 = loc("./scratch/dave.mlir":929:12)
#loc931 = loc("./scratch/dave.mlir":930:12)
#loc932 = loc("./scratch/dave.mlir":931:12)
#loc933 = loc("./scratch/dave.mlir":932:12)
#loc934 = loc("./scratch/dave.mlir":933:12)
#loc935 = loc("./scratch/dave.mlir":934:12)
#loc936 = loc("./scratch/dave.mlir":935:12)
#loc937 = loc("./scratch/dave.mlir":936:12)
#loc938 = loc("./scratch/dave.mlir":937:12)
#loc939 = loc("./scratch/dave.mlir":938:12)
#loc940 = loc("./scratch/dave.mlir":939:12)
#loc941 = loc("./scratch/dave.mlir":940:12)
#loc942 = loc("./scratch/dave.mlir":941:12)
#loc943 = loc("./scratch/dave.mlir":942:12)
#loc944 = loc("./scratch/dave.mlir":943:12)
#loc945 = loc("./scratch/dave.mlir":944:12)
#loc946 = loc("./scratch/dave.mlir":945:12)
#loc947 = loc("./scratch/dave.mlir":946:12)
#loc948 = loc("./scratch/dave.mlir":947:12)
#loc949 = loc("./scratch/dave.mlir":948:12)
#loc950 = loc("./scratch/dave.mlir":949:12)
#loc951 = loc("./scratch/dave.mlir":950:12)
#loc952 = loc("./scratch/dave.mlir":951:12)
#loc953 = loc("./scratch/dave.mlir":952:12)
#loc954 = loc("./scratch/dave.mlir":953:12)
#loc955 = loc("./scratch/dave.mlir":954:12)
#loc956 = loc("./scratch/dave.mlir":955:12)
#loc957 = loc("./scratch/dave.mlir":956:12)
#loc958 = loc("./scratch/dave.mlir":957:12)
#loc959 = loc("./scratch/dave.mlir":958:12)
#loc960 = loc("./scratch/dave.mlir":959:12)
#loc961 = loc("./scratch/dave.mlir":960:12)
#loc962 = loc("./scratch/dave.mlir":961:12)
#loc963 = loc("./scratch/dave.mlir":962:12)
#loc964 = loc("./scratch/dave.mlir":963:12)
#loc965 = loc("./scratch/dave.mlir":964:12)
#loc966 = loc("./scratch/dave.mlir":965:12)
#loc967 = loc("./scratch/dave.mlir":966:12)
#loc968 = loc("./scratch/dave.mlir":967:12)
#loc969 = loc("./scratch/dave.mlir":968:12)
#loc970 = loc("./scratch/dave.mlir":969:12)
#loc971 = loc("./scratch/dave.mlir":970:12)
#loc972 = loc("./scratch/dave.mlir":971:12)
#loc973 = loc("./scratch/dave.mlir":972:12)
#loc974 = loc("./scratch/dave.mlir":973:12)
#loc975 = loc("./scratch/dave.mlir":974:12)
#loc976 = loc("./scratch/dave.mlir":975:12)
#loc977 = loc("./scratch/dave.mlir":976:12)
#loc978 = loc("./scratch/dave.mlir":977:12)
#loc979 = loc("./scratch/dave.mlir":978:12)
#loc980 = loc("./scratch/dave.mlir":979:12)
#loc981 = loc("./scratch/dave.mlir":980:12)
#loc982 = loc("./scratch/dave.mlir":981:12)
#loc983 = loc("./scratch/dave.mlir":982:12)
#loc984 = loc("./scratch/dave.mlir":983:12)
#loc985 = loc("./scratch/dave.mlir":984:12)
#loc986 = loc("./scratch/dave.mlir":985:12)
#loc987 = loc("./scratch/dave.mlir":986:12)
#loc988 = loc("./scratch/dave.mlir":987:12)
#loc989 = loc("./scratch/dave.mlir":988:12)
#loc990 = loc("./scratch/dave.mlir":989:12)
#loc991 = loc("./scratch/dave.mlir":990:12)
#loc992 = loc("./scratch/dave.mlir":991:12)
#loc993 = loc("./scratch/dave.mlir":992:12)
#loc994 = loc("./scratch/dave.mlir":993:12)
#loc995 = loc("./scratch/dave.mlir":994:12)
#loc996 = loc("./scratch/dave.mlir":995:12)
#loc997 = loc("./scratch/dave.mlir":996:12)
#loc998 = loc("./scratch/dave.mlir":997:12)
#loc999 = loc("./scratch/dave.mlir":998:12)
#loc1000 = loc("./scratch/dave.mlir":999:12)
#loc1001 = loc("./scratch/dave.mlir":1000:12)
#loc1002 = loc("./scratch/dave.mlir":1001:12)
#loc1003 = loc("./scratch/dave.mlir":1002:12)
#loc1004 = loc("./scratch/dave.mlir":1003:13)
#loc1005 = loc("./scratch/dave.mlir":1004:13)
#loc1006 = loc("./scratch/dave.mlir":1005:13)
#loc1007 = loc("./scratch/dave.mlir":1006:13)
#loc1008 = loc("./scratch/dave.mlir":1007:13)
#loc1009 = loc("./scratch/dave.mlir":1008:13)
#loc1010 = loc("./scratch/dave.mlir":1009:13)
#loc1011 = loc("./scratch/dave.mlir":1010:13)
#loc1012 = loc("./scratch/dave.mlir":1011:13)
#loc1013 = loc("./scratch/dave.mlir":1012:13)
#loc1014 = loc("./scratch/dave.mlir":1013:13)
#loc1015 = loc("./scratch/dave.mlir":1014:13)
#loc1016 = loc("./scratch/dave.mlir":1015:13)
#loc1017 = loc("./scratch/dave.mlir":1016:13)
#loc1018 = loc("./scratch/dave.mlir":1017:13)
#loc1019 = loc("./scratch/dave.mlir":1018:13)
#loc1020 = loc("./scratch/dave.mlir":1019:13)
#loc1021 = loc("./scratch/dave.mlir":1020:13)
#loc1022 = loc("./scratch/dave.mlir":1021:13)
#loc1023 = loc("./scratch/dave.mlir":1022:13)
#loc1024 = loc("./scratch/dave.mlir":1023:13)
#loc1025 = loc("./scratch/dave.mlir":1024:13)
#loc1026 = loc("./scratch/dave.mlir":1025:13)
#loc1027 = loc("./scratch/dave.mlir":1026:13)
#loc1028 = loc("./scratch/dave.mlir":1027:13)
#loc1029 = loc("./scratch/dave.mlir":1028:13)
#loc1030 = loc("./scratch/dave.mlir":1029:13)
#loc1031 = loc("./scratch/dave.mlir":1030:13)
#loc1032 = loc("./scratch/dave.mlir":1031:13)
#loc1033 = loc("./scratch/dave.mlir":1032:13)
#loc1034 = loc("./scratch/dave.mlir":1033:13)
#loc1035 = loc("./scratch/dave.mlir":1034:13)
#loc1036 = loc("./scratch/dave.mlir":1035:13)
#loc1037 = loc("./scratch/dave.mlir":1036:13)
#loc1038 = loc("./scratch/dave.mlir":1037:13)
#loc1039 = loc("./scratch/dave.mlir":1038:13)
#loc1040 = loc("./scratch/dave.mlir":1039:13)
#loc1041 = loc("./scratch/dave.mlir":1040:13)
#loc1042 = loc("./scratch/dave.mlir":1041:13)
#loc1043 = loc("./scratch/dave.mlir":1042:13)
#loc1044 = loc("./scratch/dave.mlir":1043:13)
#loc1045 = loc("./scratch/dave.mlir":1044:13)
#loc1046 = loc("./scratch/dave.mlir":1045:13)
#loc1047 = loc("./scratch/dave.mlir":1046:13)
#loc1048 = loc("./scratch/dave.mlir":1047:13)
#loc1049 = loc("./scratch/dave.mlir":1048:13)
#loc1050 = loc("./scratch/dave.mlir":1049:13)
#loc1051 = loc("./scratch/dave.mlir":1050:13)
#loc1052 = loc("./scratch/dave.mlir":1051:13)
#loc1053 = loc("./scratch/dave.mlir":1052:13)
#loc1054 = loc("./scratch/dave.mlir":1053:13)
#loc1055 = loc("./scratch/dave.mlir":1054:13)
#loc1056 = loc("./scratch/dave.mlir":1055:13)
#loc1057 = loc("./scratch/dave.mlir":1056:13)
#loc1058 = loc("./scratch/dave.mlir":1057:13)
#loc1059 = loc("./scratch/dave.mlir":1058:13)
#loc1060 = loc("./scratch/dave.mlir":1059:13)
#loc1061 = loc("./scratch/dave.mlir":1060:13)
#loc1062 = loc("./scratch/dave.mlir":1061:13)
#loc1063 = loc("./scratch/dave.mlir":1062:13)
#loc1064 = loc("./scratch/dave.mlir":1063:13)
#loc1065 = loc("./scratch/dave.mlir":1064:13)
#loc1066 = loc("./scratch/dave.mlir":1065:13)
#loc1067 = loc("./scratch/dave.mlir":1066:13)
#loc1068 = loc("./scratch/dave.mlir":1067:13)
#loc1069 = loc("./scratch/dave.mlir":1068:13)
#loc1070 = loc("./scratch/dave.mlir":1069:13)
#loc1071 = loc("./scratch/dave.mlir":1070:13)
#loc1072 = loc("./scratch/dave.mlir":1071:13)
#loc1073 = loc("./scratch/dave.mlir":1072:13)
#loc1074 = loc("./scratch/dave.mlir":1073:13)
#loc1075 = loc("./scratch/dave.mlir":1074:13)
#loc1076 = loc("./scratch/dave.mlir":1075:13)
#loc1077 = loc("./scratch/dave.mlir":1076:13)
#loc1078 = loc("./scratch/dave.mlir":1077:13)
#loc1079 = loc("./scratch/dave.mlir":1078:13)
#loc1080 = loc("./scratch/dave.mlir":1079:13)
#loc1081 = loc("./scratch/dave.mlir":1080:13)
#loc1082 = loc("./scratch/dave.mlir":1081:13)
#loc1083 = loc("./scratch/dave.mlir":1082:13)
#loc1084 = loc("./scratch/dave.mlir":1083:13)
#loc1085 = loc("./scratch/dave.mlir":1084:13)
#loc1086 = loc("./scratch/dave.mlir":1085:13)
#loc1087 = loc("./scratch/dave.mlir":1086:13)
#loc1088 = loc("./scratch/dave.mlir":1087:13)
#loc1089 = loc("./scratch/dave.mlir":1088:13)
#loc1090 = loc("./scratch/dave.mlir":1089:13)
#loc1091 = loc("./scratch/dave.mlir":1090:13)
#loc1092 = loc("./scratch/dave.mlir":1091:13)
#loc1093 = loc("./scratch/dave.mlir":1092:13)
#loc1094 = loc("./scratch/dave.mlir":1093:13)
#loc1095 = loc("./scratch/dave.mlir":1094:13)
#loc1096 = loc("./scratch/dave.mlir":1095:13)
#loc1097 = loc("./scratch/dave.mlir":1096:13)
#loc1098 = loc("./scratch/dave.mlir":1097:13)
#loc1099 = loc("./scratch/dave.mlir":1098:13)
#loc1100 = loc("./scratch/dave.mlir":1099:13)
#loc1101 = loc("./scratch/dave.mlir":1100:13)
#loc1102 = loc("./scratch/dave.mlir":1101:13)
#loc1103 = loc("./scratch/dave.mlir":1102:13)
#loc1104 = loc("./scratch/dave.mlir":1103:13)
#loc1105 = loc("./scratch/dave.mlir":1104:13)
#loc1106 = loc("./scratch/dave.mlir":1105:13)
#loc1107 = loc("./scratch/dave.mlir":1106:13)
#loc1108 = loc("./scratch/dave.mlir":1107:13)
#loc1109 = loc("./scratch/dave.mlir":1108:13)
#loc1110 = loc("./scratch/dave.mlir":1109:13)
#loc1111 = loc("./scratch/dave.mlir":1110:13)
#loc1112 = loc("./scratch/dave.mlir":1111:13)
#loc1113 = loc("./scratch/dave.mlir":1112:13)
#loc1114 = loc("./scratch/dave.mlir":1113:13)
#loc1115 = loc("./scratch/dave.mlir":1114:13)
#loc1116 = loc("./scratch/dave.mlir":1115:13)
#loc1117 = loc("./scratch/dave.mlir":1116:13)
#loc1118 = loc("./scratch/dave.mlir":1117:13)
#loc1119 = loc("./scratch/dave.mlir":1118:13)
#loc1120 = loc("./scratch/dave.mlir":1119:13)
#loc1121 = loc("./scratch/dave.mlir":1120:13)
#loc1122 = loc("./scratch/dave.mlir":1121:13)
#loc1123 = loc("./scratch/dave.mlir":1122:13)
#loc1124 = loc("./scratch/dave.mlir":1123:13)
#loc1125 = loc("./scratch/dave.mlir":1124:13)
#loc1126 = loc("./scratch/dave.mlir":1125:13)
#loc1127 = loc("./scratch/dave.mlir":1126:13)
#loc1128 = loc("./scratch/dave.mlir":1127:13)
#loc1129 = loc("./scratch/dave.mlir":1128:13)
#loc1130 = loc("./scratch/dave.mlir":1129:13)
#loc1131 = loc("./scratch/dave.mlir":1130:13)
#loc1132 = loc("./scratch/dave.mlir":1131:13)
#loc1133 = loc("./scratch/dave.mlir":1132:13)
#loc1134 = loc("./scratch/dave.mlir":1133:13)
#loc1135 = loc("./scratch/dave.mlir":1134:13)
#loc1136 = loc("./scratch/dave.mlir":1135:13)
#loc1137 = loc("./scratch/dave.mlir":1136:13)
#loc1138 = loc("./scratch/dave.mlir":1137:13)
#loc1139 = loc("./scratch/dave.mlir":1138:13)
#loc1140 = loc("./scratch/dave.mlir":1139:13)
#loc1141 = loc("./scratch/dave.mlir":1140:13)
#loc1142 = loc("./scratch/dave.mlir":1141:13)
#loc1143 = loc("./scratch/dave.mlir":1142:13)
#loc1144 = loc("./scratch/dave.mlir":1143:13)
#loc1145 = loc("./scratch/dave.mlir":1144:13)
#loc1146 = loc("./scratch/dave.mlir":1145:13)
#loc1147 = loc("./scratch/dave.mlir":1146:13)
#loc1148 = loc("./scratch/dave.mlir":1147:13)
#loc1149 = loc("./scratch/dave.mlir":1148:13)
#loc1150 = loc("./scratch/dave.mlir":1149:13)
#loc1151 = loc("./scratch/dave.mlir":1150:13)
#loc1152 = loc("./scratch/dave.mlir":1151:13)
#loc1153 = loc("./scratch/dave.mlir":1152:13)
#loc1154 = loc("./scratch/dave.mlir":1153:13)
#loc1155 = loc("./scratch/dave.mlir":1154:13)
#loc1156 = loc("./scratch/dave.mlir":1155:13)
#loc1157 = loc("./scratch/dave.mlir":1156:13)
#loc1158 = loc("./scratch/dave.mlir":1157:13)
#loc1159 = loc("./scratch/dave.mlir":1158:13)
#loc1160 = loc("./scratch/dave.mlir":1159:13)
#loc1161 = loc("./scratch/dave.mlir":1160:13)
#loc1162 = loc("./scratch/dave.mlir":1161:13)
#loc1163 = loc("./scratch/dave.mlir":1162:13)
#loc1164 = loc("./scratch/dave.mlir":1163:13)
#loc1165 = loc("./scratch/dave.mlir":1164:13)
#loc1166 = loc("./scratch/dave.mlir":1165:13)
#loc1167 = loc("./scratch/dave.mlir":1166:13)
#loc1168 = loc("./scratch/dave.mlir":1167:13)
#loc1169 = loc("./scratch/dave.mlir":1168:13)
#loc1170 = loc("./scratch/dave.mlir":1169:13)
#loc1171 = loc("./scratch/dave.mlir":1170:13)
#loc1172 = loc("./scratch/dave.mlir":1171:13)
#loc1173 = loc("./scratch/dave.mlir":1172:13)
#loc1174 = loc("./scratch/dave.mlir":1173:13)
#loc1175 = loc("./scratch/dave.mlir":1174:13)
#loc1176 = loc("./scratch/dave.mlir":1175:13)
#loc1177 = loc("./scratch/dave.mlir":1176:13)
#loc1178 = loc("./scratch/dave.mlir":1177:13)
#loc1179 = loc("./scratch/dave.mlir":1178:13)
#loc1180 = loc("./scratch/dave.mlir":1179:13)
#loc1181 = loc("./scratch/dave.mlir":1180:13)
#loc1182 = loc("./scratch/dave.mlir":1181:13)
#loc1183 = loc("./scratch/dave.mlir":1182:13)
#loc1184 = loc("./scratch/dave.mlir":1183:13)
#loc1185 = loc("./scratch/dave.mlir":1184:13)
#loc1186 = loc("./scratch/dave.mlir":1185:13)
#loc1187 = loc("./scratch/dave.mlir":1186:13)
#loc1188 = loc("./scratch/dave.mlir":1187:13)
#loc1189 = loc("./scratch/dave.mlir":1188:13)
#loc1190 = loc("./scratch/dave.mlir":1189:13)
#loc1191 = loc("./scratch/dave.mlir":1190:13)
#loc1192 = loc("./scratch/dave.mlir":1191:13)
#loc1193 = loc("./scratch/dave.mlir":1192:13)
#loc1194 = loc("./scratch/dave.mlir":1193:13)
#loc1195 = loc("./scratch/dave.mlir":1194:13)
#loc1196 = loc("./scratch/dave.mlir":1195:13)
#loc1197 = loc("./scratch/dave.mlir":1196:13)
#loc1198 = loc("./scratch/dave.mlir":1197:13)
#loc1199 = loc("./scratch/dave.mlir":1198:13)
#loc1200 = loc("./scratch/dave.mlir":1199:13)
#loc1201 = loc("./scratch/dave.mlir":1200:13)
#loc1202 = loc("./scratch/dave.mlir":1201:13)
#loc1203 = loc("./scratch/dave.mlir":1202:13)
#loc1204 = loc("./scratch/dave.mlir":1203:13)
#loc1205 = loc("./scratch/dave.mlir":1204:13)
#loc1206 = loc("./scratch/dave.mlir":1205:13)
#loc1207 = loc("./scratch/dave.mlir":1206:13)
#loc1208 = loc("./scratch/dave.mlir":1207:13)
#loc1209 = loc("./scratch/dave.mlir":1208:13)
#loc1210 = loc("./scratch/dave.mlir":1209:13)
#loc1211 = loc("./scratch/dave.mlir":1210:13)
#loc1212 = loc("./scratch/dave.mlir":1211:13)
#loc1213 = loc("./scratch/dave.mlir":1212:13)
#loc1214 = loc("./scratch/dave.mlir":1213:13)
#loc1215 = loc("./scratch/dave.mlir":1214:13)
#loc1216 = loc("./scratch/dave.mlir":1215:13)
#loc1217 = loc("./scratch/dave.mlir":1216:13)
#loc1218 = loc("./scratch/dave.mlir":1217:13)
#loc1219 = loc("./scratch/dave.mlir":1218:13)
#loc1220 = loc("./scratch/dave.mlir":1219:13)
#loc1221 = loc("./scratch/dave.mlir":1220:13)
#loc1222 = loc("./scratch/dave.mlir":1221:13)
#loc1223 = loc("./scratch/dave.mlir":1222:13)
#loc1224 = loc("./scratch/dave.mlir":1223:13)
#loc1225 = loc("./scratch/dave.mlir":1224:13)
#loc1226 = loc("./scratch/dave.mlir":1225:13)
#loc1227 = loc("./scratch/dave.mlir":1226:13)
#loc1228 = loc("./scratch/dave.mlir":1227:13)
#loc1229 = loc("./scratch/dave.mlir":1228:13)
#loc1230 = loc("./scratch/dave.mlir":1229:13)
#loc1231 = loc("./scratch/dave.mlir":1230:13)
#loc1232 = loc("./scratch/dave.mlir":1231:13)
#loc1233 = loc("./scratch/dave.mlir":1232:13)
#loc1234 = loc("./scratch/dave.mlir":1233:13)
#loc1235 = loc("./scratch/dave.mlir":1234:13)
#loc1236 = loc("./scratch/dave.mlir":1235:13)
#loc1237 = loc("./scratch/dave.mlir":1236:13)
#loc1238 = loc("./scratch/dave.mlir":1237:13)
#loc1239 = loc("./scratch/dave.mlir":1238:13)
#loc1240 = loc("./scratch/dave.mlir":1239:13)
#loc1241 = loc("./scratch/dave.mlir":1240:13)
#loc1242 = loc("./scratch/dave.mlir":1241:13)
#loc1243 = loc("./scratch/dave.mlir":1242:13)
#loc1244 = loc("./scratch/dave.mlir":1243:13)
#loc1245 = loc("./scratch/dave.mlir":1244:13)
#loc1246 = loc("./scratch/dave.mlir":1245:13)
#loc1247 = loc("./scratch/dave.mlir":1246:13)
#loc1248 = loc("./scratch/dave.mlir":1247:13)
#loc1249 = loc("./scratch/dave.mlir":1248:13)
#loc1250 = loc("./scratch/dave.mlir":1249:13)
#loc1251 = loc("./scratch/dave.mlir":1250:13)
#loc1252 = loc("./scratch/dave.mlir":1251:13)
#loc1253 = loc("./scratch/dave.mlir":1252:13)
#loc1254 = loc("./scratch/dave.mlir":1253:13)
#loc1255 = loc("./scratch/dave.mlir":1254:13)
#loc1256 = loc("./scratch/dave.mlir":1255:13)
#loc1257 = loc("./scratch/dave.mlir":1256:13)
#loc1258 = loc("./scratch/dave.mlir":1257:13)
#loc1259 = loc("./scratch/dave.mlir":1258:13)
#loc1260 = loc("./scratch/dave.mlir":1259:13)
#loc1261 = loc("./scratch/dave.mlir":1260:13)
#loc1262 = loc("./scratch/dave.mlir":1261:13)
#loc1263 = loc("./scratch/dave.mlir":1262:13)
#loc1264 = loc("./scratch/dave.mlir":1263:13)
#loc1265 = loc("./scratch/dave.mlir":1264:13)
#loc1266 = loc("./scratch/dave.mlir":1265:13)
#loc1267 = loc("./scratch/dave.mlir":1266:13)
#loc1268 = loc("./scratch/dave.mlir":1267:13)
#loc1269 = loc("./scratch/dave.mlir":1268:13)
#loc1270 = loc("./scratch/dave.mlir":1269:13)
#loc1271 = loc("./scratch/dave.mlir":1270:13)
#loc1272 = loc("./scratch/dave.mlir":1271:13)
#loc1273 = loc("./scratch/dave.mlir":1272:13)
#loc1274 = loc("./scratch/dave.mlir":1273:13)
#loc1275 = loc("./scratch/dave.mlir":1274:13)
#loc1276 = loc("./scratch/dave.mlir":1275:13)
#loc1277 = loc("./scratch/dave.mlir":1276:13)
#loc1278 = loc("./scratch/dave.mlir":1277:13)
#loc1279 = loc("./scratch/dave.mlir":1278:13)
#loc1280 = loc("./scratch/dave.mlir":1279:13)
#loc1281 = loc("./scratch/dave.mlir":1280:13)
#loc1282 = loc("./scratch/dave.mlir":1281:13)
#loc1283 = loc("./scratch/dave.mlir":1282:13)
#loc1284 = loc("./scratch/dave.mlir":1283:13)
#loc1285 = loc("./scratch/dave.mlir":1284:13)
#loc1286 = loc("./scratch/dave.mlir":1285:13)
#loc1287 = loc("./scratch/dave.mlir":1286:13)
#loc1288 = loc("./scratch/dave.mlir":1287:13)
#loc1289 = loc("./scratch/dave.mlir":1288:13)
#loc1290 = loc("./scratch/dave.mlir":1289:13)
#loc1291 = loc("./scratch/dave.mlir":1290:13)
#loc1292 = loc("./scratch/dave.mlir":1291:13)
#loc1293 = loc("./scratch/dave.mlir":1292:13)
#loc1294 = loc("./scratch/dave.mlir":1293:13)
#loc1295 = loc("./scratch/dave.mlir":1294:13)
#loc1296 = loc("./scratch/dave.mlir":1295:13)
#loc1297 = loc("./scratch/dave.mlir":1296:13)
#loc1298 = loc("./scratch/dave.mlir":1297:13)
#loc1299 = loc("./scratch/dave.mlir":1298:13)
#loc1300 = loc("./scratch/dave.mlir":1299:13)
#loc1301 = loc("./scratch/dave.mlir":1300:13)
#loc1302 = loc("./scratch/dave.mlir":1301:13)
#loc1303 = loc("./scratch/dave.mlir":1302:13)
#loc1304 = loc("./scratch/dave.mlir":1303:13)
#loc1305 = loc("./scratch/dave.mlir":1304:13)
#loc1306 = loc("./scratch/dave.mlir":1305:13)
#loc1307 = loc("./scratch/dave.mlir":1306:13)
#loc1308 = loc("./scratch/dave.mlir":1307:13)
#loc1309 = loc("./scratch/dave.mlir":1308:13)
#loc1310 = loc("./scratch/dave.mlir":1309:13)
#loc1311 = loc("./scratch/dave.mlir":1310:13)
#loc1312 = loc("./scratch/dave.mlir":1311:13)
#loc1313 = loc("./scratch/dave.mlir":1312:13)
#loc1314 = loc("./scratch/dave.mlir":1313:13)
#loc1315 = loc("./scratch/dave.mlir":1314:13)
#loc1316 = loc("./scratch/dave.mlir":1315:13)
#loc1317 = loc("./scratch/dave.mlir":1316:13)
#loc1318 = loc("./scratch/dave.mlir":1317:13)
#loc1319 = loc("./scratch/dave.mlir":1318:13)
#loc1320 = loc("./scratch/dave.mlir":1319:13)
#loc1321 = loc("./scratch/dave.mlir":1320:13)
#loc1322 = loc("./scratch/dave.mlir":1321:13)
#loc1323 = loc("./scratch/dave.mlir":1322:13)
#loc1324 = loc("./scratch/dave.mlir":1323:13)
#loc1325 = loc("./scratch/dave.mlir":1324:13)
#loc1326 = loc("./scratch/dave.mlir":1325:13)
#loc1327 = loc("./scratch/dave.mlir":1326:13)
#loc1328 = loc("./scratch/dave.mlir":1327:13)
#loc1329 = loc("./scratch/dave.mlir":1328:13)
#loc1330 = loc("./scratch/dave.mlir":1329:13)
#loc1331 = loc("./scratch/dave.mlir":1330:13)
#loc1332 = loc("./scratch/dave.mlir":1331:13)
#loc1333 = loc("./scratch/dave.mlir":1332:13)
#loc1334 = loc("./scratch/dave.mlir":1333:13)
#loc1335 = loc("./scratch/dave.mlir":1334:13)
#loc1336 = loc("./scratch/dave.mlir":1335:13)
#loc1337 = loc("./scratch/dave.mlir":1336:13)
#loc1338 = loc("./scratch/dave.mlir":1337:13)
#loc1339 = loc("./scratch/dave.mlir":1338:13)
#loc1340 = loc("./scratch/dave.mlir":1339:13)
#loc1341 = loc("./scratch/dave.mlir":1340:13)
#loc1342 = loc("./scratch/dave.mlir":1341:13)
#loc1343 = loc("./scratch/dave.mlir":1342:13)
#loc1344 = loc("./scratch/dave.mlir":1343:13)
#loc1345 = loc("./scratch/dave.mlir":1344:13)
#loc1346 = loc("./scratch/dave.mlir":1345:13)
#loc1347 = loc("./scratch/dave.mlir":1346:13)
#loc1348 = loc("./scratch/dave.mlir":1347:13)
#loc1349 = loc("./scratch/dave.mlir":1348:13)
#loc1350 = loc("./scratch/dave.mlir":1349:13)
#loc1351 = loc("./scratch/dave.mlir":1350:13)
#loc1352 = loc("./scratch/dave.mlir":1351:13)
#loc1353 = loc("./scratch/dave.mlir":1352:13)
#loc1354 = loc("./scratch/dave.mlir":1353:13)
#loc1355 = loc("./scratch/dave.mlir":1354:13)
#loc1356 = loc("./scratch/dave.mlir":1355:13)
#loc1357 = loc("./scratch/dave.mlir":1356:13)
#loc1358 = loc("./scratch/dave.mlir":1357:13)
#loc1359 = loc("./scratch/dave.mlir":1358:13)
#loc1360 = loc("./scratch/dave.mlir":1359:13)
#loc1361 = loc("./scratch/dave.mlir":1360:13)
#loc1362 = loc("./scratch/dave.mlir":1361:13)
#loc1363 = loc("./scratch/dave.mlir":1362:13)
#loc1364 = loc("./scratch/dave.mlir":1363:13)
#loc1365 = loc("./scratch/dave.mlir":1364:13)
#loc1366 = loc("./scratch/dave.mlir":1365:13)
#loc1367 = loc("./scratch/dave.mlir":1366:13)
#loc1368 = loc("./scratch/dave.mlir":1367:13)
#loc1369 = loc("./scratch/dave.mlir":1368:13)
#loc1370 = loc("./scratch/dave.mlir":1369:13)
#loc1371 = loc("./scratch/dave.mlir":1370:13)
#loc1372 = loc("./scratch/dave.mlir":1371:13)
#loc1373 = loc("./scratch/dave.mlir":1372:13)
#loc1374 = loc("./scratch/dave.mlir":1373:13)
#loc1375 = loc("./scratch/dave.mlir":1374:13)
#loc1376 = loc("./scratch/dave.mlir":1375:13)
#loc1377 = loc("./scratch/dave.mlir":1376:13)
#loc1378 = loc("./scratch/dave.mlir":1377:13)
#loc1379 = loc("./scratch/dave.mlir":1378:13)
#loc1380 = loc("./scratch/dave.mlir":1379:13)
#loc1381 = loc("./scratch/dave.mlir":1380:13)
#loc1382 = loc("./scratch/dave.mlir":1381:13)
#loc1383 = loc("./scratch/dave.mlir":1382:13)
#loc1384 = loc("./scratch/dave.mlir":1383:13)
#loc1385 = loc("./scratch/dave.mlir":1384:13)
#loc1386 = loc("./scratch/dave.mlir":1385:13)
#loc1387 = loc("./scratch/dave.mlir":1386:13)
#loc1388 = loc("./scratch/dave.mlir":1387:13)
#loc1389 = loc("./scratch/dave.mlir":1388:13)
#loc1390 = loc("./scratch/dave.mlir":1389:13)
#loc1391 = loc("./scratch/dave.mlir":1390:13)
#loc1392 = loc("./scratch/dave.mlir":1391:13)
#loc1393 = loc("./scratch/dave.mlir":1392:13)
#loc1394 = loc("./scratch/dave.mlir":1393:13)
#loc1395 = loc("./scratch/dave.mlir":1394:13)
#loc1396 = loc("./scratch/dave.mlir":1395:13)
#loc1397 = loc("./scratch/dave.mlir":1396:13)
#loc1398 = loc("./scratch/dave.mlir":1397:13)
#loc1399 = loc("./scratch/dave.mlir":1398:13)
#loc1400 = loc("./scratch/dave.mlir":1399:13)
#loc1401 = loc("./scratch/dave.mlir":1400:13)
#loc1402 = loc("./scratch/dave.mlir":1401:13)
#loc1403 = loc("./scratch/dave.mlir":1402:13)
#loc1404 = loc("./scratch/dave.mlir":1403:13)
#loc1405 = loc("./scratch/dave.mlir":1404:13)
#loc1406 = loc("./scratch/dave.mlir":1405:13)
#loc1407 = loc("./scratch/dave.mlir":1406:13)
#loc1408 = loc("./scratch/dave.mlir":1407:13)
#loc1409 = loc("./scratch/dave.mlir":1408:13)
#loc1410 = loc("./scratch/dave.mlir":1409:13)
#loc1411 = loc("./scratch/dave.mlir":1410:13)
#loc1412 = loc("./scratch/dave.mlir":1411:13)
#loc1413 = loc("./scratch/dave.mlir":1412:13)
#loc1414 = loc("./scratch/dave.mlir":1413:13)
#loc1415 = loc("./scratch/dave.mlir":1414:13)
#loc1416 = loc("./scratch/dave.mlir":1415:13)
#loc1417 = loc("./scratch/dave.mlir":1416:13)
#loc1418 = loc("./scratch/dave.mlir":1417:13)
#loc1419 = loc("./scratch/dave.mlir":1418:13)
#loc1420 = loc("./scratch/dave.mlir":1419:13)
#loc1421 = loc("./scratch/dave.mlir":1420:13)
#loc1422 = loc("./scratch/dave.mlir":1421:13)
#loc1423 = loc("./scratch/dave.mlir":1422:13)
#loc1424 = loc("./scratch/dave.mlir":1423:13)
#loc1425 = loc("./scratch/dave.mlir":1424:13)
#loc1426 = loc("./scratch/dave.mlir":1425:13)
#loc1427 = loc("./scratch/dave.mlir":1426:13)
#loc1428 = loc("./scratch/dave.mlir":1427:13)
#loc1429 = loc("./scratch/dave.mlir":1428:13)
#loc1430 = loc("./scratch/dave.mlir":1429:13)
#loc1431 = loc("./scratch/dave.mlir":1430:13)
#loc1432 = loc("./scratch/dave.mlir":1431:13)
#loc1433 = loc("./scratch/dave.mlir":1432:13)
#loc1434 = loc("./scratch/dave.mlir":1433:13)
#loc1435 = loc("./scratch/dave.mlir":1434:13)
#loc1436 = loc("./scratch/dave.mlir":1435:13)
#loc1437 = loc("./scratch/dave.mlir":1436:13)
#loc1438 = loc("./scratch/dave.mlir":1437:13)
#loc1439 = loc("./scratch/dave.mlir":1438:13)
#loc1440 = loc("./scratch/dave.mlir":1439:13)
#loc1441 = loc("./scratch/dave.mlir":1440:13)
#loc1442 = loc("./scratch/dave.mlir":1441:13)
#loc1443 = loc("./scratch/dave.mlir":1442:13)
#loc1444 = loc("./scratch/dave.mlir":1443:13)
#loc1445 = loc("./scratch/dave.mlir":1444:13)
#loc1446 = loc("./scratch/dave.mlir":1445:13)
#loc1447 = loc("./scratch/dave.mlir":1446:13)
#loc1448 = loc("./scratch/dave.mlir":1447:13)
#loc1449 = loc("./scratch/dave.mlir":1448:13)
#loc1450 = loc("./scratch/dave.mlir":1449:13)
#loc1451 = loc("./scratch/dave.mlir":1450:13)
#loc1452 = loc("./scratch/dave.mlir":1451:13)
#loc1453 = loc("./scratch/dave.mlir":1452:13)
#loc1454 = loc("./scratch/dave.mlir":1453:13)
#loc1455 = loc("./scratch/dave.mlir":1454:13)
#loc1456 = loc("./scratch/dave.mlir":1455:13)
#loc1457 = loc("./scratch/dave.mlir":1456:13)
#loc1458 = loc("./scratch/dave.mlir":1457:13)
#loc1459 = loc("./scratch/dave.mlir":1458:13)
#loc1460 = loc("./scratch/dave.mlir":1459:13)
#loc1461 = loc("./scratch/dave.mlir":1460:13)
#loc1462 = loc("./scratch/dave.mlir":1461:13)
#loc1463 = loc("./scratch/dave.mlir":1462:13)
#loc1464 = loc("./scratch/dave.mlir":1463:13)
#loc1465 = loc("./scratch/dave.mlir":1464:13)
#loc1466 = loc("./scratch/dave.mlir":1465:13)
#loc1467 = loc("./scratch/dave.mlir":1466:13)
#loc1468 = loc("./scratch/dave.mlir":1467:13)
#loc1469 = loc("./scratch/dave.mlir":1468:13)
#loc1470 = loc("./scratch/dave.mlir":1469:13)
#loc1471 = loc("./scratch/dave.mlir":1470:13)
#loc1472 = loc("./scratch/dave.mlir":1471:13)
#loc1473 = loc("./scratch/dave.mlir":1472:13)
#loc1474 = loc("./scratch/dave.mlir":1473:13)
#loc1475 = loc("./scratch/dave.mlir":1474:13)
#loc1476 = loc("./scratch/dave.mlir":1475:13)
#loc1477 = loc("./scratch/dave.mlir":1476:13)
#loc1478 = loc("./scratch/dave.mlir":1477:13)
#loc1479 = loc("./scratch/dave.mlir":1478:13)
#loc1480 = loc("./scratch/dave.mlir":1479:13)
#loc1481 = loc("./scratch/dave.mlir":1480:13)
#loc1482 = loc("./scratch/dave.mlir":1481:13)
#loc1483 = loc("./scratch/dave.mlir":1482:13)
#loc1484 = loc("./scratch/dave.mlir":1483:13)
#loc1485 = loc("./scratch/dave.mlir":1484:13)
#loc1486 = loc("./scratch/dave.mlir":1485:13)
#loc1487 = loc("./scratch/dave.mlir":1486:13)
#loc1488 = loc("./scratch/dave.mlir":1487:13)
#loc1489 = loc("./scratch/dave.mlir":1488:13)
#loc1490 = loc("./scratch/dave.mlir":1489:13)
#loc1491 = loc("./scratch/dave.mlir":1490:13)
#loc1492 = loc("./scratch/dave.mlir":1491:13)
#loc1493 = loc("./scratch/dave.mlir":1492:13)
#loc1494 = loc("./scratch/dave.mlir":1493:13)
#loc1495 = loc("./scratch/dave.mlir":1494:13)
#loc1496 = loc("./scratch/dave.mlir":1495:13)
#loc1497 = loc("./scratch/dave.mlir":1496:13)
#loc1498 = loc("./scratch/dave.mlir":1497:13)
#loc1499 = loc("./scratch/dave.mlir":1498:13)
#loc1500 = loc("./scratch/dave.mlir":1499:13)
#loc1501 = loc("./scratch/dave.mlir":1500:13)
#loc1502 = loc("./scratch/dave.mlir":1501:13)
#loc1503 = loc("./scratch/dave.mlir":1502:13)
#loc1504 = loc("./scratch/dave.mlir":1503:13)
#loc1505 = loc("./scratch/dave.mlir":1504:13)
#loc1506 = loc("./scratch/dave.mlir":1505:13)
#loc1507 = loc("./scratch/dave.mlir":1506:13)
#loc1508 = loc("./scratch/dave.mlir":1507:13)
#loc1509 = loc("./scratch/dave.mlir":1508:13)
#loc1510 = loc("./scratch/dave.mlir":1509:13)
#loc1511 = loc("./scratch/dave.mlir":1510:13)
#loc1512 = loc("./scratch/dave.mlir":1511:13)
#loc1513 = loc("./scratch/dave.mlir":1512:13)
#loc1514 = loc("./scratch/dave.mlir":1513:13)
#loc1515 = loc("./scratch/dave.mlir":1514:13)
#loc1516 = loc("./scratch/dave.mlir":1515:13)
#loc1517 = loc("./scratch/dave.mlir":1516:13)
#loc1518 = loc("./scratch/dave.mlir":1517:13)
#loc1519 = loc("./scratch/dave.mlir":1518:13)
#loc1520 = loc("./scratch/dave.mlir":1519:13)
#loc1521 = loc("./scratch/dave.mlir":1520:13)
#loc1522 = loc("./scratch/dave.mlir":1521:13)
#loc1523 = loc("./scratch/dave.mlir":1522:13)
#loc1524 = loc("./scratch/dave.mlir":1523:13)
#loc1525 = loc("./scratch/dave.mlir":1524:13)
#loc1526 = loc("./scratch/dave.mlir":1525:13)
#loc1527 = loc("./scratch/dave.mlir":1526:13)
#loc1528 = loc("./scratch/dave.mlir":1527:13)
#loc1529 = loc("./scratch/dave.mlir":1528:13)
#loc1530 = loc("./scratch/dave.mlir":1529:13)
#loc1531 = loc("./scratch/dave.mlir":1530:13)
#loc1532 = loc("./scratch/dave.mlir":1531:13)
#loc1533 = loc("./scratch/dave.mlir":1532:13)
#loc1534 = loc("./scratch/dave.mlir":1533:13)
#loc1535 = loc("./scratch/dave.mlir":1534:13)
#loc1536 = loc("./scratch/dave.mlir":1535:13)
#loc1537 = loc("./scratch/dave.mlir":1536:13)
#loc1538 = loc("./scratch/dave.mlir":1537:13)
#loc1539 = loc("./scratch/dave.mlir":1538:13)
#loc1540 = loc("./scratch/dave.mlir":1539:13)
#loc1541 = loc("./scratch/dave.mlir":1540:13)
#loc1542 = loc("./scratch/dave.mlir":1541:13)
#loc1543 = loc("./scratch/dave.mlir":1542:13)
#loc1544 = loc("./scratch/dave.mlir":1543:13)
#loc1545 = loc("./scratch/dave.mlir":1544:13)
#loc1546 = loc("./scratch/dave.mlir":1545:13)
#loc1547 = loc("./scratch/dave.mlir":1546:13)
#loc1548 = loc("./scratch/dave.mlir":1547:13)
#loc1549 = loc("./scratch/dave.mlir":1548:13)
#loc1550 = loc("./scratch/dave.mlir":1549:13)
#loc1551 = loc("./scratch/dave.mlir":1550:13)
#loc1552 = loc("./scratch/dave.mlir":1551:13)
#loc1553 = loc("./scratch/dave.mlir":1552:13)
#loc1554 = loc("./scratch/dave.mlir":1553:13)
#loc1555 = loc("./scratch/dave.mlir":1554:13)
#loc1556 = loc("./scratch/dave.mlir":1555:13)
#loc1557 = loc("./scratch/dave.mlir":1556:13)
#loc1558 = loc("./scratch/dave.mlir":1557:13)
#loc1559 = loc("./scratch/dave.mlir":1558:13)
#loc1560 = loc("./scratch/dave.mlir":1559:13)
#loc1561 = loc("./scratch/dave.mlir":1560:13)
#loc1562 = loc("./scratch/dave.mlir":1561:13)
#loc1563 = loc("./scratch/dave.mlir":1562:13)
#loc1564 = loc("./scratch/dave.mlir":1563:13)
#loc1565 = loc("./scratch/dave.mlir":1564:13)
#loc1566 = loc("./scratch/dave.mlir":1565:13)
#loc1567 = loc("./scratch/dave.mlir":1566:13)
#loc1568 = loc("./scratch/dave.mlir":1567:13)
#loc1569 = loc("./scratch/dave.mlir":1568:13)
#loc1570 = loc("./scratch/dave.mlir":1569:13)
#loc1571 = loc("./scratch/dave.mlir":1570:13)
#loc1572 = loc("./scratch/dave.mlir":1571:13)
#loc1573 = loc("./scratch/dave.mlir":1572:13)
#loc1574 = loc("./scratch/dave.mlir":1573:13)
#loc1575 = loc("./scratch/dave.mlir":1574:13)
#loc1576 = loc("./scratch/dave.mlir":1575:13)
#loc1577 = loc("./scratch/dave.mlir":1576:13)
#loc1578 = loc("./scratch/dave.mlir":1577:13)
#loc1579 = loc("./scratch/dave.mlir":1578:13)
#loc1580 = loc("./scratch/dave.mlir":1579:13)
#loc1581 = loc("./scratch/dave.mlir":1580:13)
#loc1582 = loc("./scratch/dave.mlir":1581:13)
#loc1583 = loc("./scratch/dave.mlir":1582:13)
#loc1584 = loc("./scratch/dave.mlir":1583:13)
#loc1585 = loc("./scratch/dave.mlir":1584:13)
#loc1586 = loc("./scratch/dave.mlir":1585:13)
#loc1587 = loc("./scratch/dave.mlir":1586:13)
#loc1588 = loc("./scratch/dave.mlir":1587:13)
#loc1589 = loc("./scratch/dave.mlir":1588:13)
#loc1590 = loc("./scratch/dave.mlir":1589:13)
#loc1591 = loc("./scratch/dave.mlir":1590:13)
#loc1592 = loc("./scratch/dave.mlir":1591:13)
#loc1593 = loc("./scratch/dave.mlir":1592:13)
#loc1594 = loc("./scratch/dave.mlir":1593:13)
#loc1595 = loc("./scratch/dave.mlir":1594:13)
#loc1596 = loc("./scratch/dave.mlir":1595:13)
#loc1597 = loc("./scratch/dave.mlir":1596:13)
#loc1598 = loc("./scratch/dave.mlir":1597:13)
#loc1599 = loc("./scratch/dave.mlir":1598:13)
#loc1600 = loc("./scratch/dave.mlir":1599:13)
#loc1601 = loc("./scratch/dave.mlir":1600:13)
#loc1602 = loc("./scratch/dave.mlir":1601:13)
#loc1603 = loc("./scratch/dave.mlir":1602:13)
#loc1604 = loc("./scratch/dave.mlir":1603:13)
#loc1605 = loc("./scratch/dave.mlir":1604:13)
#loc1606 = loc("./scratch/dave.mlir":1605:13)
#loc1607 = loc("./scratch/dave.mlir":1606:13)
#loc1608 = loc("./scratch/dave.mlir":1607:13)
#loc1609 = loc("./scratch/dave.mlir":1608:13)
#loc1610 = loc("./scratch/dave.mlir":1609:13)
#loc1611 = loc("./scratch/dave.mlir":1610:13)
#loc1612 = loc("./scratch/dave.mlir":1611:13)
#loc1613 = loc("./scratch/dave.mlir":1612:13)
#loc1614 = loc("./scratch/dave.mlir":1613:13)
#loc1615 = loc("./scratch/dave.mlir":1614:13)
#loc1616 = loc("./scratch/dave.mlir":1615:13)
#loc1617 = loc("./scratch/dave.mlir":1616:13)
#loc1618 = loc("./scratch/dave.mlir":1617:13)
#loc1619 = loc("./scratch/dave.mlir":1618:13)
#loc1620 = loc("./scratch/dave.mlir":1619:13)
#loc1621 = loc("./scratch/dave.mlir":1620:13)
#loc1622 = loc("./scratch/dave.mlir":1621:13)
#loc1623 = loc("./scratch/dave.mlir":1622:13)
#loc1624 = loc("./scratch/dave.mlir":1623:13)
#loc1625 = loc("./scratch/dave.mlir":1624:13)
#loc1626 = loc("./scratch/dave.mlir":1625:13)
#loc1627 = loc("./scratch/dave.mlir":1626:13)
#loc1628 = loc("./scratch/dave.mlir":1627:13)
#loc1629 = loc("./scratch/dave.mlir":1628:13)
#loc1630 = loc("./scratch/dave.mlir":1629:13)
#loc1631 = loc("./scratch/dave.mlir":1630:13)
#loc1632 = loc("./scratch/dave.mlir":1631:13)
#loc1633 = loc("./scratch/dave.mlir":1632:13)
#loc1634 = loc("./scratch/dave.mlir":1633:13)
#loc1635 = loc("./scratch/dave.mlir":1634:13)
#loc1636 = loc("./scratch/dave.mlir":1635:13)
#loc1637 = loc("./scratch/dave.mlir":1636:13)
#loc1638 = loc("./scratch/dave.mlir":1637:13)
#loc1639 = loc("./scratch/dave.mlir":1638:13)
#loc1640 = loc("./scratch/dave.mlir":1639:13)
#loc1641 = loc("./scratch/dave.mlir":1640:13)
#loc1642 = loc("./scratch/dave.mlir":1641:13)
#loc1643 = loc("./scratch/dave.mlir":1642:13)
#loc1644 = loc("./scratch/dave.mlir":1643:13)
#loc1645 = loc("./scratch/dave.mlir":1644:13)
#loc1646 = loc("./scratch/dave.mlir":1645:13)
#loc1647 = loc("./scratch/dave.mlir":1646:13)
#loc1648 = loc("./scratch/dave.mlir":1647:13)
#loc1649 = loc("./scratch/dave.mlir":1648:13)
#loc1650 = loc("./scratch/dave.mlir":1649:13)
#loc1651 = loc("./scratch/dave.mlir":1650:13)
#loc1652 = loc("./scratch/dave.mlir":1651:13)
#loc1653 = loc("./scratch/dave.mlir":1652:13)
#loc1654 = loc("./scratch/dave.mlir":1653:13)
#loc1655 = loc("./scratch/dave.mlir":1654:13)
#loc1656 = loc("./scratch/dave.mlir":1655:13)
#loc1657 = loc("./scratch/dave.mlir":1656:13)
#loc1658 = loc("./scratch/dave.mlir":1657:13)
#loc1659 = loc("./scratch/dave.mlir":1658:13)
#loc1660 = loc("./scratch/dave.mlir":1659:13)
#loc1661 = loc("./scratch/dave.mlir":1660:13)
#loc1662 = loc("./scratch/dave.mlir":1661:13)
#loc1663 = loc("./scratch/dave.mlir":1662:13)
#loc1664 = loc("./scratch/dave.mlir":1663:13)
#loc1665 = loc("./scratch/dave.mlir":1664:13)
#loc1666 = loc("./scratch/dave.mlir":1665:13)
#loc1667 = loc("./scratch/dave.mlir":1666:13)
#loc1668 = loc("./scratch/dave.mlir":1667:13)
#loc1669 = loc("./scratch/dave.mlir":1668:13)
#loc1670 = loc("./scratch/dave.mlir":1669:13)
#loc1671 = loc("./scratch/dave.mlir":1670:13)
#loc1672 = loc("./scratch/dave.mlir":1671:13)
#loc1673 = loc("./scratch/dave.mlir":1672:13)
#loc1674 = loc("./scratch/dave.mlir":1673:13)
#loc1675 = loc("./scratch/dave.mlir":1674:13)
#loc1676 = loc("./scratch/dave.mlir":1675:13)
#loc1677 = loc("./scratch/dave.mlir":1676:13)
#loc1678 = loc("./scratch/dave.mlir":1677:13)
#loc1679 = loc("./scratch/dave.mlir":1678:13)
#loc1680 = loc("./scratch/dave.mlir":1679:13)
#loc1681 = loc("./scratch/dave.mlir":1680:13)
#loc1682 = loc("./scratch/dave.mlir":1681:13)
#loc1683 = loc("./scratch/dave.mlir":1682:13)
#loc1684 = loc("./scratch/dave.mlir":1683:13)
#loc1685 = loc("./scratch/dave.mlir":1684:13)
#loc1686 = loc("./scratch/dave.mlir":1685:13)
#loc1687 = loc("./scratch/dave.mlir":1686:13)
#loc1688 = loc("./scratch/dave.mlir":1687:13)
#loc1689 = loc("./scratch/dave.mlir":1688:13)
#loc1690 = loc("./scratch/dave.mlir":1689:13)
#loc1691 = loc("./scratch/dave.mlir":1690:13)
#loc1692 = loc("./scratch/dave.mlir":1691:13)
#loc1693 = loc("./scratch/dave.mlir":1692:13)
#loc1694 = loc("./scratch/dave.mlir":1693:13)
#loc1695 = loc("./scratch/dave.mlir":1694:13)
#loc1696 = loc("./scratch/dave.mlir":1695:13)
#loc1697 = loc("./scratch/dave.mlir":1696:13)
#loc1698 = loc("./scratch/dave.mlir":1697:13)
#loc1699 = loc("./scratch/dave.mlir":1698:13)
#loc1700 = loc("./scratch/dave.mlir":1699:13)
#loc1701 = loc("./scratch/dave.mlir":1700:13)
#loc1702 = loc("./scratch/dave.mlir":1701:13)
#loc1703 = loc("./scratch/dave.mlir":1702:13)
#loc1704 = loc("./scratch/dave.mlir":1703:13)
#loc1705 = loc("./scratch/dave.mlir":1704:13)
#loc1706 = loc("./scratch/dave.mlir":1705:13)
#loc1707 = loc("./scratch/dave.mlir":1706:13)
#loc1708 = loc("./scratch/dave.mlir":1707:13)
#loc1709 = loc("./scratch/dave.mlir":1708:13)
#loc1710 = loc("./scratch/dave.mlir":1709:13)
#loc1711 = loc("./scratch/dave.mlir":1710:13)
#loc1712 = loc("./scratch/dave.mlir":1711:13)
#loc1713 = loc("./scratch/dave.mlir":1712:13)
#loc1714 = loc("./scratch/dave.mlir":1713:13)
#loc1715 = loc("./scratch/dave.mlir":1714:13)
#loc1716 = loc("./scratch/dave.mlir":1715:13)
#loc1717 = loc("./scratch/dave.mlir":1716:13)
#loc1718 = loc("./scratch/dave.mlir":1717:13)
#loc1719 = loc("./scratch/dave.mlir":1718:13)
#loc1720 = loc("./scratch/dave.mlir":1719:13)
#loc1721 = loc("./scratch/dave.mlir":1720:13)
#loc1722 = loc("./scratch/dave.mlir":1721:13)
#loc1723 = loc("./scratch/dave.mlir":1722:13)
#loc1724 = loc("./scratch/dave.mlir":1723:13)
#loc1725 = loc("./scratch/dave.mlir":1724:13)
#loc1726 = loc("./scratch/dave.mlir":1725:13)
#loc1727 = loc("./scratch/dave.mlir":1726:13)
#loc1728 = loc("./scratch/dave.mlir":1727:13)
#loc1729 = loc("./scratch/dave.mlir":1728:13)
#loc1730 = loc("./scratch/dave.mlir":1729:13)
#loc1731 = loc("./scratch/dave.mlir":1730:13)
#loc1732 = loc("./scratch/dave.mlir":1731:13)
#loc1733 = loc("./scratch/dave.mlir":1732:13)
#loc1734 = loc("./scratch/dave.mlir":1733:13)
#loc1735 = loc("./scratch/dave.mlir":1734:13)
#loc1736 = loc("./scratch/dave.mlir":1735:13)
#loc1737 = loc("./scratch/dave.mlir":1736:13)
#loc1738 = loc("./scratch/dave.mlir":1737:13)
#loc1739 = loc("./scratch/dave.mlir":1738:13)
#loc1740 = loc("./scratch/dave.mlir":1739:13)
#loc1741 = loc("./scratch/dave.mlir":1740:13)
#loc1742 = loc("./scratch/dave.mlir":1741:13)
#loc1743 = loc("./scratch/dave.mlir":1742:13)
#loc1744 = loc("./scratch/dave.mlir":1743:13)
#loc1745 = loc("./scratch/dave.mlir":1744:13)
#loc1746 = loc("./scratch/dave.mlir":1745:13)
#loc1747 = loc("./scratch/dave.mlir":1746:13)
#loc1748 = loc("./scratch/dave.mlir":1747:13)
#loc1749 = loc("./scratch/dave.mlir":1748:13)
#loc1750 = loc("./scratch/dave.mlir":1749:13)
#loc1751 = loc("./scratch/dave.mlir":1750:13)
#loc1752 = loc("./scratch/dave.mlir":1751:13)
#loc1753 = loc("./scratch/dave.mlir":1752:13)
#loc1754 = loc("./scratch/dave.mlir":1753:13)
#loc1755 = loc("./scratch/dave.mlir":1754:13)
#loc1756 = loc("./scratch/dave.mlir":1755:13)
#loc1757 = loc("./scratch/dave.mlir":1756:13)
#loc1758 = loc("./scratch/dave.mlir":1757:13)
#loc1759 = loc("./scratch/dave.mlir":1758:13)
#loc1760 = loc("./scratch/dave.mlir":1759:13)
#loc1761 = loc("./scratch/dave.mlir":1760:13)
#loc1762 = loc("./scratch/dave.mlir":1761:13)
#loc1763 = loc("./scratch/dave.mlir":1762:13)
#loc1764 = loc("./scratch/dave.mlir":1763:13)
#loc1765 = loc("./scratch/dave.mlir":1764:13)
#loc1766 = loc("./scratch/dave.mlir":1765:13)
#loc1767 = loc("./scratch/dave.mlir":1766:13)
#loc1768 = loc("./scratch/dave.mlir":1767:13)
#loc1769 = loc("./scratch/dave.mlir":1768:13)
#loc1770 = loc("./scratch/dave.mlir":1769:13)
#loc1771 = loc("./scratch/dave.mlir":1770:13)
#loc1772 = loc("./scratch/dave.mlir":1771:13)
#loc1773 = loc("./scratch/dave.mlir":1772:13)
#loc1774 = loc("./scratch/dave.mlir":1773:13)
#loc1775 = loc("./scratch/dave.mlir":1774:13)
#loc1776 = loc("./scratch/dave.mlir":1775:13)
#loc1777 = loc("./scratch/dave.mlir":1776:13)
#loc1778 = loc("./scratch/dave.mlir":1777:13)
#loc1779 = loc("./scratch/dave.mlir":1778:13)
#loc1780 = loc("./scratch/dave.mlir":1779:13)
#loc1781 = loc("./scratch/dave.mlir":1780:13)
#loc1782 = loc("./scratch/dave.mlir":1781:13)
#loc1783 = loc("./scratch/dave.mlir":1782:13)
#loc1784 = loc("./scratch/dave.mlir":1783:13)
#loc1785 = loc("./scratch/dave.mlir":1784:13)
#loc1786 = loc("./scratch/dave.mlir":1785:13)
#loc1787 = loc("./scratch/dave.mlir":1786:13)
#loc1788 = loc("./scratch/dave.mlir":1787:13)
#loc1789 = loc("./scratch/dave.mlir":1788:13)
#loc1790 = loc("./scratch/dave.mlir":1789:13)
#loc1791 = loc("./scratch/dave.mlir":1790:13)
#loc1792 = loc("./scratch/dave.mlir":1791:13)
#loc1793 = loc("./scratch/dave.mlir":1792:13)
#loc1794 = loc("./scratch/dave.mlir":1793:13)
#loc1795 = loc("./scratch/dave.mlir":1794:13)
#loc1796 = loc("./scratch/dave.mlir":1795:13)
#loc1797 = loc("./scratch/dave.mlir":1796:13)
#loc1798 = loc("./scratch/dave.mlir":1797:13)
#loc1799 = loc("./scratch/dave.mlir":1798:13)
#loc1800 = loc("./scratch/dave.mlir":1799:13)
#loc1801 = loc("./scratch/dave.mlir":1800:13)
#loc1802 = loc("./scratch/dave.mlir":1801:13)
#loc1803 = loc("./scratch/dave.mlir":1802:13)
#loc1804 = loc("./scratch/dave.mlir":1803:13)
#loc1805 = loc("./scratch/dave.mlir":1804:13)
#loc1806 = loc("./scratch/dave.mlir":1805:13)
#loc1807 = loc("./scratch/dave.mlir":1806:13)
#loc1808 = loc("./scratch/dave.mlir":1807:13)
#loc1809 = loc("./scratch/dave.mlir":1808:13)
#loc1810 = loc("./scratch/dave.mlir":1809:13)
#loc1811 = loc("./scratch/dave.mlir":1810:13)
#loc1812 = loc("./scratch/dave.mlir":1811:13)
#loc1813 = loc("./scratch/dave.mlir":1812:13)
#loc1814 = loc("./scratch/dave.mlir":1813:13)
#loc1815 = loc("./scratch/dave.mlir":1814:13)
#loc1816 = loc("./scratch/dave.mlir":1815:13)
#loc1817 = loc("./scratch/dave.mlir":1816:13)
#loc1818 = loc("./scratch/dave.mlir":1817:13)
#loc1819 = loc("./scratch/dave.mlir":1818:13)
#loc1820 = loc("./scratch/dave.mlir":1819:13)
#loc1821 = loc("./scratch/dave.mlir":1820:13)
#loc1822 = loc("./scratch/dave.mlir":1821:13)
#loc1823 = loc("./scratch/dave.mlir":1822:13)
#loc1824 = loc("./scratch/dave.mlir":1823:13)
#loc1825 = loc("./scratch/dave.mlir":1824:13)
#loc1826 = loc("./scratch/dave.mlir":1825:13)
#loc1827 = loc("./scratch/dave.mlir":1826:13)
#loc1828 = loc("./scratch/dave.mlir":1827:13)
#loc1829 = loc("./scratch/dave.mlir":1828:13)
#loc1830 = loc("./scratch/dave.mlir":1829:13)
#loc1831 = loc("./scratch/dave.mlir":1830:13)
#loc1832 = loc("./scratch/dave.mlir":1831:13)
#loc1833 = loc("./scratch/dave.mlir":1832:13)
#loc1834 = loc("./scratch/dave.mlir":1833:13)
#loc1835 = loc("./scratch/dave.mlir":1834:13)
#loc1836 = loc("./scratch/dave.mlir":1835:13)
#loc1837 = loc("./scratch/dave.mlir":1836:13)
#loc1838 = loc("./scratch/dave.mlir":1837:13)
#loc1839 = loc("./scratch/dave.mlir":1838:13)
#loc1840 = loc("./scratch/dave.mlir":1839:13)
#loc1841 = loc("./scratch/dave.mlir":1840:13)
#loc1842 = loc("./scratch/dave.mlir":1841:13)
#loc1843 = loc("./scratch/dave.mlir":1842:13)
#loc1844 = loc("./scratch/dave.mlir":1843:13)
#loc1845 = loc("./scratch/dave.mlir":1844:13)
#loc1846 = loc("./scratch/dave.mlir":1845:13)
#loc1847 = loc("./scratch/dave.mlir":1846:13)
#loc1848 = loc("./scratch/dave.mlir":1847:13)
#loc1849 = loc("./scratch/dave.mlir":1848:13)
#loc1850 = loc("./scratch/dave.mlir":1849:13)
#loc1851 = loc("./scratch/dave.mlir":1850:13)
#loc1852 = loc("./scratch/dave.mlir":1851:13)
#loc1853 = loc("./scratch/dave.mlir":1852:13)
#loc1854 = loc("./scratch/dave.mlir":1853:13)
#loc1855 = loc("./scratch/dave.mlir":1854:13)
#loc1856 = loc("./scratch/dave.mlir":1855:13)
#loc1857 = loc("./scratch/dave.mlir":1856:13)
#loc1858 = loc("./scratch/dave.mlir":1857:13)
#loc1859 = loc("./scratch/dave.mlir":1858:13)
#loc1860 = loc("./scratch/dave.mlir":1859:13)
#loc1861 = loc("./scratch/dave.mlir":1860:13)
#loc1862 = loc("./scratch/dave.mlir":1861:13)
#loc1863 = loc("./scratch/dave.mlir":1862:13)
#loc1864 = loc("./scratch/dave.mlir":1863:13)
#loc1865 = loc("./scratch/dave.mlir":1864:13)
#loc1866 = loc("./scratch/dave.mlir":1865:13)
#loc1867 = loc("./scratch/dave.mlir":1866:13)
#loc1868 = loc("./scratch/dave.mlir":1867:13)
#loc1869 = loc("./scratch/dave.mlir":1868:13)
#loc1870 = loc("./scratch/dave.mlir":1869:13)
#loc1871 = loc("./scratch/dave.mlir":1870:13)
#loc1872 = loc("./scratch/dave.mlir":1871:13)
#loc1873 = loc("./scratch/dave.mlir":1872:13)
#loc1874 = loc("./scratch/dave.mlir":1873:13)
#loc1875 = loc("./scratch/dave.mlir":1874:13)
#loc1876 = loc("./scratch/dave.mlir":1875:13)
#loc1877 = loc("./scratch/dave.mlir":1876:13)
#loc1878 = loc("./scratch/dave.mlir":1877:13)
#loc1879 = loc("./scratch/dave.mlir":1878:13)
#loc1880 = loc("./scratch/dave.mlir":1879:13)
#loc1881 = loc("./scratch/dave.mlir":1880:13)
#loc1882 = loc("./scratch/dave.mlir":1881:13)
#loc1883 = loc("./scratch/dave.mlir":1882:13)
#loc1884 = loc("./scratch/dave.mlir":1883:13)
#loc1885 = loc("./scratch/dave.mlir":1884:13)
#loc1886 = loc("./scratch/dave.mlir":1885:13)
#loc1887 = loc("./scratch/dave.mlir":1886:13)
#loc1888 = loc("./scratch/dave.mlir":1887:13)
#loc1889 = loc("./scratch/dave.mlir":1888:13)
#loc1890 = loc("./scratch/dave.mlir":1889:13)
#loc1891 = loc("./scratch/dave.mlir":1890:13)
#loc1892 = loc("./scratch/dave.mlir":1891:13)
#loc1893 = loc("./scratch/dave.mlir":1892:13)
#loc1894 = loc("./scratch/dave.mlir":1893:13)
#loc1895 = loc("./scratch/dave.mlir":1894:13)
#loc1896 = loc("./scratch/dave.mlir":1895:13)
#loc1897 = loc("./scratch/dave.mlir":1896:13)
#loc1898 = loc("./scratch/dave.mlir":1897:13)
#loc1899 = loc("./scratch/dave.mlir":1898:13)
#loc1900 = loc("./scratch/dave.mlir":1899:13)
#loc1901 = loc("./scratch/dave.mlir":1900:13)
#loc1902 = loc("./scratch/dave.mlir":1901:13)
#loc1903 = loc("./scratch/dave.mlir":1902:13)
#loc1904 = loc("./scratch/dave.mlir":1903:13)
#loc1905 = loc("./scratch/dave.mlir":1904:13)
#loc1906 = loc("./scratch/dave.mlir":1905:13)
#loc1907 = loc("./scratch/dave.mlir":1906:13)
#loc1908 = loc("./scratch/dave.mlir":1907:13)
#loc1909 = loc("./scratch/dave.mlir":1908:13)
#loc1910 = loc("./scratch/dave.mlir":1909:13)
#loc1911 = loc("./scratch/dave.mlir":1910:13)
#loc1912 = loc("./scratch/dave.mlir":1911:13)
#loc1913 = loc("./scratch/dave.mlir":1912:13)
#loc1914 = loc("./scratch/dave.mlir":1913:13)
#loc1915 = loc("./scratch/dave.mlir":1914:13)
#loc1916 = loc("./scratch/dave.mlir":1915:13)
#loc1917 = loc("./scratch/dave.mlir":1916:13)
#loc1918 = loc("./scratch/dave.mlir":1917:13)
#loc1919 = loc("./scratch/dave.mlir":1918:13)
#loc1920 = loc("./scratch/dave.mlir":1919:13)
#loc1921 = loc("./scratch/dave.mlir":1920:13)
#loc1922 = loc("./scratch/dave.mlir":1921:13)
#loc1923 = loc("./scratch/dave.mlir":1922:13)
#loc1924 = loc("./scratch/dave.mlir":1923:13)
#loc1925 = loc("./scratch/dave.mlir":1924:13)
#loc1926 = loc("./scratch/dave.mlir":1925:13)
#loc1927 = loc("./scratch/dave.mlir":1926:13)
#loc1928 = loc("./scratch/dave.mlir":1927:13)
#loc1929 = loc("./scratch/dave.mlir":1928:13)
#loc1930 = loc("./scratch/dave.mlir":1929:13)
#loc1931 = loc("./scratch/dave.mlir":1930:13)
#loc1932 = loc("./scratch/dave.mlir":1931:13)
#loc1933 = loc("./scratch/dave.mlir":1932:13)
#loc1934 = loc("./scratch/dave.mlir":1933:13)
#loc1935 = loc("./scratch/dave.mlir":1934:13)
#loc1936 = loc("./scratch/dave.mlir":1935:13)
#loc1937 = loc("./scratch/dave.mlir":1936:13)
#loc1938 = loc("./scratch/dave.mlir":1937:13)
#loc1939 = loc("./scratch/dave.mlir":1938:13)
#loc1940 = loc("./scratch/dave.mlir":1939:13)
#loc1941 = loc("./scratch/dave.mlir":1940:13)
#loc1942 = loc("./scratch/dave.mlir":1941:13)
#loc1943 = loc("./scratch/dave.mlir":1942:13)
#loc1944 = loc("./scratch/dave.mlir":1943:13)
#loc1945 = loc("./scratch/dave.mlir":1944:13)
#loc1946 = loc("./scratch/dave.mlir":1945:13)
#loc1947 = loc("./scratch/dave.mlir":1946:13)
#loc1948 = loc("./scratch/dave.mlir":1947:13)
#loc1949 = loc("./scratch/dave.mlir":1948:13)
#loc1950 = loc("./scratch/dave.mlir":1949:13)
#loc1951 = loc("./scratch/dave.mlir":1950:13)
#loc1952 = loc("./scratch/dave.mlir":1951:13)
#loc1953 = loc("./scratch/dave.mlir":1952:13)
#loc1954 = loc("./scratch/dave.mlir":1953:13)
#loc1955 = loc("./scratch/dave.mlir":1954:13)
#loc1956 = loc("./scratch/dave.mlir":1955:13)
#loc1957 = loc("./scratch/dave.mlir":1956:13)
#loc1958 = loc("./scratch/dave.mlir":1957:13)
#loc1959 = loc("./scratch/dave.mlir":1958:13)
#loc1960 = loc("./scratch/dave.mlir":1959:13)
#loc1961 = loc("./scratch/dave.mlir":1960:13)
#loc1962 = loc("./scratch/dave.mlir":1961:13)
#loc1963 = loc("./scratch/dave.mlir":1962:13)
#loc1964 = loc("./scratch/dave.mlir":1963:13)
#loc1965 = loc("./scratch/dave.mlir":1964:13)
#loc1966 = loc("./scratch/dave.mlir":1965:13)
#loc1967 = loc("./scratch/dave.mlir":1966:13)
#loc1968 = loc("./scratch/dave.mlir":1967:13)
#loc1969 = loc("./scratch/dave.mlir":1968:13)
#loc1970 = loc("./scratch/dave.mlir":1969:13)
#loc1971 = loc("./scratch/dave.mlir":1970:13)
#loc1972 = loc("./scratch/dave.mlir":1971:13)
#loc1973 = loc("./scratch/dave.mlir":1972:13)
#loc1974 = loc("./scratch/dave.mlir":1973:13)
#loc1975 = loc("./scratch/dave.mlir":1974:13)
#loc1976 = loc("./scratch/dave.mlir":1975:13)
#loc1977 = loc("./scratch/dave.mlir":1976:13)
#loc1978 = loc("./scratch/dave.mlir":1977:13)
#loc1979 = loc("./scratch/dave.mlir":1978:13)
#loc1980 = loc("./scratch/dave.mlir":1979:13)
#loc1981 = loc("./scratch/dave.mlir":1980:13)
#loc1982 = loc("./scratch/dave.mlir":1981:13)
#loc1983 = loc("./scratch/dave.mlir":1982:13)
#loc1984 = loc("./scratch/dave.mlir":1983:13)
#loc1985 = loc("./scratch/dave.mlir":1984:13)
#loc1986 = loc("./scratch/dave.mlir":1985:13)
#loc1987 = loc("./scratch/dave.mlir":1986:13)
#loc1988 = loc("./scratch/dave.mlir":1987:13)
#loc1989 = loc("./scratch/dave.mlir":1988:13)
#loc1990 = loc("./scratch/dave.mlir":1989:13)
#loc1991 = loc("./scratch/dave.mlir":1990:13)
#loc1992 = loc("./scratch/dave.mlir":1991:13)
#loc1993 = loc("./scratch/dave.mlir":1992:13)
#loc1994 = loc("./scratch/dave.mlir":1993:13)
#loc1995 = loc("./scratch/dave.mlir":1994:13)
#loc1996 = loc("./scratch/dave.mlir":1995:13)
#loc1997 = loc("./scratch/dave.mlir":1996:13)
#loc1998 = loc("./scratch/dave.mlir":1997:13)
#loc1999 = loc("./scratch/dave.mlir":1998:13)
#loc2000 = loc("./scratch/dave.mlir":1999:13)
#loc2001 = loc("./scratch/dave.mlir":2000:13)
#loc2002 = loc("./scratch/dave.mlir":2001:13)
#loc2003 = loc("./scratch/dave.mlir":2002:13)
#loc2004 = loc("./scratch/dave.mlir":2003:13)
#loc2005 = loc("./scratch/dave.mlir":2004:13)
#loc2006 = loc("./scratch/dave.mlir":2005:13)
#loc2007 = loc("./scratch/dave.mlir":2006:13)
#loc2008 = loc("./scratch/dave.mlir":2007:13)
#loc2009 = loc("./scratch/dave.mlir":2008:13)
#loc2010 = loc("./scratch/dave.mlir":2009:13)
#loc2011 = loc("./scratch/dave.mlir":2010:13)
#loc2012 = loc("./scratch/dave.mlir":2011:13)
#loc2013 = loc("./scratch/dave.mlir":2012:13)
#loc2014 = loc("./scratch/dave.mlir":2013:13)
#loc2015 = loc("./scratch/dave.mlir":2014:13)
#loc2016 = loc("./scratch/dave.mlir":2015:13)
#loc2017 = loc("./scratch/dave.mlir":2016:13)
#loc2018 = loc("./scratch/dave.mlir":2017:13)
#loc2019 = loc("./scratch/dave.mlir":2018:13)
#loc2020 = loc("./scratch/dave.mlir":2019:13)
#loc2021 = loc("./scratch/dave.mlir":2020:13)
#loc2022 = loc("./scratch/dave.mlir":2021:13)
#loc2023 = loc("./scratch/dave.mlir":2022:13)
#loc2024 = loc("./scratch/dave.mlir":2023:13)
#loc2025 = loc("./scratch/dave.mlir":2024:13)
#loc2026 = loc("./scratch/dave.mlir":2025:13)
#loc2027 = loc("./scratch/dave.mlir":2026:13)
#loc2028 = loc("./scratch/dave.mlir":2027:13)
#loc2029 = loc("./scratch/dave.mlir":2028:13)
#loc2030 = loc("./scratch/dave.mlir":2029:13)
#loc2031 = loc("./scratch/dave.mlir":2030:13)
#loc2032 = loc("./scratch/dave.mlir":2031:13)
#loc2033 = loc("./scratch/dave.mlir":2032:13)
#loc2034 = loc("./scratch/dave.mlir":2033:13)
#loc2035 = loc("./scratch/dave.mlir":2034:13)
#loc2036 = loc("./scratch/dave.mlir":2035:13)
#loc2037 = loc("./scratch/dave.mlir":2036:13)
#loc2038 = loc("./scratch/dave.mlir":2037:13)
#loc2039 = loc("./scratch/dave.mlir":2038:13)
#loc2040 = loc("./scratch/dave.mlir":2039:13)
#loc2041 = loc("./scratch/dave.mlir":2040:13)
#loc2042 = loc("./scratch/dave.mlir":2041:13)
#loc2043 = loc("./scratch/dave.mlir":2042:13)
#loc2044 = loc("./scratch/dave.mlir":2043:13)
#loc2045 = loc("./scratch/dave.mlir":2044:13)
#loc2046 = loc("./scratch/dave.mlir":2045:13)
#loc2047 = loc("./scratch/dave.mlir":2046:13)
#loc2048 = loc("./scratch/dave.mlir":2047:13)
#loc2049 = loc("./scratch/dave.mlir":2048:13)
#loc2050 = loc("./scratch/dave.mlir":2049:13)
#loc2051 = loc("./scratch/dave.mlir":2050:13)
#loc2052 = loc("./scratch/dave.mlir":2051:13)
#loc2053 = loc("./scratch/dave.mlir":2052:13)
#loc2054 = loc("./scratch/dave.mlir":2053:13)
#loc2055 = loc("./scratch/dave.mlir":2054:13)
#loc2056 = loc("./scratch/dave.mlir":2055:13)
#loc2057 = loc("./scratch/dave.mlir":2056:13)
#loc2058 = loc("./scratch/dave.mlir":2057:13)
#loc2059 = loc("./scratch/dave.mlir":2058:13)
#loc2060 = loc("./scratch/dave.mlir":2059:13)
#loc2061 = loc("./scratch/dave.mlir":2060:13)
#loc2062 = loc("./scratch/dave.mlir":2061:13)
#loc2063 = loc("./scratch/dave.mlir":2062:13)
#loc2064 = loc("./scratch/dave.mlir":2063:13)
#loc2065 = loc("./scratch/dave.mlir":2064:13)
#loc2066 = loc("./scratch/dave.mlir":2065:13)
#loc2067 = loc("./scratch/dave.mlir":2066:13)
#loc2068 = loc("./scratch/dave.mlir":2067:13)
#loc2069 = loc("./scratch/dave.mlir":2068:13)
#loc2070 = loc("./scratch/dave.mlir":2069:13)
#loc2071 = loc("./scratch/dave.mlir":2070:13)
#loc2072 = loc("./scratch/dave.mlir":2071:13)
#loc2073 = loc("./scratch/dave.mlir":2072:13)
#loc2074 = loc("./scratch/dave.mlir":2073:13)
#loc2075 = loc("./scratch/dave.mlir":2074:13)
#loc2076 = loc("./scratch/dave.mlir":2075:13)
#loc2077 = loc("./scratch/dave.mlir":2076:13)
#loc2078 = loc("./scratch/dave.mlir":2077:13)
#loc2079 = loc("./scratch/dave.mlir":2078:13)
#loc2080 = loc("./scratch/dave.mlir":2079:13)
#loc2081 = loc("./scratch/dave.mlir":2080:13)
#loc2082 = loc("./scratch/dave.mlir":2081:13)
#loc2083 = loc("./scratch/dave.mlir":2082:13)
#loc2084 = loc("./scratch/dave.mlir":2083:13)
#loc2085 = loc("./scratch/dave.mlir":2084:13)
#loc2086 = loc("./scratch/dave.mlir":2085:13)
#loc2087 = loc("./scratch/dave.mlir":2086:13)
#loc2088 = loc("./scratch/dave.mlir":2087:13)
#loc2089 = loc("./scratch/dave.mlir":2088:13)
#loc2090 = loc("./scratch/dave.mlir":2089:13)
#loc2091 = loc("./scratch/dave.mlir":2090:13)
#loc2092 = loc("./scratch/dave.mlir":2091:13)
#loc2093 = loc("./scratch/dave.mlir":2092:13)
#loc2094 = loc("./scratch/dave.mlir":2093:13)
#loc2095 = loc("./scratch/dave.mlir":2094:13)
#loc2096 = loc("./scratch/dave.mlir":2095:13)
#loc2097 = loc("./scratch/dave.mlir":2096:13)
#loc2098 = loc("./scratch/dave.mlir":2097:13)
#loc2099 = loc("./scratch/dave.mlir":2098:13)
#loc2100 = loc("./scratch/dave.mlir":2099:13)
#loc2101 = loc("./scratch/dave.mlir":2100:13)
#loc2102 = loc("./scratch/dave.mlir":2101:13)
#loc2103 = loc("./scratch/dave.mlir":2102:13)
#loc2104 = loc("./scratch/dave.mlir":2103:13)
#loc2105 = loc("./scratch/dave.mlir":2104:13)
#loc2106 = loc("./scratch/dave.mlir":2105:13)
#loc2107 = loc("./scratch/dave.mlir":2106:13)
#loc2108 = loc("./scratch/dave.mlir":2107:13)
#loc2109 = loc("./scratch/dave.mlir":2108:13)
#loc2110 = loc("./scratch/dave.mlir":2109:13)
#loc2111 = loc("./scratch/dave.mlir":2110:13)
#loc2112 = loc("./scratch/dave.mlir":2111:13)
#loc2113 = loc("./scratch/dave.mlir":2112:13)
#loc2114 = loc("./scratch/dave.mlir":2113:13)
#loc2115 = loc("./scratch/dave.mlir":2114:13)
#loc2116 = loc("./scratch/dave.mlir":2115:13)
#loc2117 = loc("./scratch/dave.mlir":2116:13)
#loc2118 = loc("./scratch/dave.mlir":2117:13)
#loc2119 = loc("./scratch/dave.mlir":2118:13)
#loc2120 = loc("./scratch/dave.mlir":2119:13)
#loc2121 = loc("./scratch/dave.mlir":2120:13)
#loc2122 = loc("./scratch/dave.mlir":2121:13)
#loc2123 = loc("./scratch/dave.mlir":2122:13)
#loc2124 = loc("./scratch/dave.mlir":2123:13)
#loc2125 = loc("./scratch/dave.mlir":2124:13)
#loc2126 = loc("./scratch/dave.mlir":2125:13)
#loc2127 = loc("./scratch/dave.mlir":2126:13)
#loc2128 = loc("./scratch/dave.mlir":2127:13)
#loc2129 = loc("./scratch/dave.mlir":2128:13)
#loc2130 = loc("./scratch/dave.mlir":2129:13)
#loc2131 = loc("./scratch/dave.mlir":2130:13)
#loc2132 = loc("./scratch/dave.mlir":2131:13)
#loc2133 = loc("./scratch/dave.mlir":2132:13)
#loc2134 = loc("./scratch/dave.mlir":2133:13)
#loc2135 = loc("./scratch/dave.mlir":2134:13)
#loc2136 = loc("./scratch/dave.mlir":2135:13)
#loc2137 = loc("./scratch/dave.mlir":2136:13)
#loc2138 = loc("./scratch/dave.mlir":2137:13)
#loc2139 = loc("./scratch/dave.mlir":2138:13)
#loc2140 = loc("./scratch/dave.mlir":2139:13)
#loc2141 = loc("./scratch/dave.mlir":2140:13)
#loc2142 = loc("./scratch/dave.mlir":2141:13)
#loc2143 = loc("./scratch/dave.mlir":2142:13)
#loc2144 = loc("./scratch/dave.mlir":2143:13)
#loc2145 = loc("./scratch/dave.mlir":2144:13)
#loc2146 = loc("./scratch/dave.mlir":2145:13)
#loc2147 = loc("./scratch/dave.mlir":2146:13)
#loc2148 = loc("./scratch/dave.mlir":2147:13)
#loc2149 = loc("./scratch/dave.mlir":2148:13)
#loc2150 = loc("./scratch/dave.mlir":2149:13)
#loc2151 = loc("./scratch/dave.mlir":2150:13)
#loc2152 = loc("./scratch/dave.mlir":2151:13)
#loc2153 = loc("./scratch/dave.mlir":2152:13)
#loc2154 = loc("./scratch/dave.mlir":2153:13)
#loc2155 = loc("./scratch/dave.mlir":2154:13)
#loc2156 = loc("./scratch/dave.mlir":2155:13)
#loc2157 = loc("./scratch/dave.mlir":2156:13)
#loc2158 = loc("./scratch/dave.mlir":2157:13)
#loc2159 = loc("./scratch/dave.mlir":2158:13)
#loc2160 = loc("./scratch/dave.mlir":2159:13)
#loc2161 = loc("./scratch/dave.mlir":2160:13)
#loc2162 = loc("./scratch/dave.mlir":2161:13)
#loc2163 = loc("./scratch/dave.mlir":2162:13)
#loc2164 = loc("./scratch/dave.mlir":2163:13)
#loc2165 = loc("./scratch/dave.mlir":2164:13)
#loc2166 = loc("./scratch/dave.mlir":2165:13)
#loc2167 = loc("./scratch/dave.mlir":2166:13)
#loc2168 = loc("./scratch/dave.mlir":2167:13)
#loc2169 = loc("./scratch/dave.mlir":2168:13)
#loc2170 = loc("./scratch/dave.mlir":2169:13)
#loc2171 = loc("./scratch/dave.mlir":2170:13)
#loc2172 = loc("./scratch/dave.mlir":2171:13)
#loc2173 = loc("./scratch/dave.mlir":2172:13)
#loc2174 = loc("./scratch/dave.mlir":2173:13)
#loc2175 = loc("./scratch/dave.mlir":2174:13)
#loc2176 = loc("./scratch/dave.mlir":2175:13)
#loc2177 = loc("./scratch/dave.mlir":2176:13)
#loc2178 = loc("./scratch/dave.mlir":2177:13)
#loc2179 = loc("./scratch/dave.mlir":2178:13)
#loc2180 = loc("./scratch/dave.mlir":2179:13)
#loc2181 = loc("./scratch/dave.mlir":2180:13)
#loc2182 = loc("./scratch/dave.mlir":2181:13)
#loc2183 = loc("./scratch/dave.mlir":2182:13)
#loc2184 = loc("./scratch/dave.mlir":2183:13)
#loc2185 = loc("./scratch/dave.mlir":2184:13)
#loc2186 = loc("./scratch/dave.mlir":2185:13)
#loc2187 = loc("./scratch/dave.mlir":2186:13)
#loc2188 = loc("./scratch/dave.mlir":2187:13)
#loc2189 = loc("./scratch/dave.mlir":2188:13)
#loc2190 = loc("./scratch/dave.mlir":2189:13)
#loc2191 = loc("./scratch/dave.mlir":2190:13)
#loc2192 = loc("./scratch/dave.mlir":2191:13)
#loc2193 = loc("./scratch/dave.mlir":2192:13)
#loc2194 = loc("./scratch/dave.mlir":2193:13)
#loc2195 = loc("./scratch/dave.mlir":2194:13)
#loc2196 = loc("./scratch/dave.mlir":2195:13)
#loc2197 = loc("./scratch/dave.mlir":2196:13)
#loc2198 = loc("./scratch/dave.mlir":2197:13)
#loc2199 = loc("./scratch/dave.mlir":2198:13)
#loc2200 = loc("./scratch/dave.mlir":2199:13)
#loc2201 = loc("./scratch/dave.mlir":2200:13)
#loc2202 = loc("./scratch/dave.mlir":2201:13)
#loc2203 = loc("./scratch/dave.mlir":2202:13)
#loc2204 = loc("./scratch/dave.mlir":2203:13)
#loc2205 = loc("./scratch/dave.mlir":2204:13)
#loc2206 = loc("./scratch/dave.mlir":2205:13)
#loc2207 = loc("./scratch/dave.mlir":2206:13)
#loc2208 = loc("./scratch/dave.mlir":2207:13)
#loc2209 = loc("./scratch/dave.mlir":2208:13)
#loc2210 = loc("./scratch/dave.mlir":2209:13)
#loc2211 = loc("./scratch/dave.mlir":2210:13)
#loc2212 = loc("./scratch/dave.mlir":2211:13)
#loc2213 = loc("./scratch/dave.mlir":2212:13)
#loc2214 = loc("./scratch/dave.mlir":2213:13)
#loc2215 = loc("./scratch/dave.mlir":2214:13)
#loc2216 = loc("./scratch/dave.mlir":2215:13)
#loc2217 = loc("./scratch/dave.mlir":2216:13)
#loc2218 = loc("./scratch/dave.mlir":2217:13)
#loc2219 = loc("./scratch/dave.mlir":2218:13)
#loc2220 = loc("./scratch/dave.mlir":2219:13)
#loc2221 = loc("./scratch/dave.mlir":2220:13)
#loc2222 = loc("./scratch/dave.mlir":2221:13)
#loc2223 = loc("./scratch/dave.mlir":2222:13)
#loc2224 = loc("./scratch/dave.mlir":2223:13)
#loc2225 = loc("./scratch/dave.mlir":2224:13)
#loc2226 = loc("./scratch/dave.mlir":2225:13)
#loc2227 = loc("./scratch/dave.mlir":2226:13)
#loc2228 = loc("./scratch/dave.mlir":2227:13)
#loc2229 = loc("./scratch/dave.mlir":2228:13)
#loc2230 = loc("./scratch/dave.mlir":2229:13)
#loc2231 = loc("./scratch/dave.mlir":2230:13)
#loc2232 = loc("./scratch/dave.mlir":2231:13)
#loc2233 = loc("./scratch/dave.mlir":2232:13)
#loc2234 = loc("./scratch/dave.mlir":2233:13)
#loc2235 = loc("./scratch/dave.mlir":2234:13)
#loc2236 = loc("./scratch/dave.mlir":2235:13)
#loc2237 = loc("./scratch/dave.mlir":2236:13)
#loc2238 = loc("./scratch/dave.mlir":2237:13)
#loc2239 = loc("./scratch/dave.mlir":2238:13)
#loc2240 = loc("./scratch/dave.mlir":2239:13)
#loc2241 = loc("./scratch/dave.mlir":2240:13)
#loc2242 = loc("./scratch/dave.mlir":2241:13)
#loc2243 = loc("./scratch/dave.mlir":2242:13)
#loc2244 = loc("./scratch/dave.mlir":2243:13)
#loc2245 = loc("./scratch/dave.mlir":2244:13)
#loc2246 = loc("./scratch/dave.mlir":2245:13)
#loc2247 = loc("./scratch/dave.mlir":2246:13)
#loc2248 = loc("./scratch/dave.mlir":2247:13)
#loc2249 = loc("./scratch/dave.mlir":2248:13)
#loc2250 = loc("./scratch/dave.mlir":2249:13)
#loc2251 = loc("./scratch/dave.mlir":2250:13)
#loc2252 = loc("./scratch/dave.mlir":2251:13)
#loc2253 = loc("./scratch/dave.mlir":2252:13)
#loc2254 = loc("./scratch/dave.mlir":2253:13)
#loc2255 = loc("./scratch/dave.mlir":2254:13)
#loc2256 = loc("./scratch/dave.mlir":2255:13)
#loc2257 = loc("./scratch/dave.mlir":2256:13)
#loc2258 = loc("./scratch/dave.mlir":2257:13)
#loc2259 = loc("./scratch/dave.mlir":2258:13)
#loc2260 = loc("./scratch/dave.mlir":2259:13)
#loc2261 = loc("./scratch/dave.mlir":2260:13)
#loc2262 = loc("./scratch/dave.mlir":2261:13)
#loc2263 = loc("./scratch/dave.mlir":2262:13)
#loc2264 = loc("./scratch/dave.mlir":2263:13)
#loc2265 = loc("./scratch/dave.mlir":2264:13)
#loc2266 = loc("./scratch/dave.mlir":2265:13)
#loc2267 = loc("./scratch/dave.mlir":2266:13)
#loc2268 = loc("./scratch/dave.mlir":2267:13)
#loc2269 = loc("./scratch/dave.mlir":2268:13)
#loc2270 = loc("./scratch/dave.mlir":2269:13)
#loc2271 = loc("./scratch/dave.mlir":2270:13)
#loc2272 = loc("./scratch/dave.mlir":2271:13)
#loc2273 = loc("./scratch/dave.mlir":2272:13)
#loc2274 = loc("./scratch/dave.mlir":2273:13)
#loc2275 = loc("./scratch/dave.mlir":2274:13)
#loc2276 = loc("./scratch/dave.mlir":2275:13)
#loc2277 = loc("./scratch/dave.mlir":2276:13)
#loc2278 = loc("./scratch/dave.mlir":2277:13)
#loc2279 = loc("./scratch/dave.mlir":2278:13)
#loc2280 = loc("./scratch/dave.mlir":2279:13)
#loc2281 = loc("./scratch/dave.mlir":2280:13)
#loc2282 = loc("./scratch/dave.mlir":2281:13)
#loc2283 = loc("./scratch/dave.mlir":2282:13)
#loc2284 = loc("./scratch/dave.mlir":2283:13)
#loc2285 = loc("./scratch/dave.mlir":2284:13)
#loc2286 = loc("./scratch/dave.mlir":2285:13)
#loc2287 = loc("./scratch/dave.mlir":2286:13)
#loc2288 = loc("./scratch/dave.mlir":2287:13)
#loc2289 = loc("./scratch/dave.mlir":2288:13)
#loc2290 = loc("./scratch/dave.mlir":2289:13)
#loc2291 = loc("./scratch/dave.mlir":2290:13)
#loc2292 = loc("./scratch/dave.mlir":2291:13)
#loc2293 = loc("./scratch/dave.mlir":2292:13)
#loc2294 = loc("./scratch/dave.mlir":2293:13)
#loc2295 = loc("./scratch/dave.mlir":2294:13)
#loc2296 = loc("./scratch/dave.mlir":2295:13)
#loc2297 = loc("./scratch/dave.mlir":2296:13)
#loc2298 = loc("./scratch/dave.mlir":2297:13)
#loc2299 = loc("./scratch/dave.mlir":2298:13)
#loc2300 = loc("./scratch/dave.mlir":2299:13)
#loc2301 = loc("./scratch/dave.mlir":2300:13)
#loc2302 = loc("./scratch/dave.mlir":2301:13)
#loc2303 = loc("./scratch/dave.mlir":2302:13)
#loc2304 = loc("./scratch/dave.mlir":2303:13)
#loc2305 = loc("./scratch/dave.mlir":2304:13)
#loc2306 = loc("./scratch/dave.mlir":2305:13)
#loc2307 = loc("./scratch/dave.mlir":2306:13)
#loc2308 = loc("./scratch/dave.mlir":2307:13)
#loc2309 = loc("./scratch/dave.mlir":2308:13)
#loc2310 = loc("./scratch/dave.mlir":2309:13)
#loc2311 = loc("./scratch/dave.mlir":2310:13)
#loc2312 = loc("./scratch/dave.mlir":2311:13)
#loc2313 = loc("./scratch/dave.mlir":2312:13)
#loc2314 = loc("./scratch/dave.mlir":2313:13)
#loc2315 = loc("./scratch/dave.mlir":2314:13)
#loc2316 = loc("./scratch/dave.mlir":2315:13)
#loc2317 = loc("./scratch/dave.mlir":2316:13)
#loc2318 = loc("./scratch/dave.mlir":2317:13)
#loc2319 = loc("./scratch/dave.mlir":2318:13)
#loc2320 = loc("./scratch/dave.mlir":2319:13)
#loc2321 = loc("./scratch/dave.mlir":2320:13)
#loc2322 = loc("./scratch/dave.mlir":2321:13)
#loc2323 = loc("./scratch/dave.mlir":2322:13)
#loc2324 = loc("./scratch/dave.mlir":2323:13)
#loc2325 = loc("./scratch/dave.mlir":2324:13)
#loc2326 = loc("./scratch/dave.mlir":2325:13)
#loc2327 = loc("./scratch/dave.mlir":2326:13)
#loc2328 = loc("./scratch/dave.mlir":2327:13)
#loc2329 = loc("./scratch/dave.mlir":2328:13)
#loc2330 = loc("./scratch/dave.mlir":2329:13)
#loc2331 = loc("./scratch/dave.mlir":2330:13)
#loc2332 = loc("./scratch/dave.mlir":2331:13)
#loc2333 = loc("./scratch/dave.mlir":2332:13)
#loc2334 = loc("./scratch/dave.mlir":2333:13)
#loc2335 = loc("./scratch/dave.mlir":2334:13)
#loc2336 = loc("./scratch/dave.mlir":2335:13)
#loc2337 = loc("./scratch/dave.mlir":2336:13)
#loc2338 = loc("./scratch/dave.mlir":2337:13)
#loc2339 = loc("./scratch/dave.mlir":2338:13)
#loc2340 = loc("./scratch/dave.mlir":2339:13)
#loc2341 = loc("./scratch/dave.mlir":2340:13)
#loc2342 = loc("./scratch/dave.mlir":2341:13)
#loc2343 = loc("./scratch/dave.mlir":2342:13)
#loc2344 = loc("./scratch/dave.mlir":2343:13)
#loc2345 = loc("./scratch/dave.mlir":2344:13)
#loc2346 = loc("./scratch/dave.mlir":2345:13)
#loc2347 = loc("./scratch/dave.mlir":2346:13)
#loc2348 = loc("./scratch/dave.mlir":2347:13)
#loc2349 = loc("./scratch/dave.mlir":2348:13)
#loc2350 = loc("./scratch/dave.mlir":2349:13)
#loc2351 = loc("./scratch/dave.mlir":2350:13)
#loc2352 = loc("./scratch/dave.mlir":2351:13)
#loc2353 = loc("./scratch/dave.mlir":2352:13)
#loc2354 = loc("./scratch/dave.mlir":2353:13)
#loc2355 = loc("./scratch/dave.mlir":2354:13)
#loc2356 = loc("./scratch/dave.mlir":2355:13)
#loc2357 = loc("./scratch/dave.mlir":2356:13)
#loc2358 = loc("./scratch/dave.mlir":2357:13)
#loc2359 = loc("./scratch/dave.mlir":2358:13)
#loc2360 = loc("./scratch/dave.mlir":2359:13)
#loc2361 = loc("./scratch/dave.mlir":2360:13)
#loc2362 = loc("./scratch/dave.mlir":2361:13)
#loc2363 = loc("./scratch/dave.mlir":2362:13)
#loc2364 = loc("./scratch/dave.mlir":2363:13)
#loc2365 = loc("./scratch/dave.mlir":2364:13)
#loc2366 = loc("./scratch/dave.mlir":2365:13)
#loc2367 = loc("./scratch/dave.mlir":2366:13)
#loc2368 = loc("./scratch/dave.mlir":2367:13)
#loc2369 = loc("./scratch/dave.mlir":2368:13)
#loc2370 = loc("./scratch/dave.mlir":2369:13)
#loc2371 = loc("./scratch/dave.mlir":2370:13)
#loc2372 = loc("./scratch/dave.mlir":2371:13)
#loc2373 = loc("./scratch/dave.mlir":2372:13)
#loc2374 = loc("./scratch/dave.mlir":2373:13)
#loc2375 = loc("./scratch/dave.mlir":2374:13)
#loc2376 = loc("./scratch/dave.mlir":2375:13)
#loc2377 = loc("./scratch/dave.mlir":2376:13)
#loc2378 = loc("./scratch/dave.mlir":2377:13)
#loc2379 = loc("./scratch/dave.mlir":2378:13)
#loc2380 = loc("./scratch/dave.mlir":2379:13)
#loc2381 = loc("./scratch/dave.mlir":2380:13)
#loc2382 = loc("./scratch/dave.mlir":2381:13)
#loc2383 = loc("./scratch/dave.mlir":2382:13)
#loc2384 = loc("./scratch/dave.mlir":2383:13)
#loc2385 = loc("./scratch/dave.mlir":2384:13)
#loc2386 = loc("./scratch/dave.mlir":2385:13)
#loc2387 = loc("./scratch/dave.mlir":2386:13)
#loc2388 = loc("./scratch/dave.mlir":2387:13)
#loc2389 = loc("./scratch/dave.mlir":2388:13)
#loc2390 = loc("./scratch/dave.mlir":2389:13)
#loc2391 = loc("./scratch/dave.mlir":2390:13)
#loc2392 = loc("./scratch/dave.mlir":2391:13)
#loc2393 = loc("./scratch/dave.mlir":2392:13)
#loc2394 = loc("./scratch/dave.mlir":2393:13)
#loc2395 = loc("./scratch/dave.mlir":2394:13)
#loc2396 = loc("./scratch/dave.mlir":2395:13)
#loc2397 = loc("./scratch/dave.mlir":2396:13)
#loc2398 = loc("./scratch/dave.mlir":2397:13)
#loc2399 = loc("./scratch/dave.mlir":2398:13)
#loc2400 = loc("./scratch/dave.mlir":2399:13)
#loc2401 = loc("./scratch/dave.mlir":2400:13)
#loc2402 = loc("./scratch/dave.mlir":2401:13)
#loc2403 = loc("./scratch/dave.mlir":2402:13)
#loc2404 = loc("./scratch/dave.mlir":2403:13)
#loc2405 = loc("./scratch/dave.mlir":2404:13)
#loc2406 = loc("./scratch/dave.mlir":2405:13)
#loc2407 = loc("./scratch/dave.mlir":2406:13)
#loc2408 = loc("./scratch/dave.mlir":2407:13)
#loc2409 = loc("./scratch/dave.mlir":2408:13)
#loc2410 = loc("./scratch/dave.mlir":2409:13)
#loc2411 = loc("./scratch/dave.mlir":2410:13)
#loc2412 = loc("./scratch/dave.mlir":2411:13)
#loc2413 = loc("./scratch/dave.mlir":2412:13)
#loc2414 = loc("./scratch/dave.mlir":2413:13)
#loc2415 = loc("./scratch/dave.mlir":2414:13)
#loc2416 = loc("./scratch/dave.mlir":2415:13)
#loc2417 = loc("./scratch/dave.mlir":2416:13)
#loc2418 = loc("./scratch/dave.mlir":2417:13)
#loc2419 = loc("./scratch/dave.mlir":2418:13)
#loc2420 = loc("./scratch/dave.mlir":2419:13)
#loc2421 = loc("./scratch/dave.mlir":2420:13)
#loc2422 = loc("./scratch/dave.mlir":2421:13)
#loc2423 = loc("./scratch/dave.mlir":2422:13)
#loc2424 = loc("./scratch/dave.mlir":2423:13)
#loc2425 = loc("./scratch/dave.mlir":2424:13)
#loc2426 = loc("./scratch/dave.mlir":2425:13)
#loc2427 = loc("./scratch/dave.mlir":2426:13)
#loc2428 = loc("./scratch/dave.mlir":2427:13)
#loc2429 = loc("./scratch/dave.mlir":2428:13)
#loc2430 = loc("./scratch/dave.mlir":2429:13)
#loc2431 = loc("./scratch/dave.mlir":2430:13)
#loc2432 = loc("./scratch/dave.mlir":2431:13)
#loc2433 = loc("./scratch/dave.mlir":2432:13)
#loc2434 = loc("./scratch/dave.mlir":2433:13)
#loc2435 = loc("./scratch/dave.mlir":2434:13)
#loc2436 = loc("./scratch/dave.mlir":2435:13)
#loc2437 = loc("./scratch/dave.mlir":2436:13)
#loc2438 = loc("./scratch/dave.mlir":2437:13)
#loc2439 = loc("./scratch/dave.mlir":2438:13)
#loc2440 = loc("./scratch/dave.mlir":2439:13)
#loc2441 = loc("./scratch/dave.mlir":2440:13)
#loc2442 = loc("./scratch/dave.mlir":2441:13)
#loc2443 = loc("./scratch/dave.mlir":2442:13)
#loc2444 = loc("./scratch/dave.mlir":2443:13)
#loc2445 = loc("./scratch/dave.mlir":2444:13)
#loc2446 = loc("./scratch/dave.mlir":2445:13)
#loc2447 = loc("./scratch/dave.mlir":2446:13)
#loc2448 = loc("./scratch/dave.mlir":2447:13)
#loc2449 = loc("./scratch/dave.mlir":2448:13)
#loc2450 = loc("./scratch/dave.mlir":2449:13)
#loc2451 = loc("./scratch/dave.mlir":2450:13)
#loc2452 = loc("./scratch/dave.mlir":2451:13)
#loc2453 = loc("./scratch/dave.mlir":2452:13)
#loc2454 = loc("./scratch/dave.mlir":2453:13)
#loc2455 = loc("./scratch/dave.mlir":2454:13)
#loc2456 = loc("./scratch/dave.mlir":2455:13)
#loc2457 = loc("./scratch/dave.mlir":2456:13)
#loc2458 = loc("./scratch/dave.mlir":2457:13)
#loc2459 = loc("./scratch/dave.mlir":2458:13)
#loc2460 = loc("./scratch/dave.mlir":2459:13)
#loc2461 = loc("./scratch/dave.mlir":2460:13)
#loc2462 = loc("./scratch/dave.mlir":2461:13)
#loc2463 = loc("./scratch/dave.mlir":2462:13)
#loc2464 = loc("./scratch/dave.mlir":2463:13)
#loc2465 = loc("./scratch/dave.mlir":2464:13)
#loc2466 = loc("./scratch/dave.mlir":2465:13)
#loc2467 = loc("./scratch/dave.mlir":2466:13)
#loc2468 = loc("./scratch/dave.mlir":2467:13)
#loc2469 = loc("./scratch/dave.mlir":2468:13)
#loc2470 = loc("./scratch/dave.mlir":2469:13)
#loc2471 = loc("./scratch/dave.mlir":2470:13)
#loc2472 = loc("./scratch/dave.mlir":2471:13)
#loc2473 = loc("./scratch/dave.mlir":2472:13)
#loc2474 = loc("./scratch/dave.mlir":2473:13)
#loc2475 = loc("./scratch/dave.mlir":2474:13)
#loc2476 = loc("./scratch/dave.mlir":2475:13)
#loc2477 = loc("./scratch/dave.mlir":2476:13)
#loc2478 = loc("./scratch/dave.mlir":2477:13)
#loc2479 = loc("./scratch/dave.mlir":2478:13)
#loc2480 = loc("./scratch/dave.mlir":2479:13)
#loc2481 = loc("./scratch/dave.mlir":2480:13)
#loc2482 = loc("./scratch/dave.mlir":2481:13)
#loc2483 = loc("./scratch/dave.mlir":2482:13)
#loc2484 = loc("./scratch/dave.mlir":2483:13)
#loc2485 = loc("./scratch/dave.mlir":2484:13)
#loc2486 = loc("./scratch/dave.mlir":2485:13)
#loc2487 = loc("./scratch/dave.mlir":2486:13)
#loc2488 = loc("./scratch/dave.mlir":2487:13)
#loc2489 = loc("./scratch/dave.mlir":2488:13)
#loc2490 = loc("./scratch/dave.mlir":2489:13)
#loc2491 = loc("./scratch/dave.mlir":2490:13)
#loc2492 = loc("./scratch/dave.mlir":2491:13)
#loc2493 = loc("./scratch/dave.mlir":2492:13)
#loc2494 = loc("./scratch/dave.mlir":2493:13)
#loc2495 = loc("./scratch/dave.mlir":2494:13)
#loc2496 = loc("./scratch/dave.mlir":2495:13)
#loc2497 = loc("./scratch/dave.mlir":2496:13)
#loc2498 = loc("./scratch/dave.mlir":2497:13)
#loc2499 = loc("./scratch/dave.mlir":2498:13)
#loc2500 = loc("./scratch/dave.mlir":2499:13)
#loc2501 = loc("./scratch/dave.mlir":2500:13)
#loc2502 = loc("./scratch/dave.mlir":2501:13)
#loc2503 = loc("./scratch/dave.mlir":2502:13)
#loc2504 = loc("./scratch/dave.mlir":2503:13)
#loc2505 = loc("./scratch/dave.mlir":2504:13)
#loc2506 = loc("./scratch/dave.mlir":2505:13)
#loc2507 = loc("./scratch/dave.mlir":2506:13)
#loc2508 = loc("./scratch/dave.mlir":2507:13)
#loc2509 = loc("./scratch/dave.mlir":2508:13)
#loc2510 = loc("./scratch/dave.mlir":2509:13)
#loc2511 = loc("./scratch/dave.mlir":2510:13)
#loc2512 = loc("./scratch/dave.mlir":2511:13)
#loc2513 = loc("./scratch/dave.mlir":2512:13)
#loc2514 = loc("./scratch/dave.mlir":2513:13)
#loc2515 = loc("./scratch/dave.mlir":2514:13)
#loc2516 = loc("./scratch/dave.mlir":2515:13)
#loc2517 = loc("./scratch/dave.mlir":2516:13)
#loc2518 = loc("./scratch/dave.mlir":2517:13)
#loc2519 = loc("./scratch/dave.mlir":2518:13)
#loc2520 = loc("./scratch/dave.mlir":2519:13)
#loc2521 = loc("./scratch/dave.mlir":2520:13)
#loc2522 = loc("./scratch/dave.mlir":2521:13)
#loc2523 = loc("./scratch/dave.mlir":2522:13)
#loc2524 = loc("./scratch/dave.mlir":2523:13)
#loc2525 = loc("./scratch/dave.mlir":2524:13)
#loc2526 = loc("./scratch/dave.mlir":2525:13)
#loc2527 = loc("./scratch/dave.mlir":2526:13)
#loc2528 = loc("./scratch/dave.mlir":2527:13)
#loc2529 = loc("./scratch/dave.mlir":2528:13)
#loc2530 = loc("./scratch/dave.mlir":2529:13)
#loc2531 = loc("./scratch/dave.mlir":2530:13)
#loc2532 = loc("./scratch/dave.mlir":2531:13)
#loc2533 = loc("./scratch/dave.mlir":2532:13)
#loc2534 = loc("./scratch/dave.mlir":2533:13)
#loc2535 = loc("./scratch/dave.mlir":2534:13)
#loc2536 = loc("./scratch/dave.mlir":2535:13)
#loc2537 = loc("./scratch/dave.mlir":2536:13)
#loc2538 = loc("./scratch/dave.mlir":2537:13)
#loc2539 = loc("./scratch/dave.mlir":2538:13)
#loc2540 = loc("./scratch/dave.mlir":2539:13)
#loc2541 = loc("./scratch/dave.mlir":2540:13)
#loc2542 = loc("./scratch/dave.mlir":2541:13)
#loc2543 = loc("./scratch/dave.mlir":2542:13)
#loc2544 = loc("./scratch/dave.mlir":2543:13)
#loc2545 = loc("./scratch/dave.mlir":2544:13)
#loc2546 = loc("./scratch/dave.mlir":2545:13)
#loc2547 = loc("./scratch/dave.mlir":2546:13)
#loc2548 = loc("./scratch/dave.mlir":2547:13)
#loc2549 = loc("./scratch/dave.mlir":2548:13)
#loc2550 = loc("./scratch/dave.mlir":2549:13)
#loc2551 = loc("./scratch/dave.mlir":2550:13)
#loc2552 = loc("./scratch/dave.mlir":2551:13)
#loc2553 = loc("./scratch/dave.mlir":2552:13)
#loc2554 = loc("./scratch/dave.mlir":2553:13)
#loc2555 = loc("./scratch/dave.mlir":2554:13)
#loc2556 = loc("./scratch/dave.mlir":2555:13)
#loc2557 = loc("./scratch/dave.mlir":2556:13)
#loc2558 = loc("./scratch/dave.mlir":2557:13)
#loc2559 = loc("./scratch/dave.mlir":2558:13)
#loc2560 = loc("./scratch/dave.mlir":2559:13)
#loc2561 = loc("./scratch/dave.mlir":2560:13)
#loc2562 = loc("./scratch/dave.mlir":2561:13)
#loc2563 = loc("./scratch/dave.mlir":2562:13)
#loc2564 = loc("./scratch/dave.mlir":2563:13)
#loc2565 = loc("./scratch/dave.mlir":2564:13)
#loc2566 = loc("./scratch/dave.mlir":2565:13)
#loc2567 = loc("./scratch/dave.mlir":2566:13)
#loc2568 = loc("./scratch/dave.mlir":2567:13)
#loc2569 = loc("./scratch/dave.mlir":2568:13)
#loc2570 = loc("./scratch/dave.mlir":2569:13)
#loc2571 = loc("./scratch/dave.mlir":2570:13)
#loc2572 = loc("./scratch/dave.mlir":2571:13)
#loc2573 = loc("./scratch/dave.mlir":2572:13)
#loc2574 = loc("./scratch/dave.mlir":2573:13)
#loc2575 = loc("./scratch/dave.mlir":2574:13)
#loc2576 = loc("./scratch/dave.mlir":2575:13)
#loc2577 = loc("./scratch/dave.mlir":2576:13)
#loc2578 = loc("./scratch/dave.mlir":2577:13)
#loc2579 = loc("./scratch/dave.mlir":2578:13)
#loc2580 = loc("./scratch/dave.mlir":2579:13)
#loc2581 = loc("./scratch/dave.mlir":2580:13)
#loc2582 = loc("./scratch/dave.mlir":2581:13)
#loc2583 = loc("./scratch/dave.mlir":2582:13)
#loc2584 = loc("./scratch/dave.mlir":2583:13)
#loc2585 = loc("./scratch/dave.mlir":2584:13)
#loc2586 = loc("./scratch/dave.mlir":2585:13)
#loc2587 = loc("./scratch/dave.mlir":2586:13)
#loc2588 = loc("./scratch/dave.mlir":2587:13)
#loc2589 = loc("./scratch/dave.mlir":2588:13)
#loc2590 = loc("./scratch/dave.mlir":2589:13)
#loc2591 = loc("./scratch/dave.mlir":2590:13)
#loc2592 = loc("./scratch/dave.mlir":2591:13)
#loc2593 = loc("./scratch/dave.mlir":2592:13)
#loc2594 = loc("./scratch/dave.mlir":2593:13)
#loc2595 = loc("./scratch/dave.mlir":2594:13)
#loc2596 = loc("./scratch/dave.mlir":2595:13)
#loc2597 = loc("./scratch/dave.mlir":2596:13)
#loc2598 = loc("./scratch/dave.mlir":2597:13)
#loc2599 = loc("./scratch/dave.mlir":2598:13)
#loc2600 = loc("./scratch/dave.mlir":2599:13)
#loc2601 = loc("./scratch/dave.mlir":2600:13)
#loc2602 = loc("./scratch/dave.mlir":2601:13)
#loc2603 = loc("./scratch/dave.mlir":2602:13)
#loc2604 = loc("./scratch/dave.mlir":2603:13)
#loc2605 = loc("./scratch/dave.mlir":2604:13)
#loc2606 = loc("./scratch/dave.mlir":2605:13)
#loc2607 = loc("./scratch/dave.mlir":2606:13)
#loc2608 = loc("./scratch/dave.mlir":2607:13)
#loc2609 = loc("./scratch/dave.mlir":2608:13)
#loc2610 = loc("./scratch/dave.mlir":2609:13)
#loc2611 = loc("./scratch/dave.mlir":2610:13)
#loc2612 = loc("./scratch/dave.mlir":2611:13)
#loc2613 = loc("./scratch/dave.mlir":2612:13)
#loc2614 = loc("./scratch/dave.mlir":2613:13)
#loc2615 = loc("./scratch/dave.mlir":2614:13)
#loc2616 = loc("./scratch/dave.mlir":2615:13)
#loc2617 = loc("./scratch/dave.mlir":2616:13)
#loc2618 = loc("./scratch/dave.mlir":2617:13)
#loc2619 = loc("./scratch/dave.mlir":2618:13)
#loc2620 = loc("./scratch/dave.mlir":2619:13)
#loc2621 = loc("./scratch/dave.mlir":2620:13)
#loc2622 = loc("./scratch/dave.mlir":2621:13)
#loc2623 = loc("./scratch/dave.mlir":2622:13)
#loc2624 = loc("./scratch/dave.mlir":2623:13)
#loc2625 = loc("./scratch/dave.mlir":2624:13)
#loc2626 = loc("./scratch/dave.mlir":2625:13)
#loc2627 = loc("./scratch/dave.mlir":2626:13)
#loc2628 = loc("./scratch/dave.mlir":2627:13)
#loc2629 = loc("./scratch/dave.mlir":2628:13)
#loc2630 = loc("./scratch/dave.mlir":2629:13)
#loc2631 = loc("./scratch/dave.mlir":2630:13)
#loc2632 = loc("./scratch/dave.mlir":2631:13)
#loc2633 = loc("./scratch/dave.mlir":2632:13)
#loc2634 = loc("./scratch/dave.mlir":2633:13)
#loc2635 = loc("./scratch/dave.mlir":2634:13)
#loc2636 = loc("./scratch/dave.mlir":2635:13)
#loc2637 = loc("./scratch/dave.mlir":2636:13)
#loc2638 = loc("./scratch/dave.mlir":2637:13)
#loc2639 = loc("./scratch/dave.mlir":2638:13)
#loc2640 = loc("./scratch/dave.mlir":2639:13)
#loc2641 = loc("./scratch/dave.mlir":2640:13)
#loc2642 = loc("./scratch/dave.mlir":2641:13)
#loc2643 = loc("./scratch/dave.mlir":2642:13)
#loc2644 = loc("./scratch/dave.mlir":2643:13)
#loc2645 = loc("./scratch/dave.mlir":2644:13)
#loc2646 = loc("./scratch/dave.mlir":2645:13)
#loc2647 = loc("./scratch/dave.mlir":2646:13)
#loc2648 = loc("./scratch/dave.mlir":2647:13)
#loc2649 = loc("./scratch/dave.mlir":2648:13)
#loc2650 = loc("./scratch/dave.mlir":2649:13)
#loc2651 = loc("./scratch/dave.mlir":2650:13)
#loc2652 = loc("./scratch/dave.mlir":2651:13)
#loc2653 = loc("./scratch/dave.mlir":2652:13)
#loc2654 = loc("./scratch/dave.mlir":2653:13)
#loc2655 = loc("./scratch/dave.mlir":2654:13)
#loc2656 = loc("./scratch/dave.mlir":2655:13)
#loc2657 = loc("./scratch/dave.mlir":2656:13)
#loc2658 = loc("./scratch/dave.mlir":2657:13)
#loc2659 = loc("./scratch/dave.mlir":2658:13)
#loc2660 = loc("./scratch/dave.mlir":2659:13)
#loc2661 = loc("./scratch/dave.mlir":2660:13)
#loc2662 = loc("./scratch/dave.mlir":2661:13)
#loc2663 = loc("./scratch/dave.mlir":2662:13)
#loc2664 = loc("./scratch/dave.mlir":2663:13)
#loc2665 = loc("./scratch/dave.mlir":2664:13)
#loc2666 = loc("./scratch/dave.mlir":2665:13)
#loc2667 = loc("./scratch/dave.mlir":2666:13)
#loc2668 = loc("./scratch/dave.mlir":2667:13)
#loc2669 = loc("./scratch/dave.mlir":2668:13)
#loc2670 = loc("./scratch/dave.mlir":2669:13)
#loc2671 = loc("./scratch/dave.mlir":2670:13)
#loc2672 = loc("./scratch/dave.mlir":2671:13)
#loc2673 = loc("./scratch/dave.mlir":2672:13)
#loc2674 = loc("./scratch/dave.mlir":2673:13)
#loc2675 = loc("./scratch/dave.mlir":2674:13)
#loc2676 = loc("./scratch/dave.mlir":2675:13)
#loc2677 = loc("./scratch/dave.mlir":2676:13)
#loc2678 = loc("./scratch/dave.mlir":2677:13)
#loc2679 = loc("./scratch/dave.mlir":2678:13)
#loc2680 = loc("./scratch/dave.mlir":2679:13)
#loc2681 = loc("./scratch/dave.mlir":2680:13)
#loc2682 = loc("./scratch/dave.mlir":2681:13)
#loc2683 = loc("./scratch/dave.mlir":2682:13)
#loc2684 = loc("./scratch/dave.mlir":2683:13)
#loc2685 = loc("./scratch/dave.mlir":2684:13)
#loc2686 = loc("./scratch/dave.mlir":2685:13)
#loc2687 = loc("./scratch/dave.mlir":2686:13)
#loc2688 = loc("./scratch/dave.mlir":2687:13)
#loc2689 = loc("./scratch/dave.mlir":2688:13)
#loc2690 = loc("./scratch/dave.mlir":2689:13)
#loc2691 = loc("./scratch/dave.mlir":2690:13)
#loc2692 = loc("./scratch/dave.mlir":2691:13)
#loc2693 = loc("./scratch/dave.mlir":2692:13)
#loc2694 = loc("./scratch/dave.mlir":2693:13)
#loc2695 = loc("./scratch/dave.mlir":2694:13)
#loc2696 = loc("./scratch/dave.mlir":2695:13)
#loc2697 = loc("./scratch/dave.mlir":2696:13)
#loc2698 = loc("./scratch/dave.mlir":2697:13)
#loc2699 = loc("./scratch/dave.mlir":2698:13)
#loc2700 = loc("./scratch/dave.mlir":2699:13)
#loc2701 = loc("./scratch/dave.mlir":2700:13)
#loc2702 = loc("./scratch/dave.mlir":2701:13)
#loc2703 = loc("./scratch/dave.mlir":2702:13)
#loc2704 = loc("./scratch/dave.mlir":2703:13)
#loc2705 = loc("./scratch/dave.mlir":2704:13)
#loc2706 = loc("./scratch/dave.mlir":2705:13)
#loc2707 = loc("./scratch/dave.mlir":2706:13)
#loc2708 = loc("./scratch/dave.mlir":2707:13)
#loc2709 = loc("./scratch/dave.mlir":2708:13)
#loc2710 = loc("./scratch/dave.mlir":2709:13)
#loc2711 = loc("./scratch/dave.mlir":2710:13)
#loc2712 = loc("./scratch/dave.mlir":2711:13)
#loc2713 = loc("./scratch/dave.mlir":2712:13)
#loc2714 = loc("./scratch/dave.mlir":2713:13)
#loc2715 = loc("./scratch/dave.mlir":2714:13)
#loc2716 = loc("./scratch/dave.mlir":2715:13)
#loc2717 = loc("./scratch/dave.mlir":2716:13)
#loc2718 = loc("./scratch/dave.mlir":2717:13)
#loc2719 = loc("./scratch/dave.mlir":2718:13)
#loc2720 = loc("./scratch/dave.mlir":2719:13)
#loc2721 = loc("./scratch/dave.mlir":2720:13)
#loc2722 = loc("./scratch/dave.mlir":2721:13)
#loc2723 = loc("./scratch/dave.mlir":2722:13)
#loc2724 = loc("./scratch/dave.mlir":2723:13)
#loc2725 = loc("./scratch/dave.mlir":2724:13)
#loc2726 = loc("./scratch/dave.mlir":2725:13)
#loc2727 = loc("./scratch/dave.mlir":2726:13)
#loc2728 = loc("./scratch/dave.mlir":2727:13)
#loc2729 = loc("./scratch/dave.mlir":2728:13)
#loc2730 = loc("./scratch/dave.mlir":2729:13)
#loc2731 = loc("./scratch/dave.mlir":2730:13)
#loc2732 = loc("./scratch/dave.mlir":2731:13)
#loc2733 = loc("./scratch/dave.mlir":2732:13)
#loc2734 = loc("./scratch/dave.mlir":2733:13)
#loc2735 = loc("./scratch/dave.mlir":2734:13)
#loc2736 = loc("./scratch/dave.mlir":2735:13)
#loc2737 = loc("./scratch/dave.mlir":2736:13)
#loc2738 = loc("./scratch/dave.mlir":2737:13)
#loc2739 = loc("./scratch/dave.mlir":2738:13)
#loc2740 = loc("./scratch/dave.mlir":2739:13)
#loc2741 = loc("./scratch/dave.mlir":2740:13)
#loc2742 = loc("./scratch/dave.mlir":2741:13)
#loc2743 = loc("./scratch/dave.mlir":2742:13)
#loc2744 = loc("./scratch/dave.mlir":2743:13)
#loc2745 = loc("./scratch/dave.mlir":2744:13)
#loc2746 = loc("./scratch/dave.mlir":2745:13)
#loc2747 = loc("./scratch/dave.mlir":2746:13)
#loc2748 = loc("./scratch/dave.mlir":2747:13)
#loc2749 = loc("./scratch/dave.mlir":2748:13)
#loc2750 = loc("./scratch/dave.mlir":2749:13)
#loc2751 = loc("./scratch/dave.mlir":2750:13)
#loc2752 = loc("./scratch/dave.mlir":2751:13)
#loc2753 = loc("./scratch/dave.mlir":2752:13)
#loc2754 = loc("./scratch/dave.mlir":2753:13)
#loc2755 = loc("./scratch/dave.mlir":2754:13)
#loc2756 = loc("./scratch/dave.mlir":2755:13)
#loc2757 = loc("./scratch/dave.mlir":2756:13)
#loc2758 = loc("./scratch/dave.mlir":2757:13)
#loc2759 = loc("./scratch/dave.mlir":2758:13)
#loc2760 = loc("./scratch/dave.mlir":2759:13)
#loc2761 = loc("./scratch/dave.mlir":2760:13)
#loc2762 = loc("./scratch/dave.mlir":2761:13)
#loc2763 = loc("./scratch/dave.mlir":2762:13)
#loc2764 = loc("./scratch/dave.mlir":2763:13)
#loc2765 = loc("./scratch/dave.mlir":2764:13)
#loc2766 = loc("./scratch/dave.mlir":2765:13)
#loc2767 = loc("./scratch/dave.mlir":2766:13)
#loc2768 = loc("./scratch/dave.mlir":2767:13)
#loc2769 = loc("./scratch/dave.mlir":2768:13)
#loc2770 = loc("./scratch/dave.mlir":2769:13)
#loc2771 = loc("./scratch/dave.mlir":2770:13)
#loc2772 = loc("./scratch/dave.mlir":2771:13)
#loc2773 = loc("./scratch/dave.mlir":2772:13)
#loc2774 = loc("./scratch/dave.mlir":2773:13)
#loc2775 = loc("./scratch/dave.mlir":2774:13)
#loc2776 = loc("./scratch/dave.mlir":2775:13)
#loc2777 = loc("./scratch/dave.mlir":2776:13)
#loc2778 = loc("./scratch/dave.mlir":2777:13)
#loc2779 = loc("./scratch/dave.mlir":2778:13)
#loc2780 = loc("./scratch/dave.mlir":2779:13)
#loc2781 = loc("./scratch/dave.mlir":2780:13)
#loc2782 = loc("./scratch/dave.mlir":2781:13)
#loc2783 = loc("./scratch/dave.mlir":2782:13)
#loc2784 = loc("./scratch/dave.mlir":2783:13)
#loc2785 = loc("./scratch/dave.mlir":2784:13)
#loc2786 = loc("./scratch/dave.mlir":2785:13)
#loc2787 = loc("./scratch/dave.mlir":2786:13)
#loc2788 = loc("./scratch/dave.mlir":2787:13)
#loc2789 = loc("./scratch/dave.mlir":2788:13)
#loc2790 = loc("./scratch/dave.mlir":2789:13)
#loc2791 = loc("./scratch/dave.mlir":2790:13)
#loc2792 = loc("./scratch/dave.mlir":2791:13)
#loc2793 = loc("./scratch/dave.mlir":2792:13)
#loc2794 = loc("./scratch/dave.mlir":2793:13)
#loc2795 = loc("./scratch/dave.mlir":2794:13)
#loc2796 = loc("./scratch/dave.mlir":2795:13)
#loc2797 = loc("./scratch/dave.mlir":2796:13)
#loc2798 = loc("./scratch/dave.mlir":2797:13)
#loc2799 = loc("./scratch/dave.mlir":2798:13)
#loc2800 = loc("./scratch/dave.mlir":2799:13)
#loc2801 = loc("./scratch/dave.mlir":2800:13)
#loc2802 = loc("./scratch/dave.mlir":2801:13)
#loc2803 = loc("./scratch/dave.mlir":2802:13)
#loc2804 = loc("./scratch/dave.mlir":2803:13)
#loc2805 = loc("./scratch/dave.mlir":2804:13)
#loc2806 = loc("./scratch/dave.mlir":2805:13)
#loc2807 = loc("./scratch/dave.mlir":2806:13)
#loc2808 = loc("./scratch/dave.mlir":2807:13)
#loc2809 = loc("./scratch/dave.mlir":2808:13)
#loc2810 = loc("./scratch/dave.mlir":2809:13)
#loc2811 = loc("./scratch/dave.mlir":2810:13)
#loc2812 = loc("./scratch/dave.mlir":2811:13)
#loc2813 = loc("./scratch/dave.mlir":2812:13)
#loc2814 = loc("./scratch/dave.mlir":2813:13)
#loc2815 = loc("./scratch/dave.mlir":2814:13)
#loc2816 = loc("./scratch/dave.mlir":2815:13)
#loc2817 = loc("./scratch/dave.mlir":2816:13)
#loc2818 = loc("./scratch/dave.mlir":2817:13)
#loc2819 = loc("./scratch/dave.mlir":2818:13)
#loc2820 = loc("./scratch/dave.mlir":2819:13)
#loc2821 = loc("./scratch/dave.mlir":2820:13)
#loc2822 = loc("./scratch/dave.mlir":2821:13)
#loc2823 = loc("./scratch/dave.mlir":2822:13)
#loc2824 = loc("./scratch/dave.mlir":2823:13)
#loc2825 = loc("./scratch/dave.mlir":2824:13)
#loc2826 = loc("./scratch/dave.mlir":2825:13)
#loc2827 = loc("./scratch/dave.mlir":2826:13)
#loc2828 = loc("./scratch/dave.mlir":2827:13)
#loc2829 = loc("./scratch/dave.mlir":2828:13)
#loc2830 = loc("./scratch/dave.mlir":2829:13)
#loc2831 = loc("./scratch/dave.mlir":2830:13)
#loc2832 = loc("./scratch/dave.mlir":2831:13)
#loc2833 = loc("./scratch/dave.mlir":2832:13)
#loc2834 = loc("./scratch/dave.mlir":2833:13)
#loc2835 = loc("./scratch/dave.mlir":2834:13)
#loc2836 = loc("./scratch/dave.mlir":2835:13)
#loc2837 = loc("./scratch/dave.mlir":2836:13)
#loc2838 = loc("./scratch/dave.mlir":2837:13)
#loc2839 = loc("./scratch/dave.mlir":2838:13)
#loc2840 = loc("./scratch/dave.mlir":2839:13)
#loc2841 = loc("./scratch/dave.mlir":2840:13)
#loc2842 = loc("./scratch/dave.mlir":2841:13)
#loc2843 = loc("./scratch/dave.mlir":2842:13)
#loc2844 = loc("./scratch/dave.mlir":2843:13)
#loc2845 = loc("./scratch/dave.mlir":2844:13)
#loc2846 = loc("./scratch/dave.mlir":2845:13)
#loc2847 = loc("./scratch/dave.mlir":2846:13)
#loc2848 = loc("./scratch/dave.mlir":2847:13)
#loc2849 = loc("./scratch/dave.mlir":2848:13)
#loc2850 = loc("./scratch/dave.mlir":2849:13)
#loc2851 = loc("./scratch/dave.mlir":2850:13)
#loc2852 = loc("./scratch/dave.mlir":2851:13)
#loc2853 = loc("./scratch/dave.mlir":2852:13)
#loc2854 = loc("./scratch/dave.mlir":2853:13)
#loc2855 = loc("./scratch/dave.mlir":2854:13)
#loc2856 = loc("./scratch/dave.mlir":2855:13)
#loc2857 = loc("./scratch/dave.mlir":2856:13)
#loc2858 = loc("./scratch/dave.mlir":2857:13)
#loc2859 = loc("./scratch/dave.mlir":2858:13)
#loc2860 = loc("./scratch/dave.mlir":2859:13)
#loc2861 = loc("./scratch/dave.mlir":2860:13)
#loc2862 = loc("./scratch/dave.mlir":2861:13)
#loc2863 = loc("./scratch/dave.mlir":2862:13)
#loc2864 = loc("./scratch/dave.mlir":2863:13)
#loc2865 = loc("./scratch/dave.mlir":2864:13)
#loc2866 = loc("./scratch/dave.mlir":2865:13)
#loc2867 = loc("./scratch/dave.mlir":2866:13)
#loc2868 = loc("./scratch/dave.mlir":2867:13)
#loc2869 = loc("./scratch/dave.mlir":2868:13)
#loc2870 = loc("./scratch/dave.mlir":2869:13)
#loc2871 = loc("./scratch/dave.mlir":2870:13)
#loc2872 = loc("./scratch/dave.mlir":2871:13)
#loc2873 = loc("./scratch/dave.mlir":2872:13)
#loc2874 = loc("./scratch/dave.mlir":2873:13)
#loc2875 = loc("./scratch/dave.mlir":2874:13)
#loc2876 = loc("./scratch/dave.mlir":2875:13)
#loc2877 = loc("./scratch/dave.mlir":2876:13)
#loc2878 = loc("./scratch/dave.mlir":2877:13)
#loc2879 = loc("./scratch/dave.mlir":2878:13)
#loc2880 = loc("./scratch/dave.mlir":2879:13)
#loc2881 = loc("./scratch/dave.mlir":2880:13)
#loc2882 = loc("./scratch/dave.mlir":2881:13)
#loc2883 = loc("./scratch/dave.mlir":2882:13)
#loc2884 = loc("./scratch/dave.mlir":2883:13)
#loc2885 = loc("./scratch/dave.mlir":2884:13)
#loc2886 = loc("./scratch/dave.mlir":2885:13)
#loc2887 = loc("./scratch/dave.mlir":2886:13)
#loc2888 = loc("./scratch/dave.mlir":2887:13)
#loc2889 = loc("./scratch/dave.mlir":2888:13)
#loc2890 = loc("./scratch/dave.mlir":2889:13)
#loc2891 = loc("./scratch/dave.mlir":2890:13)
#loc2892 = loc("./scratch/dave.mlir":2891:13)
#loc2893 = loc("./scratch/dave.mlir":2892:13)
#loc2894 = loc("./scratch/dave.mlir":2893:13)
#loc2895 = loc("./scratch/dave.mlir":2894:13)
#loc2896 = loc("./scratch/dave.mlir":2895:13)
#loc2897 = loc("./scratch/dave.mlir":2896:13)
#loc2898 = loc("./scratch/dave.mlir":2897:13)
#loc2899 = loc("./scratch/dave.mlir":2898:13)
#loc2900 = loc("./scratch/dave.mlir":2899:13)
#loc2901 = loc("./scratch/dave.mlir":2900:13)
#loc2902 = loc("./scratch/dave.mlir":2901:13)
#loc2903 = loc("./scratch/dave.mlir":2902:13)
#loc2904 = loc("./scratch/dave.mlir":2903:13)
#loc2905 = loc("./scratch/dave.mlir":2904:13)
#loc2906 = loc("./scratch/dave.mlir":2905:13)
#loc2907 = loc("./scratch/dave.mlir":2906:13)
#loc2908 = loc("./scratch/dave.mlir":2907:13)
#loc2909 = loc("./scratch/dave.mlir":2908:13)
#loc2910 = loc("./scratch/dave.mlir":2909:13)
#loc2911 = loc("./scratch/dave.mlir":2910:13)
#loc2912 = loc("./scratch/dave.mlir":2911:13)
#loc2913 = loc("./scratch/dave.mlir":2912:13)
#loc2914 = loc("./scratch/dave.mlir":2913:13)
#loc2915 = loc("./scratch/dave.mlir":2914:13)
#loc2916 = loc("./scratch/dave.mlir":2915:13)
#loc2917 = loc("./scratch/dave.mlir":2916:13)
#loc2918 = loc("./scratch/dave.mlir":2917:13)
#loc2919 = loc("./scratch/dave.mlir":2918:13)
#loc2920 = loc("./scratch/dave.mlir":2919:13)
#loc2921 = loc("./scratch/dave.mlir":2920:13)
#loc2922 = loc("./scratch/dave.mlir":2921:13)
#loc2923 = loc("./scratch/dave.mlir":2922:13)
#loc2924 = loc("./scratch/dave.mlir":2923:13)
#loc2925 = loc("./scratch/dave.mlir":2924:13)
#loc2926 = loc("./scratch/dave.mlir":2925:13)
#loc2927 = loc("./scratch/dave.mlir":2926:13)
#loc2928 = loc("./scratch/dave.mlir":2927:13)
#loc2929 = loc("./scratch/dave.mlir":2928:13)
#loc2930 = loc("./scratch/dave.mlir":2929:13)
#loc2931 = loc("./scratch/dave.mlir":2930:13)
#loc2932 = loc("./scratch/dave.mlir":2931:13)
#loc2933 = loc("./scratch/dave.mlir":2932:13)
#loc2934 = loc("./scratch/dave.mlir":2933:13)
#loc2935 = loc("./scratch/dave.mlir":2934:13)
#loc2936 = loc("./scratch/dave.mlir":2935:13)
#loc2937 = loc("./scratch/dave.mlir":2936:13)
#loc2938 = loc("./scratch/dave.mlir":2937:13)
#loc2939 = loc("./scratch/dave.mlir":2938:13)
#loc2940 = loc("./scratch/dave.mlir":2939:13)
#loc2941 = loc("./scratch/dave.mlir":2940:13)
#loc2942 = loc("./scratch/dave.mlir":2941:13)
#loc2943 = loc("./scratch/dave.mlir":2942:13)
#loc2944 = loc("./scratch/dave.mlir":2943:13)
#loc2945 = loc("./scratch/dave.mlir":2944:13)
#loc2946 = loc("./scratch/dave.mlir":2945:13)
#loc2947 = loc("./scratch/dave.mlir":2946:13)
#loc2948 = loc("./scratch/dave.mlir":2947:13)
#loc2949 = loc("./scratch/dave.mlir":2948:13)
#loc2950 = loc("./scratch/dave.mlir":2949:13)
#loc2951 = loc("./scratch/dave.mlir":2950:13)
#loc2952 = loc("./scratch/dave.mlir":2951:13)
#loc2953 = loc("./scratch/dave.mlir":2952:13)
#loc2954 = loc("./scratch/dave.mlir":2953:13)
#loc2955 = loc("./scratch/dave.mlir":2954:13)
#loc2956 = loc("./scratch/dave.mlir":2955:13)
#loc2957 = loc("./scratch/dave.mlir":2956:13)
#loc2958 = loc("./scratch/dave.mlir":2957:13)
#loc2959 = loc("./scratch/dave.mlir":2958:13)
#loc2960 = loc("./scratch/dave.mlir":2959:13)
#loc2961 = loc("./scratch/dave.mlir":2960:13)
#loc2962 = loc("./scratch/dave.mlir":2961:13)
#loc2963 = loc("./scratch/dave.mlir":2962:13)
#loc2964 = loc("./scratch/dave.mlir":2963:13)
#loc2965 = loc("./scratch/dave.mlir":2964:13)
#loc2966 = loc("./scratch/dave.mlir":2965:13)
#loc2967 = loc("./scratch/dave.mlir":2966:13)
#loc2968 = loc("./scratch/dave.mlir":2967:13)
#loc2969 = loc("./scratch/dave.mlir":2968:13)
#loc2970 = loc("./scratch/dave.mlir":2969:13)
#loc2971 = loc("./scratch/dave.mlir":2970:13)
#loc2972 = loc("./scratch/dave.mlir":2971:13)
#loc2973 = loc("./scratch/dave.mlir":2972:13)
#loc2974 = loc("./scratch/dave.mlir":2973:13)
#loc2975 = loc("./scratch/dave.mlir":2974:13)
#loc2976 = loc("./scratch/dave.mlir":2975:13)
#loc2977 = loc("./scratch/dave.mlir":2976:13)
#loc2978 = loc("./scratch/dave.mlir":2977:13)
#loc2979 = loc("./scratch/dave.mlir":2978:13)
#loc2980 = loc("./scratch/dave.mlir":2979:13)
#loc2981 = loc("./scratch/dave.mlir":2980:13)
#loc2982 = loc("./scratch/dave.mlir":2981:13)
#loc2983 = loc("./scratch/dave.mlir":2982:13)
#loc2984 = loc("./scratch/dave.mlir":2983:13)
#loc2985 = loc("./scratch/dave.mlir":2984:13)
#loc2986 = loc("./scratch/dave.mlir":2985:13)
#loc2987 = loc("./scratch/dave.mlir":2986:13)
#loc2988 = loc("./scratch/dave.mlir":2987:13)
#loc2989 = loc("./scratch/dave.mlir":2988:13)
#loc2990 = loc("./scratch/dave.mlir":2989:13)
#loc2991 = loc("./scratch/dave.mlir":2990:13)
#loc2992 = loc("./scratch/dave.mlir":2991:13)
#loc2993 = loc("./scratch/dave.mlir":2992:13)
#loc2994 = loc("./scratch/dave.mlir":2993:13)
#loc2995 = loc("./scratch/dave.mlir":2994:13)
#loc2996 = loc("./scratch/dave.mlir":2995:13)
#loc2997 = loc("./scratch/dave.mlir":2996:13)
#loc2998 = loc("./scratch/dave.mlir":2997:13)
#loc2999 = loc("./scratch/dave.mlir":2998:13)
#loc3000 = loc("./scratch/dave.mlir":2999:13)
#loc3001 = loc("./scratch/dave.mlir":3000:13)
#loc3002 = loc("./scratch/dave.mlir":3001:13)
#loc3003 = loc("./scratch/dave.mlir":3002:13)
#loc3004 = loc("./scratch/dave.mlir":3003:13)
#loc3005 = loc("./scratch/dave.mlir":3004:13)
#loc3006 = loc("./scratch/dave.mlir":3005:13)
#loc3007 = loc("./scratch/dave.mlir":3006:13)
#loc3008 = loc("./scratch/dave.mlir":3007:13)
#loc3009 = loc("./scratch/dave.mlir":3008:13)
#loc3010 = loc("./scratch/dave.mlir":3009:13)
#loc3011 = loc("./scratch/dave.mlir":3010:13)
#loc3012 = loc("./scratch/dave.mlir":3011:13)
#loc3013 = loc("./scratch/dave.mlir":3012:13)
#loc3014 = loc("./scratch/dave.mlir":3013:13)
#loc3015 = loc("./scratch/dave.mlir":3014:13)
#loc3016 = loc("./scratch/dave.mlir":3015:13)
#loc3017 = loc("./scratch/dave.mlir":3016:13)
#loc3018 = loc("./scratch/dave.mlir":3017:13)
#loc3019 = loc("./scratch/dave.mlir":3018:13)
#loc3020 = loc("./scratch/dave.mlir":3019:13)
#loc3021 = loc("./scratch/dave.mlir":3020:13)
#loc3022 = loc("./scratch/dave.mlir":3021:13)
#loc3023 = loc("./scratch/dave.mlir":3022:13)
#loc3024 = loc("./scratch/dave.mlir":3023:13)
#loc3025 = loc("./scratch/dave.mlir":3024:13)
#loc3026 = loc("./scratch/dave.mlir":3025:13)
#loc3027 = loc("./scratch/dave.mlir":3026:13)
#loc3028 = loc("./scratch/dave.mlir":3027:13)
#loc3029 = loc("./scratch/dave.mlir":3028:13)
#loc3030 = loc("./scratch/dave.mlir":3029:13)
#loc3031 = loc("./scratch/dave.mlir":3030:13)
#loc3032 = loc("./scratch/dave.mlir":3031:13)
#loc3033 = loc("./scratch/dave.mlir":3032:13)
#loc3034 = loc("./scratch/dave.mlir":3033:13)
#loc3035 = loc("./scratch/dave.mlir":3034:13)
#loc3036 = loc("./scratch/dave.mlir":3035:13)
#loc3037 = loc("./scratch/dave.mlir":3036:13)
#loc3038 = loc("./scratch/dave.mlir":3037:13)
#loc3039 = loc("./scratch/dave.mlir":3038:13)
#loc3040 = loc("./scratch/dave.mlir":3039:13)
#loc3041 = loc("./scratch/dave.mlir":3040:13)
#loc3042 = loc("./scratch/dave.mlir":3041:13)
#loc3043 = loc("./scratch/dave.mlir":3042:13)
#loc3044 = loc("./scratch/dave.mlir":3043:13)
#loc3045 = loc("./scratch/dave.mlir":3044:13)
#loc3046 = loc("./scratch/dave.mlir":3045:13)
#loc3047 = loc("./scratch/dave.mlir":3046:13)
#loc3048 = loc("./scratch/dave.mlir":3047:13)
#loc3049 = loc("./scratch/dave.mlir":3048:13)
#loc3050 = loc("./scratch/dave.mlir":3049:13)
#loc3051 = loc("./scratch/dave.mlir":3050:13)
#loc3052 = loc("./scratch/dave.mlir":3051:13)
#loc3053 = loc("./scratch/dave.mlir":3052:13)
#loc3054 = loc("./scratch/dave.mlir":3053:13)
#loc3055 = loc("./scratch/dave.mlir":3054:13)
#loc3056 = loc("./scratch/dave.mlir":3055:13)
#loc3057 = loc("./scratch/dave.mlir":3056:13)
#loc3058 = loc("./scratch/dave.mlir":3057:13)
#loc3059 = loc("./scratch/dave.mlir":3058:13)
#loc3060 = loc("./scratch/dave.mlir":3059:13)
#loc3061 = loc("./scratch/dave.mlir":3060:13)
#loc3062 = loc("./scratch/dave.mlir":3061:13)
#loc3063 = loc("./scratch/dave.mlir":3062:13)
#loc3064 = loc("./scratch/dave.mlir":3063:13)
#loc3065 = loc("./scratch/dave.mlir":3064:13)
#loc3066 = loc("./scratch/dave.mlir":3065:13)
#loc3067 = loc("./scratch/dave.mlir":3066:13)
#loc3068 = loc("./scratch/dave.mlir":3067:13)
#loc3069 = loc("./scratch/dave.mlir":3068:13)
#loc3070 = loc("./scratch/dave.mlir":3069:13)
#loc3071 = loc("./scratch/dave.mlir":3070:13)
#loc3072 = loc("./scratch/dave.mlir":3071:13)
#loc3073 = loc("./scratch/dave.mlir":3072:13)
#loc3074 = loc("./scratch/dave.mlir":3073:13)
#loc3075 = loc("./scratch/dave.mlir":3074:13)
#loc3076 = loc("./scratch/dave.mlir":3075:13)
#loc3077 = loc("./scratch/dave.mlir":3076:13)
#loc3078 = loc("./scratch/dave.mlir":3077:13)
#loc3079 = loc("./scratch/dave.mlir":3078:13)
#loc3080 = loc("./scratch/dave.mlir":3079:13)
#loc3081 = loc("./scratch/dave.mlir":3080:13)
#loc3082 = loc("./scratch/dave.mlir":3081:13)
#loc3083 = loc("./scratch/dave.mlir":3082:13)
#loc3084 = loc("./scratch/dave.mlir":3083:13)
#loc3085 = loc("./scratch/dave.mlir":3084:13)
#loc3086 = loc("./scratch/dave.mlir":3085:13)
#loc3087 = loc("./scratch/dave.mlir":3086:13)
#loc3088 = loc("./scratch/dave.mlir":3087:13)
#loc3089 = loc("./scratch/dave.mlir":3088:13)
#loc3090 = loc("./scratch/dave.mlir":3089:13)
#loc3091 = loc("./scratch/dave.mlir":3090:13)
#loc3092 = loc("./scratch/dave.mlir":3091:13)
#loc3093 = loc("./scratch/dave.mlir":3092:13)
#loc3094 = loc("./scratch/dave.mlir":3093:13)
#loc3095 = loc("./scratch/dave.mlir":3094:13)
#loc3096 = loc("./scratch/dave.mlir":3095:13)
#loc3097 = loc("./scratch/dave.mlir":3096:13)
#loc3098 = loc("./scratch/dave.mlir":3097:13)
#loc3099 = loc("./scratch/dave.mlir":3098:13)
#loc3100 = loc("./scratch/dave.mlir":3099:13)
#loc3101 = loc("./scratch/dave.mlir":3100:13)
#loc3102 = loc("./scratch/dave.mlir":3101:13)
#loc3103 = loc("./scratch/dave.mlir":3102:13)
#loc3104 = loc("./scratch/dave.mlir":3103:13)
#loc3105 = loc("./scratch/dave.mlir":3104:13)
#loc3106 = loc("./scratch/dave.mlir":3105:13)
#loc3107 = loc("./scratch/dave.mlir":3106:13)
#loc3108 = loc("./scratch/dave.mlir":3107:13)
#loc3109 = loc("./scratch/dave.mlir":3108:13)
#loc3110 = loc("./scratch/dave.mlir":3109:13)
#loc3111 = loc("./scratch/dave.mlir":3110:13)
#loc3112 = loc("./scratch/dave.mlir":3111:13)
#loc3113 = loc("./scratch/dave.mlir":3112:13)
#loc3114 = loc("./scratch/dave.mlir":3113:13)
#loc3115 = loc("./scratch/dave.mlir":3114:13)
#loc3116 = loc("./scratch/dave.mlir":3115:13)
#loc3117 = loc("./scratch/dave.mlir":3116:13)
#loc3118 = loc("./scratch/dave.mlir":3117:13)
#loc3119 = loc("./scratch/dave.mlir":3118:13)
#loc3120 = loc("./scratch/dave.mlir":3119:13)
#loc3121 = loc("./scratch/dave.mlir":3120:13)
#loc3122 = loc("./scratch/dave.mlir":3121:13)
#loc3123 = loc("./scratch/dave.mlir":3122:13)
#loc3124 = loc("./scratch/dave.mlir":3123:13)
#loc3125 = loc("./scratch/dave.mlir":3124:13)
#loc3126 = loc("./scratch/dave.mlir":3125:13)
#loc3127 = loc("./scratch/dave.mlir":3126:13)
#loc3128 = loc("./scratch/dave.mlir":3127:13)
#loc3129 = loc("./scratch/dave.mlir":3128:13)
#loc3130 = loc("./scratch/dave.mlir":3129:13)
#loc3131 = loc("./scratch/dave.mlir":3130:13)
#loc3132 = loc("./scratch/dave.mlir":3131:13)
#loc3133 = loc("./scratch/dave.mlir":3132:13)
#loc3134 = loc("./scratch/dave.mlir":3133:13)
#loc3135 = loc("./scratch/dave.mlir":3134:13)
#loc3136 = loc("./scratch/dave.mlir":3135:13)
#loc3137 = loc("./scratch/dave.mlir":3136:13)
#loc3138 = loc("./scratch/dave.mlir":3137:13)
#loc3139 = loc("./scratch/dave.mlir":3138:13)
#loc3140 = loc("./scratch/dave.mlir":3139:13)
#loc3141 = loc("./scratch/dave.mlir":3140:13)
#loc3142 = loc("./scratch/dave.mlir":3141:13)
#loc3143 = loc("./scratch/dave.mlir":3142:13)
#loc3144 = loc("./scratch/dave.mlir":3143:13)
#loc3145 = loc("./scratch/dave.mlir":3144:13)
#loc3146 = loc("./scratch/dave.mlir":3145:13)
#loc3147 = loc("./scratch/dave.mlir":3146:13)
#loc3148 = loc("./scratch/dave.mlir":3147:13)
#loc3149 = loc("./scratch/dave.mlir":3148:13)
#loc3150 = loc("./scratch/dave.mlir":3149:13)
#loc3151 = loc("./scratch/dave.mlir":3150:13)
#loc3152 = loc("./scratch/dave.mlir":3151:13)
#loc3153 = loc("./scratch/dave.mlir":3152:13)
#loc3154 = loc("./scratch/dave.mlir":3153:13)
#loc3155 = loc("./scratch/dave.mlir":3154:13)
#loc3156 = loc("./scratch/dave.mlir":3155:13)
#loc3157 = loc("./scratch/dave.mlir":3156:13)
#loc3158 = loc("./scratch/dave.mlir":3157:13)
#loc3159 = loc("./scratch/dave.mlir":3158:13)
#loc3160 = loc("./scratch/dave.mlir":3159:13)
#loc3161 = loc("./scratch/dave.mlir":3160:13)
#loc3162 = loc("./scratch/dave.mlir":3161:13)
#loc3163 = loc("./scratch/dave.mlir":3162:13)
#loc3164 = loc("./scratch/dave.mlir":3163:13)
#loc3165 = loc("./scratch/dave.mlir":3164:13)
#loc3166 = loc("./scratch/dave.mlir":3165:13)
#loc3167 = loc("./scratch/dave.mlir":3166:13)
#loc3168 = loc("./scratch/dave.mlir":3167:13)
#loc3169 = loc("./scratch/dave.mlir":3168:13)
#loc3170 = loc("./scratch/dave.mlir":3169:13)
#loc3171 = loc("./scratch/dave.mlir":3170:13)
#loc3172 = loc("./scratch/dave.mlir":3171:13)
#loc3173 = loc("./scratch/dave.mlir":3172:13)
#loc3174 = loc("./scratch/dave.mlir":3173:13)
#loc3175 = loc("./scratch/dave.mlir":3174:13)
#loc3176 = loc("./scratch/dave.mlir":3175:13)
#loc3177 = loc("./scratch/dave.mlir":3176:13)
#loc3178 = loc("./scratch/dave.mlir":3177:13)
#loc3179 = loc("./scratch/dave.mlir":3178:13)
#loc3180 = loc("./scratch/dave.mlir":3179:13)
#loc3181 = loc("./scratch/dave.mlir":3180:13)
#loc3182 = loc("./scratch/dave.mlir":3181:13)
#loc3183 = loc("./scratch/dave.mlir":3182:13)
#loc3184 = loc("./scratch/dave.mlir":3183:13)
#loc3185 = loc("./scratch/dave.mlir":3184:13)
#loc3186 = loc("./scratch/dave.mlir":3185:13)
#loc3187 = loc("./scratch/dave.mlir":3186:13)
#loc3188 = loc("./scratch/dave.mlir":3187:13)
#loc3189 = loc("./scratch/dave.mlir":3188:13)
#loc3190 = loc("./scratch/dave.mlir":3189:13)
#loc3191 = loc("./scratch/dave.mlir":3190:13)
#loc3192 = loc("./scratch/dave.mlir":3191:13)
#loc3193 = loc("./scratch/dave.mlir":3192:13)
#loc3194 = loc("./scratch/dave.mlir":3193:13)
#loc3195 = loc("./scratch/dave.mlir":3194:13)
#loc3196 = loc("./scratch/dave.mlir":3195:13)
#loc3197 = loc("./scratch/dave.mlir":3196:13)
#loc3198 = loc("./scratch/dave.mlir":3197:13)
#loc3199 = loc("./scratch/dave.mlir":3198:13)
#loc3200 = loc("./scratch/dave.mlir":3199:13)
#loc3201 = loc("./scratch/dave.mlir":3200:13)
#loc3202 = loc("./scratch/dave.mlir":3201:13)
#loc3203 = loc("./scratch/dave.mlir":3202:13)
#loc3204 = loc("./scratch/dave.mlir":3203:13)
#loc3205 = loc("./scratch/dave.mlir":3204:13)
#loc3206 = loc("./scratch/dave.mlir":3205:13)
#loc3207 = loc("./scratch/dave.mlir":3206:13)
#loc3208 = loc("./scratch/dave.mlir":3207:13)
#loc3209 = loc("./scratch/dave.mlir":3208:13)
#loc3210 = loc("./scratch/dave.mlir":3209:13)
#loc3211 = loc("./scratch/dave.mlir":3210:13)
#loc3212 = loc("./scratch/dave.mlir":3211:13)
#loc3213 = loc("./scratch/dave.mlir":3212:13)
#loc3214 = loc("./scratch/dave.mlir":3213:13)
#loc3215 = loc("./scratch/dave.mlir":3214:13)
#loc3216 = loc("./scratch/dave.mlir":3215:13)
#loc3217 = loc("./scratch/dave.mlir":3216:13)
#loc3218 = loc("./scratch/dave.mlir":3217:13)
#loc3219 = loc("./scratch/dave.mlir":3218:13)
#loc3220 = loc("./scratch/dave.mlir":3219:13)
#loc3221 = loc("./scratch/dave.mlir":3220:13)
#loc3222 = loc("./scratch/dave.mlir":3221:13)
#loc3223 = loc("./scratch/dave.mlir":3222:13)
#loc3224 = loc("./scratch/dave.mlir":3223:13)
#loc3225 = loc("./scratch/dave.mlir":3224:13)
#loc3226 = loc("./scratch/dave.mlir":3225:13)
#loc3227 = loc("./scratch/dave.mlir":3226:13)
#loc3228 = loc("./scratch/dave.mlir":3227:13)
#loc3229 = loc("./scratch/dave.mlir":3228:13)
#loc3230 = loc("./scratch/dave.mlir":3229:13)
#loc3231 = loc("./scratch/dave.mlir":3230:13)
#loc3232 = loc("./scratch/dave.mlir":3231:13)
#loc3233 = loc("./scratch/dave.mlir":3232:13)
#loc3234 = loc("./scratch/dave.mlir":3233:13)
#loc3235 = loc("./scratch/dave.mlir":3234:13)
#loc3236 = loc("./scratch/dave.mlir":3235:13)
#loc3237 = loc("./scratch/dave.mlir":3236:13)
#loc3238 = loc("./scratch/dave.mlir":3237:13)
#loc3239 = loc("./scratch/dave.mlir":3238:13)
#loc3240 = loc("./scratch/dave.mlir":3239:13)
#loc3241 = loc("./scratch/dave.mlir":3240:13)
#loc3242 = loc("./scratch/dave.mlir":3241:13)
#loc3243 = loc("./scratch/dave.mlir":3242:13)
#loc3244 = loc("./scratch/dave.mlir":3243:13)
#loc3245 = loc("./scratch/dave.mlir":3244:13)
#loc3246 = loc("./scratch/dave.mlir":3245:13)
#loc3247 = loc("./scratch/dave.mlir":3246:13)
#loc3248 = loc("./scratch/dave.mlir":3247:13)
#loc3249 = loc("./scratch/dave.mlir":3248:13)
#loc3250 = loc("./scratch/dave.mlir":3249:13)
#loc3251 = loc("./scratch/dave.mlir":3250:13)
#loc3252 = loc("./scratch/dave.mlir":3251:13)
#loc3253 = loc("./scratch/dave.mlir":3252:13)
#loc3254 = loc("./scratch/dave.mlir":3253:13)
#loc3255 = loc("./scratch/dave.mlir":3254:13)
#loc3256 = loc("./scratch/dave.mlir":3255:13)
#loc3257 = loc("./scratch/dave.mlir":3256:13)
#loc3258 = loc("./scratch/dave.mlir":3257:13)
#loc3259 = loc("./scratch/dave.mlir":3258:13)
#loc3260 = loc("./scratch/dave.mlir":3259:13)
#loc3261 = loc("./scratch/dave.mlir":3260:13)
#loc3262 = loc("./scratch/dave.mlir":3261:13)
#loc3263 = loc("./scratch/dave.mlir":3262:13)
#loc3264 = loc("./scratch/dave.mlir":3263:13)
#loc3265 = loc("./scratch/dave.mlir":3264:13)
#loc3266 = loc("./scratch/dave.mlir":3265:13)
#loc3267 = loc("./scratch/dave.mlir":3266:13)
#loc3268 = loc("./scratch/dave.mlir":3267:13)
#loc3269 = loc("./scratch/dave.mlir":3268:13)
#loc3270 = loc("./scratch/dave.mlir":3269:13)
#loc3271 = loc("./scratch/dave.mlir":3270:13)
#loc3272 = loc("./scratch/dave.mlir":3271:13)
#loc3273 = loc("./scratch/dave.mlir":3272:13)
#loc3274 = loc("./scratch/dave.mlir":3273:13)
#loc3275 = loc("./scratch/dave.mlir":3274:13)
#loc3276 = loc("./scratch/dave.mlir":3275:13)
#loc3277 = loc("./scratch/dave.mlir":3276:13)
#loc3278 = loc("./scratch/dave.mlir":3277:13)
#loc3279 = loc("./scratch/dave.mlir":3278:13)
#loc3280 = loc("./scratch/dave.mlir":3279:13)
#loc3281 = loc("./scratch/dave.mlir":3280:13)
#loc3282 = loc("./scratch/dave.mlir":3281:13)
#loc3283 = loc("./scratch/dave.mlir":3282:13)
#loc3284 = loc("./scratch/dave.mlir":3283:13)
#loc3285 = loc("./scratch/dave.mlir":3284:13)
#loc3286 = loc("./scratch/dave.mlir":3285:13)
#loc3287 = loc("./scratch/dave.mlir":3286:13)
#loc3288 = loc("./scratch/dave.mlir":3287:13)
#loc3289 = loc("./scratch/dave.mlir":3288:13)
#loc3290 = loc("./scratch/dave.mlir":3289:13)
#loc3291 = loc("./scratch/dave.mlir":3290:13)
#loc3292 = loc("./scratch/dave.mlir":3291:13)
#loc3293 = loc("./scratch/dave.mlir":3292:13)
#loc3294 = loc("./scratch/dave.mlir":3293:13)
#loc3295 = loc("./scratch/dave.mlir":3294:13)
#loc3296 = loc("./scratch/dave.mlir":3295:13)
#loc3297 = loc("./scratch/dave.mlir":3296:13)
#loc3298 = loc("./scratch/dave.mlir":3297:13)
#loc3299 = loc("./scratch/dave.mlir":3298:13)
#loc3300 = loc("./scratch/dave.mlir":3299:13)
#loc3301 = loc("./scratch/dave.mlir":3300:13)
#loc3302 = loc("./scratch/dave.mlir":3301:13)
#loc3303 = loc("./scratch/dave.mlir":3302:13)
#loc3304 = loc("./scratch/dave.mlir":3303:13)
#loc3305 = loc("./scratch/dave.mlir":3304:13)
#loc3306 = loc("./scratch/dave.mlir":3305:13)
#loc3307 = loc("./scratch/dave.mlir":3306:13)
#loc3308 = loc("./scratch/dave.mlir":3307:13)
#loc3309 = loc("./scratch/dave.mlir":3308:13)
#loc3310 = loc("./scratch/dave.mlir":3309:13)
#loc3311 = loc("./scratch/dave.mlir":3310:13)
#loc3312 = loc("./scratch/dave.mlir":3311:13)
#loc3313 = loc("./scratch/dave.mlir":3312:13)
#loc3314 = loc("./scratch/dave.mlir":3313:13)
#loc3315 = loc("./scratch/dave.mlir":3314:13)
#loc3316 = loc("./scratch/dave.mlir":3315:13)
#loc3317 = loc("./scratch/dave.mlir":3316:13)
#loc3318 = loc("./scratch/dave.mlir":3317:13)
#loc3319 = loc("./scratch/dave.mlir":3318:13)
#loc3320 = loc("./scratch/dave.mlir":3319:13)
#loc3321 = loc("./scratch/dave.mlir":3320:13)
#loc3322 = loc("./scratch/dave.mlir":3321:13)
#loc3323 = loc("./scratch/dave.mlir":3322:13)
#loc3324 = loc("./scratch/dave.mlir":3323:13)
#loc3325 = loc("./scratch/dave.mlir":3324:13)
#loc3326 = loc("./scratch/dave.mlir":3325:13)
#loc3327 = loc("./scratch/dave.mlir":3326:13)
#loc3328 = loc("./scratch/dave.mlir":3327:13)
#loc3329 = loc("./scratch/dave.mlir":3328:13)
#loc3330 = loc("./scratch/dave.mlir":3329:13)
#loc3331 = loc("./scratch/dave.mlir":3330:13)
#loc3332 = loc("./scratch/dave.mlir":3331:13)
#loc3333 = loc("./scratch/dave.mlir":3332:13)
#loc3334 = loc("./scratch/dave.mlir":3333:13)
#loc3335 = loc("./scratch/dave.mlir":3334:13)
#loc3336 = loc("./scratch/dave.mlir":3335:13)
#loc3337 = loc("./scratch/dave.mlir":3336:13)
#loc3338 = loc("./scratch/dave.mlir":3337:13)
#loc3339 = loc("./scratch/dave.mlir":3338:13)
#loc3340 = loc("./scratch/dave.mlir":3339:13)
#loc3341 = loc("./scratch/dave.mlir":3340:13)
#loc3342 = loc("./scratch/dave.mlir":3341:13)
#loc3343 = loc("./scratch/dave.mlir":3342:13)
#loc3344 = loc("./scratch/dave.mlir":3343:13)
#loc3345 = loc("./scratch/dave.mlir":3344:13)
#loc3346 = loc("./scratch/dave.mlir":3345:13)
#loc3347 = loc("./scratch/dave.mlir":3346:13)
#loc3348 = loc("./scratch/dave.mlir":3347:13)
#loc3349 = loc("./scratch/dave.mlir":3348:13)
#loc3350 = loc("./scratch/dave.mlir":3349:13)
#loc3351 = loc("./scratch/dave.mlir":3350:13)
#loc3352 = loc("./scratch/dave.mlir":3351:13)
#loc3353 = loc("./scratch/dave.mlir":3352:13)
#loc3354 = loc("./scratch/dave.mlir":3353:13)
#loc3355 = loc("./scratch/dave.mlir":3354:13)
#loc3356 = loc("./scratch/dave.mlir":3355:13)
#loc3357 = loc("./scratch/dave.mlir":3356:13)
#loc3358 = loc("./scratch/dave.mlir":3357:13)
#loc3359 = loc("./scratch/dave.mlir":3358:13)

{-#
  dialect_resources: {
    builtin: {
      __model_Constant_3_attr__value: "0x080000000400000000000000",
      __model_Constant_4_attr__value: "0x08000000FFFFFFFFFFFFFFFF",
      __model_layers.0_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.0_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.0_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.0_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.0_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.0_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.0_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.0_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.0_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.0_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.0_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.0_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.0_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.0_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.0_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.0_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.0_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.0_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.0_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.0_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.0_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.0_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.0_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.0_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.0_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.0_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.1_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.1_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.1_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.1_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.1_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.1_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.1_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.1_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.1_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.1_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.1_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.1_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.1_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.1_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.1_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.1_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.1_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.1_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.1_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.1_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.1_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.1_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.1_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.1_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.1_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.1_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.2_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.2_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.2_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.2_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.2_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.2_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.2_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.2_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.2_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.2_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.2_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.2_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.2_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.2_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.2_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.2_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.2_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.2_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.2_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.2_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.2_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.2_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.2_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.2_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.2_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.2_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.3_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.3_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.3_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.3_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.3_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.3_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.3_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.3_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.3_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.3_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.3_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.3_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.3_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.3_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.3_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.3_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.3_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.3_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.3_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.3_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.3_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.3_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.3_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.3_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.3_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.3_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.4_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.4_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.4_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.4_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.4_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.4_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.4_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.4_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.4_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.4_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.4_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.4_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.4_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.4_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.4_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.4_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.4_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.4_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.4_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.4_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.4_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.4_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.4_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.4_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.4_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.4_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.5_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.5_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.5_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.5_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.5_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.5_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.5_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.5_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.5_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.5_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.5_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.5_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.5_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.5_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.5_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.5_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.5_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.5_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.5_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.5_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.5_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.5_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.5_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.5_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.5_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.5_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.6_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.6_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.6_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.6_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.6_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.6_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.6_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.6_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.6_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.6_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.6_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.6_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.6_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.6_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.6_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.6_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.6_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.6_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.6_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.6_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.6_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.6_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.6_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.6_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.6_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.6_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.7_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.7_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.7_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.7_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.7_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.7_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.7_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.7_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.7_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.7_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.7_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.7_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.7_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.7_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.7_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.7_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.7_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.7_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.7_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.7_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.7_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.7_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.7_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.7_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.7_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.7_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.8_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.8_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.8_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.8_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.8_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.8_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.8_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.8_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.8_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.8_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.8_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.8_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.8_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.8_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.8_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.8_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.8_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.8_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.8_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.8_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.8_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.8_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.8_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.8_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.8_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.8_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.9_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.9_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.9_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.9_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.9_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.9_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.9_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.9_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.9_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.9_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.9_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.9_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.9_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.9_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.9_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.9_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.9_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.9_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.9_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.9_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.9_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.9_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.9_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.9_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.9_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.9_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.10_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.10_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.10_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.10_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.10_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.10_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.10_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.10_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.10_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.10_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.10_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.10_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.10_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.10_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.10_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.10_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.10_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.10_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.10_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.10_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.10_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.10_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.10_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.10_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.10_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.10_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.11_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.11_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.11_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.11_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.11_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.11_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.11_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.11_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.11_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.11_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.11_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.11_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.11_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.11_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.11_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.11_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.11_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.11_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.11_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.11_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.11_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.11_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.11_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.11_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.11_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.11_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.12_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.12_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.12_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.12_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.12_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.12_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.12_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.12_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.12_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.12_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.12_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.12_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.12_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.12_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.12_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.12_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.12_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.12_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.12_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.12_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.12_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.12_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.12_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.12_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.12_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.12_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.13_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.13_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.13_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.13_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.13_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.13_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.13_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.13_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.13_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.13_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.13_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.13_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.13_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.13_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.13_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.13_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.13_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.13_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.13_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.13_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.13_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.13_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.13_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.13_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.13_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.13_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.14_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.14_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.14_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.14_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.14_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.14_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.14_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.14_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.14_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.14_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.14_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.14_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.14_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.14_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.14_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.14_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.14_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.14_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.14_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.14_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.14_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.14_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.14_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.14_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.14_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.14_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.15_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.15_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.15_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.15_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.15_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.15_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.15_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.15_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.15_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.15_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.15_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.15_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.15_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.15_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.15_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.15_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.15_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.15_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.15_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.15_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.15_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.15_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.15_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.15_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.15_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.15_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.16_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.16_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.16_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.16_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.16_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.16_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.16_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.16_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.16_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.16_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.16_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.16_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.16_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.16_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.16_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.16_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.16_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.16_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.16_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.16_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.16_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.16_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.16_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.16_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.16_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.16_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.17_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.17_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.17_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.17_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.17_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.17_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.17_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.17_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.17_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.17_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.17_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.17_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.17_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.17_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.17_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.17_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.17_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.17_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.17_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.17_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.17_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.17_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.17_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.17_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.17_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.17_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.18_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.18_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.18_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.18_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.18_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.18_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.18_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.18_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.18_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.18_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.18_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.18_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.18_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.18_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.18_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.18_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.18_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.18_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.18_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.18_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.18_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.18_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.18_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.18_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.18_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.18_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.19_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.19_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.19_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.19_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.19_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.19_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.19_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.19_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.19_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.19_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.19_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.19_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.19_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.19_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.19_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.19_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.19_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.19_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.19_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.19_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.19_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.19_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.19_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.19_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.19_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.19_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.20_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.20_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.20_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.20_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.20_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.20_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.20_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.20_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.20_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.20_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.20_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.20_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.20_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.20_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.20_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.20_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.20_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.20_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.20_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.20_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.20_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.20_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.20_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.20_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.20_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.20_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.21_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.21_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.21_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.21_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.21_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.21_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.21_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.21_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.21_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.21_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.21_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.21_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.21_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.21_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.21_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.21_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.21_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.21_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.21_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.21_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.21_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.21_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.21_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.21_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.21_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.21_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.22_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.22_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.22_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.22_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.22_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.22_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.22_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.22_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.22_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.22_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.22_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.22_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.22_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.22_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.22_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.22_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.22_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.22_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.22_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.22_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.22_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.22_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.22_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.22_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.22_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.22_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.23_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.23_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.23_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.23_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.23_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.23_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.23_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.23_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.23_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.23_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.23_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.23_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.23_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.23_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.23_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.23_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.23_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.23_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.23_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.23_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.23_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.23_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.23_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.23_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.23_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.23_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.24_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.24_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.24_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.24_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.24_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.24_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.24_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.24_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.24_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.24_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.24_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.24_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.24_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.24_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.24_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.24_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.24_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.24_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.24_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.24_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.24_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.24_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.24_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.24_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.24_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.24_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.25_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.25_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.25_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.25_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.25_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.25_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.25_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.25_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.25_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.25_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.25_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.25_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.25_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.25_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.25_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.25_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.25_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.25_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.25_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.25_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.25_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.25_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.25_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.25_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.25_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.25_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.26_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.26_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.26_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.26_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.26_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.26_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.26_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.26_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.26_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.26_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.26_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.26_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.26_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.26_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.26_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.26_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.26_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.26_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.26_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.26_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.26_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.26_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.26_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.26_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.26_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.26_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.27_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.27_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.27_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.27_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.27_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.27_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.27_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.27_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.27_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.27_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.27_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.27_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.27_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.27_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.27_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.27_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.27_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.27_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.27_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.27_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.27_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.27_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.27_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.27_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.27_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.27_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.28_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.28_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.28_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.28_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.28_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.28_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.28_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.28_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.28_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.28_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.28_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.28_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.28_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.28_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.28_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.28_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.28_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.28_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.28_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.28_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.28_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.28_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.28_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.28_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.28_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.28_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.29_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.29_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.29_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.29_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.29_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.29_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.29_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.29_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.29_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.29_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.29_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.29_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.29_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.29_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.29_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.29_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.29_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.29_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.29_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.29_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.29_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.29_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.29_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.29_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.29_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.29_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.30_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.30_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.30_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.30_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.30_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.30_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.30_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.30_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.30_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.30_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.30_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.30_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.30_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.30_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.30_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.30_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.30_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.30_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.30_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.30_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.30_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.30_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.30_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.30_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.30_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.30_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.31_input_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.31_input_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.31_input_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_layers.31_self_attn_Constant_3_attr__value: "0x080000000100000000000000",
      __model_layers.31_self_attn_Constant_4_attr__value: "0x080000000100000000000000",
      __model_layers.31_self_attn_Constant_5_attr__value: "0x080000000300000000000000",
      __model_layers.31_self_attn_Constant_6_attr__value: "0x080000000000000000000000",
      __model_layers.31_self_attn_Constant_7_attr__value: "0x080000004000000000000000",
      __model_layers.31_self_attn_Constant_8_attr__value: "0x080000000100000000000000",
      __model_layers.31_self_attn_Constant_9_attr__value: "0x080000000300000000000000",
      __model_layers.31_self_attn_Constant_10_attr__value: "0x080000004000000000000000",
      __model_layers.31_self_attn_Constant_11_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.31_self_attn_Constant_12_attr__value: "0x080000000100000000000000",
      __model_layers.31_self_attn_Constant_13_attr__value: "0x080000000300000000000000",
      __model_layers.31_self_attn_Constant_14_attr__value: "0x080000000000000000000000",
      __model_layers.31_self_attn_Constant_15_attr__value: "0x080000004000000000000000",
      __model_layers.31_self_attn_Constant_16_attr__value: "0x080000000100000000000000",
      __model_layers.31_self_attn_Constant_17_attr__value: "0x080000000300000000000000",
      __model_layers.31_self_attn_Constant_18_attr__value: "0x080000004000000000000000",
      __model_layers.31_self_attn_Constant_19_attr__value: "0x08000000FFFFFFFFFFFFFF7F",
      __model_layers.31_self_attn_Constant_20_attr__value: "0x080000000100000000000000",
      __model_layers.31_self_attn_Constant_21_attr__value: "0x08000000F3043541",
      __model_layers.31_self_attn_Constant_22_attr__value: "0x08000000010000000000000008000000000000000010000000000000",
      __model_layers.31_post_attention_layernorm_Constant_attr__value: "0x0800000000000040",
      __model_layers.31_post_attention_layernorm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_layers.31_post_attention_layernorm_Constant_2_attr__value: "0x080000000000803F",
      __model_norm_Constant_attr__value: "0x0800000000000040",
      __model_norm_Constant_1_attr__value: "0x08000000ACC52737",
      __model_norm_Constant_2_attr__value: "0x080000000000803F"
    }
  }
#-}


